"""
Aplica√ß√£o FastAPI para Previs√£o de Pre√ßos B3SA3.SA

Esta API serve o modelo LSTM treinado para fazer previs√µes de pre√ßos
de a√ß√µes da B3 S.A. (B3SA3.SA).

Fase 8: Inclui sistema de monitoramento de produ√ß√£o com logging estruturado.
"""

import os
import sys
import time
import traceback
from datetime import datetime
from pathlib import Path
from contextlib import asynccontextmanager
from typing import Dict, Any

import numpy as np
import joblib
from fastapi import FastAPI, HTTPException, status
from fastapi.responses import JSONResponse, RedirectResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from tensorflow.keras.models import load_model

# Adiciona o diret√≥rio raiz ao path para imports
ROOT_DIR = Path(__file__).parent.parent
sys.path.append(str(ROOT_DIR))

from api.schemas import (
    PrevisaoInput,
    PrevisaoAutoInput,
    PrevisaoOutput,
    HealthResponse,
    InfoModeloResponse
)

# Sistema de monitoramento (Fase 8)
from api.monitoring import get_prediction_logger, get_metrics_logger

# Sistema de valida√ß√£o de performance (Fase 12)
from src.performance_monitor import PerformanceMonitor

# M√≥dulo de busca autom√°tica de dados (Fase 9)
from api.data_fetcher import (
    buscar_dados_historicos,
    formatar_dados_para_modelo,
    validar_ticker_format,
    obter_info_ticker
)

# M√≥dulo de banco de dados SQLite (Fase 10)
try:
    from database import get_db
    DB_DISPONIVEL = True
except ImportError:
    DB_DISPONIVEL = False
    print("‚ö†Ô∏è  M√≥dulo database n√£o encontrado - endpoints de dados hist√≥ricos desabilitados")


# Vari√°veis globais para armazenar modelo e scaler
model = None
scaler = None
example_data = None  # Dados de exemplo pr√©-carregados
WINDOW_SIZE = 60
NUM_FEATURES = 5


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Gerenciador de ciclo de vida da aplica√ß√£o.
    
    Carrega o modelo e scaler na inicializa√ß√£o e libera recursos
    no encerramento.
    """
    global model, scaler, example_data
    
    # Startup: Carregar modelo e scaler
    print("üöÄ Iniciando API...")
    print("üìÇ Carregando artefatos do modelo...")
    
    try:
        # Caminhos dos artefatos
        model_path = ROOT_DIR / "models" / "lstm_model_best.h5"
        scaler_path = ROOT_DIR / "models" / "scaler.pkl"
        example_path = ROOT_DIR / "data" / "processed" / "example_input.npy"
        
        # Validar exist√™ncia dos arquivos
        if not model_path.exists():
            raise FileNotFoundError(f"Modelo n√£o encontrado: {model_path}")
        
        if not scaler_path.exists():
            raise FileNotFoundError(f"Scaler n√£o encontrado: {scaler_path}")
        
        # Carregar modelo
        print(f"   ‚îî‚îÄ Carregando modelo: {model_path}")
        model = load_model(str(model_path))
        print(f"   ‚úÖ Modelo carregado com sucesso!")
        
        # Carregar scaler
        print(f"   ‚îî‚îÄ Carregando scaler: {scaler_path}")
        scaler = joblib.load(str(scaler_path))
        print(f"   ‚úÖ Scaler carregado com sucesso!")
        
        # Carregar dados de exemplo (opcional)
        if example_path.exists():
            print(f"   ‚îî‚îÄ Carregando dados de exemplo: {example_path}")
            example_data = np.load(str(example_path))
            print(f"   ‚úÖ Dados de exemplo carregados! Shape: {example_data.shape}")
        else:
            print(f"   ‚ö†Ô∏è  Dados de exemplo n√£o encontrados (opcional)")
        
        print("‚úÖ API pronta para receber requisi√ß√µes!\n")
        
    except Exception as e:
        print(f"‚ùå Erro ao carregar artefatos: {e}")
        raise
    
    yield
    
    # Shutdown: Limpar recursos
    print("\nüõë Encerrando API...")
    model = None
    scaler = None
    print("‚úÖ Recursos liberados.")


# Inicializar aplica√ß√£o FastAPI
app = FastAPI(
    title="API de Previs√£o B3SA3.SA",
    description="API REST para previs√£o de pre√ßos de a√ß√µes da B3 S.A. usando LSTM",
    version="1.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

# Montar diret√≥rio de arquivos est√°ticos (interface web)
static_dir = ROOT_DIR / "static"
if static_dir.exists():
    app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")


@app.get(
    "/",
    summary="P√°gina Inicial",
    description="Redireciona para interface web ou retorna status",
    include_in_schema=False
)
async def root():
    """
    Redireciona para interface web se dispon√≠vel, sen√£o retorna health check.
    """
    index_file = ROOT_DIR / "static" / "index.html"
    if index_file.exists():
        return FileResponse(str(index_file))
    else:
        return await health_check()


@app.get(
    "/api",
    response_model=HealthResponse,
    summary="Health Check API",
    description="Verifica se a API est√° ativa e operacional",
    tags=["Status"]
)
async def health_check() -> HealthResponse:
    """
    Endpoint de health check.
    
    Returns:
        HealthResponse: Status da API e informa√ß√µes b√°sicas
    """
    return HealthResponse(
        status="ativo",
        mensagem="API de previs√£o B3SA3.SA operacional",
        versao="1.0.0",
        modelo_carregado=(model is not None and scaler is not None)
    )


@app.get(
    "/health",
    response_model=HealthResponse,
    summary="Health Check Alternativo",
    description="Endpoint alternativo para verifica√ß√£o de sa√∫de da API",
    tags=["Status"]
)
async def health() -> HealthResponse:
    """
    Endpoint alternativo de health check.
    
    Returns:
        HealthResponse: Status da API
    """
    return await health_check()


@app.get(
    "/info",
    response_model=InfoModeloResponse,
    summary="Informa√ß√µes do Modelo",
    description="Retorna informa√ß√µes detalhadas sobre o modelo LSTM",
    tags=["Modelo"]
)
async def info_modelo() -> InfoModeloResponse:
    """
    Retorna informa√ß√µes sobre o modelo carregado.
    
    Returns:
        InfoModeloResponse: Detalhes do modelo e m√©tricas de performance
    """
    if model is None or scaler is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Modelo n√£o est√° carregado. Aguarde a inicializa√ß√£o da API."
        )
    
    return InfoModeloResponse(
        nome="LSTM_B3SA3_Predictor",
        arquitetura="LSTM - 2 camadas (64 ‚Üí 32 unidades) + Dropout (0.2)",
        parametros=30369,
        metricas={
            "RMSE": "R$ 0.26",
            "MAE": "R$ 0.20",
            "MAPE": "1.53%",
            "R2": "0.9351"
        },
        window_size=60,
        features=["Open", "High", "Low", "Close", "Volume"]
    )


@app.get(
    "/data/historical/{ticker}",
    summary="Dados Hist√≥ricos do Banco de Dados",
    description="Retorna dados hist√≥ricos OHLCV do cache SQLite para um per√≠odo espec√≠fico",
    tags=["Dados"],
    status_code=status.HTTP_200_OK
)
async def obter_dados_historicos(
    ticker: str,
    start_date: str,  # YYYY-MM-DD
    end_date: str     # YYYY-MM-DD
) -> JSONResponse:
    """
    Retorna dados hist√≥ricos do banco de dados SQLite.
    
    Este endpoint permite consultar qualquer per√≠odo de dados hist√≥ricos
    armazenados no cache local, sem depender do Yahoo Finance.
    
    Args:
        ticker: S√≠mbolo da a√ß√£o (ex: B3SA3.SA)
        start_date: Data inicial no formato YYYY-MM-DD
        end_date: Data final no formato YYYY-MM-DD
        
    Returns:
        JSONResponse com:
        - ticker: S√≠mbolo consultado
        - period: {"start": start_date, "end": end_date}
        - count: N√∫mero de registros retornados
        - data: Array de objetos com date, open, high, low, close, volume
        
    Raises:
        HTTPException 503: Se banco de dados n√£o estiver dispon√≠vel
        HTTPException 400: Se datas forem inv√°lidas
        HTTPException 404: Se n√£o houver dados para o per√≠odo
    """
    if not DB_DISPONIVEL:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Banco de dados SQLite n√£o est√° dispon√≠vel. Execute: python database/populate_db.py"
        )
    
    # Valida formato das datas
    try:
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        
        if start_dt > end_dt:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="start_date deve ser anterior a end_date"
            )
            
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Formato de data inv√°lido. Use YYYY-MM-DD. Erro: {str(e)}"
        )
    
    # Busca dados do banco
    try:
        db = get_db()
        df = db.get_data_by_period(ticker, start_dt, end_dt)
        
        if df is None or df.empty:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Nenhum dado encontrado para {ticker} entre {start_date} e {end_date}. "
                       f"Execute: python database/populate_db.py --ticker {ticker}"
            )
        
        # Converte DataFrame para lista de dicion√°rios
        data = []
        for idx, row in df.iterrows():
            # idx pode ser string ou datetime, normalizar para string
            if hasattr(idx, 'strftime'):
                date_str = idx.strftime("%Y-%m-%d")
            else:
                date_str = str(idx)
            
            data.append({
                "date": date_str,
                "open": float(row['Open']),
                "high": float(row['High']),
                "low": float(row['Low']),
                "close": float(row['Close']),
                "volume": int(row['Volume'])
            })
        
        return JSONResponse(
            content={
                "ticker": ticker,
                "period": {
                    "start": start_date,
                    "end": end_date
                },
                "count": len(data),
                "data": data
            },
            status_code=status.HTTP_200_OK
        )
        
    except Exception as e:
        print(f"‚ùå Erro ao buscar dados hist√≥ricos: {str(e)}")
        print(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao consultar banco de dados: {str(e)}"
        )


@app.post(
    "/predict",
    response_model=PrevisaoOutput,
    summary="Fazer Previs√£o",
    description="Gera previs√£o de pre√ßo para o pr√≥ximo dia com base em 60 pre√ßos hist√≥ricos",
    tags=["Previs√£o"],
    status_code=status.HTTP_200_OK
)
async def fazer_previsao(previsao_input: PrevisaoInput) -> PrevisaoOutput:
    """
    Endpoint principal para fazer previs√µes.
    
    Recebe uma lista de 60 pre√ßos de fechamento consecutivos e retorna
    a previs√£o do pr√≥ximo pre√ßo.
    
    FASE 8: Inclui logging detalhado para monitoramento em produ√ß√£o.
    
    Args:
        previsao_input: Objeto contendo lista de 60 pre√ßos
        
    Returns:
        PrevisaoOutput: Previs√£o do pr√≥ximo pre√ßo
        
    Raises:
        HTTPException: Se o modelo n√£o estiver carregado ou ocorrer erro na previs√£o
    """
    # Inicializa loggers
    pred_logger = get_prediction_logger()
    metrics_logger = get_metrics_logger()
    
    # Incrementa contador de requisi√ß√µes
    metrics_logger.increment_request()
    
    # Marca in√≠cio do processamento
    start_time = time.time()
    
    # Validar se modelo e scaler est√£o carregados
    if model is None or scaler is None:
        metrics_logger.increment_error()
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Modelo n√£o est√° carregado. Aguarde a inicializa√ß√£o da API."
        )
    
    try:
        # Extrair dados da requisi√ß√£o (agora √© 2D array: 60 dias x 5 features)
        dados = previsao_input.dados
        
        # Verificar dimens√µes (valida√ß√£o adicional)
        if len(dados) != WINDOW_SIZE:
            metrics_logger.increment_error()
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"√â necess√°rio fornecer exatamente {WINDOW_SIZE} dias de dados. Recebidos: {len(dados)}"
            )
        
        # Converter para numpy array
        # Shape: (60, 5) - 60 dias com 5 features cada [Open, High, Low, Close, Volume]
        dados_array = np.array(dados)
        
        # Validar shape
        if dados_array.shape != (WINDOW_SIZE, NUM_FEATURES):
            metrics_logger.increment_error()
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Shape esperado: ({WINDOW_SIZE}, {NUM_FEATURES}). Recebido: {dados_array.shape}"
            )
        
        # Normalizar os dados usando o scaler
        # Scaler espera shape (60, 5)
        dados_normalizados = scaler.transform(dados_array)
        
        # Reshape para formato esperado pelo modelo LSTM
        # Shape: (60, 5) -> (1, 60, 5) onde (batch_size, timesteps, features)
        dados_lstm = dados_normalizados.reshape(1, WINDOW_SIZE, NUM_FEATURES)
        
        # Fazer previs√£o
        predicao_normalizada = model.predict(dados_lstm, verbose=0)
        
        # Desnormalizar a previs√£o
        # O modelo retorna shape (1, 1) mas scaler espera (1, 5)
        # Criar array com shape correto onde apenas Close (√≠ndice 3) importa
        predicao_array = np.zeros((1, NUM_FEATURES))
        predicao_array[0, 3] = predicao_normalizada[0, 0]  # Close √© feature index 3
        
        # Desnormalizar
        predicao_real = scaler.inverse_transform(predicao_array)
        
        # Extrair valor previsto de Close
        valor_previsto = float(predicao_real[0, 3])
        
        # Calcula tempo de processamento
        processing_time = (time.time() - start_time) * 1000  # em ms
        
        # FASE 8: Log estruturado da previs√£o
        # Converte dados para formato adequado (shape 60x5 -> lista de listas)
        input_for_log = dados_lstm[0].tolist()  # Shape: (60, 5)
        
        request_id = pred_logger.log_prediction(
            input_data=input_for_log,
            prediction=valor_previsto,
            processing_time_ms=processing_time
        )
        
        # Retornar resposta
        return PrevisaoOutput(
            preco_previsto=round(valor_previsto, 2),
            confianca="alta",
            mensagem=f"Previs√£o gerada com sucesso. Modelo com MAPE de 1.53% no teste. [ID: {request_id}]"
        )
        
    except HTTPException:
        # Re-lan√ßar exce√ß√µes HTTP
        raise
        
    except Exception as e:
        # Capturar qualquer outro erro
        metrics_logger.increment_error()
        
        # Log do erro
        pred_logger.log_error(
            error_message=str(e),
            input_data=previsao_input.dados if hasattr(previsao_input, 'dados') else None
        )
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao processar previs√£o: {str(e)}"
        )


@app.post(
    "/predict/auto",
    response_model=PrevisaoOutput,
    summary="Previs√£o Autom√°tica via Ticker",
    description="Busca automaticamente dados OHLCV do Yahoo Finance e gera previs√£o",
    tags=["Previs√£o"],
    status_code=status.HTTP_200_OK
)
async def fazer_previsao_auto(previsao_input: PrevisaoAutoInput) -> PrevisaoOutput:
    """
    Endpoint de previs√£o autom√°tica com busca de dados via Yahoo Finance.
    
    Recebe apenas um ticker (ex: 'B3SA3.SA') e automaticamente:
    1. Busca √∫ltimos 60 dias de dados OHLCV via yfinance
    2. Normaliza os dados
    3. Gera previs√£o do pr√≥ximo pre√ßo de fechamento
    
    Args:
        previsao_input: Objeto contendo ticker symbol
        
    Returns:
        PrevisaoOutput: Previs√£o do pr√≥ximo pre√ßo
        
    Raises:
        HTTPException: Se ticker inv√°lido, dados insuficientes ou erro na previs√£o
    """
    # Inicializa loggers
    pred_logger = get_prediction_logger()
    metrics_logger = get_metrics_logger()
    
    # Incrementa contador de requisi√ß√µes
    metrics_logger.increment_request()
    
    # Marca in√≠cio do processamento
    start_time = time.time()
    
    # Validar se modelo e scaler est√£o carregados
    if model is None or scaler is None:
        metrics_logger.increment_error()
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Modelo n√£o est√° carregado. Aguarde a inicializa√ß√£o da API."
        )
    
    try:
        # Validar e normalizar ticker
        ticker = validar_ticker_format(previsao_input.ticker)
        
        # Buscar dados hist√≥ricos do Yahoo Finance (retorna fonte tamb√©m)
        dados_array, df_original, data_source = buscar_dados_historicos(
            ticker=ticker,
            dias=WINDOW_SIZE,
            validar=True
        )
        
        # Validar shape dos dados
        if dados_array.shape != (WINDOW_SIZE, NUM_FEATURES):
            metrics_logger.increment_error()
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Dados retornados com shape incorreto: {dados_array.shape}"
            )
        
        # Normalizar os dados usando o scaler
        dados_normalizados = scaler.transform(dados_array)
        
        # Reshape para formato esperado pelo modelo LSTM
        # Shape: (60, 5) -> (1, 60, 5)
        dados_lstm = dados_normalizados.reshape(1, WINDOW_SIZE, NUM_FEATURES)
        
        # Fazer previs√£o
        predicao_normalizada = model.predict(dados_lstm, verbose=0)
        
        # Desnormalizar a previs√£o
        # Criar array com shape correto para inverse_transform
        # Precisamos passar array (1, 5) onde apenas Close (√≠ndice 3) importa
        predicao_array = np.zeros((1, NUM_FEATURES))
        predicao_array[0, 3] = predicao_normalizada[0, 0]  # Close √© feature index 3
        
        # Desnormalizar
        predicao_real = scaler.inverse_transform(predicao_array)
        
        # Extrair valor previsto de Close
        valor_previsto = float(predicao_real[0, 3])
        
        # Calcular tempo de processamento
        processing_time = (time.time() - start_time) * 1000  # em ms
        
        # Obter informa√ß√µes do ticker
        info_ticker = obter_info_ticker(ticker)
        ticker_info_str = f" ({info_ticker['nome']})" if info_ticker else ""
        
        # Formatar data dos dados (verificar se index √© datetime)
        try:
            if hasattr(df_original.index[-1], 'strftime'):
                data_str = df_original.index[-1].strftime('%Y-%m-%d')
            else:
                data_str = "dados de fallback"
        except:
            data_str = "dados hist√≥ricos"
        
        # Log estruturado da previs√£o
        input_for_log = dados_lstm[0].tolist()  # Shape: (60, 5)
        
        request_id = pred_logger.log_prediction(
            input_data=input_for_log,
            prediction=valor_previsto,
            processing_time_ms=processing_time,
            data_source=data_source  # Adicionar fonte dos dados
        )
        
        # Registrar previs√£o no sistema de monitoramento (Fase 12)
        try:
            monitor = PerformanceMonitor(ticker=ticker)
            monitor.register_prediction(
                prediction_value=valor_previsto,
                prediction_date=datetime.now().isoformat(),
                request_id=request_id
            )
        except Exception as mon_error:
            # N√£o falhar a previs√£o se monitoramento falhar
            print(f"‚ö†Ô∏è  Erro ao registrar no monitoramento: {mon_error}")
        
        # Retornar resposta
        return PrevisaoOutput(
            preco_previsto=round(valor_previsto, 2),
            confianca="alta",
            mensagem=f"Previs√£o para {ticker}{ticker_info_str} gerada com sucesso. "
                    f"Modelo MAPE 1.53%. Dados at√©: {data_str} "
                    f"[ID: {request_id}]"
        )
        
    except HTTPException:
        # Re-lan√ßar exce√ß√µes HTTP (j√° tratadas)
        raise
        
    except Exception as e:
        # Capturar qualquer outro erro
        metrics_logger.increment_error()
        
        # Log do erro
        pred_logger.log_error(
            error_message=str(e),
            input_data={"ticker": previsao_input.ticker}
        )
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao processar previs√£o autom√°tica: {str(e)}"
        )


@app.get(
    "/predict/example",
    response_model=PrevisaoOutput,
    summary="Previs√£o com Dados de Exemplo",
    description="Gera previs√£o usando dados de exemplo pr√©-carregados (demonstra√ß√£o)",
    tags=["Previs√£o"],
    status_code=status.HTTP_200_OK
)
async def fazer_previsao_exemplo() -> PrevisaoOutput:
    """
    Endpoint de demonstra√ß√£o com dados de exemplo pr√©-carregados.
    
    N√£o requer nenhum input - usa dados de teste reais salvos.
    Ideal para testar rapidamente a API sem precisar fornecer dados.
    
    Returns:
        PrevisaoOutput: Previs√£o do pr√≥ximo pre√ßo
        
    Raises:
        HTTPException: Se modelo n√£o carregado ou dados de exemplo n√£o dispon√≠veis
    """
    # Inicializa loggers
    pred_logger = get_prediction_logger()
    metrics_logger = get_metrics_logger()
    
    # Incrementa contador
    metrics_logger.increment_request()
    
    # Marca in√≠cio
    start_time = time.time()
    
    # Validar se modelo e dados est√£o carregados
    if model is None or scaler is None:
        metrics_logger.increment_error()
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Modelo n√£o est√° carregado. Aguarde a inicializa√ß√£o da API."
        )
    
    if example_data is None:
        metrics_logger.increment_error()
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Dados de exemplo n√£o dispon√≠veis. Execute: python generate_example_data.py"
        )
    
    try:
        # Usar dados de exemplo (j√° est√£o normalizados)
        # Shape: (60, 5) -> (1, 60, 5)
        dados_lstm = example_data.reshape(1, WINDOW_SIZE, NUM_FEATURES)
        
        # Fazer previs√£o
        predicao_normalizada = model.predict(dados_lstm, verbose=0)
        
        # Desnormalizar
        predicao_array = np.zeros((1, NUM_FEATURES))
        predicao_array[0, 3] = predicao_normalizada[0, 0]
        predicao_real = scaler.inverse_transform(predicao_array)
        valor_previsto = float(predicao_real[0, 3])
        
        # Tempo de processamento
        processing_time = (time.time() - start_time) * 1000
        
        # Log
        input_for_log = dados_lstm[0].tolist()
        request_id = pred_logger.log_prediction(
            input_data=input_for_log,
            prediction=valor_previsto,
            processing_time_ms=processing_time
        )
        
        # Retornar resposta
        return PrevisaoOutput(
            preco_previsto=round(valor_previsto, 2),
            confianca="alta",
            mensagem=f"Previs√£o de exemplo gerada com sucesso. "
                    f"Usando dados reais do conjunto de teste. "
                    f"Modelo MAPE 1.53%. [ID: {request_id}]"
        )
        
    except Exception as e:
        metrics_logger.increment_error()
        pred_logger.log_error(
            error_message=str(e),
            input_data=None
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao processar previs√£o de exemplo: {str(e)}"
        )


@app.get(
    "/metrics",
    summary="M√©tricas do Modelo",
    description="Retorna as m√©tricas de performance do modelo no conjunto de teste",
    tags=["Modelo"]
)
async def obter_metricas() -> Dict[str, Any]:
    """
    Retorna as m√©tricas de performance do modelo.
    
    Returns:
        Dict contendo as m√©tricas de avalia√ß√£o
    """
    if model is None or scaler is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Modelo n√£o est√° carregado."
        )
    
    return {
        "metricas_teste": {
            "RMSE": {
                "valor": "R$ 0.26",
                "descricao": "Raiz do Erro Quadr√°tico M√©dio"
            },
            "MAE": {
                "valor": "R$ 0.20",
                "descricao": "Erro Absoluto M√©dio"
            },
            "MAPE": {
                "valor": "1.53%",
                "descricao": "Erro Percentual Absoluto M√©dio",
                "interpretacao": "EXCELENTE (< 2%)"
            },
            "R2": {
                "valor": "0.9351",
                "descricao": "Coeficiente de Determina√ß√£o",
                "interpretacao": "Modelo explica 93.51% da vari√¢ncia"
            }
        },
        "parametros_modelo": {
            "window_size": 60,
            "num_features": 5,
            "camadas": "LSTM(64) + Dropout(0.2) + LSTM(32) + Dense(1)",
            "total_parametros": 30369
        },
        "dados_treinamento": {
            "periodo": "2020-11-03 a 2025-10-31",
            "total_dias": 1246,
            "sequencias_geradas": 1186,
            "divisao": {
                "treino": "70% (830 sequ√™ncias)",
                "validacao": "15% (177 sequ√™ncias)",
                "teste": "15% (179 sequ√™ncias)"
            }
        }
    }


# ============================================================
# ENDPOINTS DE MONITORAMENTO DE PERFORMANCE
# ============================================================

@app.post(
    "/monitoring/register",
    summary="Registrar Previs√£o para Monitoramento",
    description="Registra uma previs√£o para valida√ß√£o futura contra dados reais",
    tags=["Monitoramento"]
)
async def registrar_previsao_monitoramento(
    prediction_value: float,
    ticker: str = "B3SA3.SA",
    request_id: str = None
) -> Dict[str, Any]:
    """
    Registra uma previs√£o no sistema de monitoramento para valida√ß√£o posterior.
    
    Args:
        prediction_value: Valor previsto
        ticker: S√≠mbolo da a√ß√£o
        request_id: ID da requisi√ß√£o
    
    Returns:
        Confirma√ß√£o do registro
    """
    try:
        monitor = PerformanceMonitor(ticker=ticker)
        monitor.register_prediction(
            prediction_value=prediction_value,
            prediction_date=datetime.now().isoformat(),
            request_id=request_id
        )
        
        return {
            "status": "success",
            "message": "Previs√£o registrada para monitoramento",
            "prediction_value": prediction_value,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao registrar previs√£o: {str(e)}"
        )


@app.get(
    "/monitoring/performance",
    summary="M√©tricas de Performance em Produ√ß√£o",
    description="Retorna m√©tricas de valida√ß√£o de previs√µes contra valores reais",
    tags=["Monitoramento"]
)
async def obter_performance_producao(ticker: str = "B3SA3.SA") -> Dict[str, Any]:
    """
    Retorna m√©tricas de performance do modelo em produ√ß√£o.
    
    Compara previs√µes realizadas com valores reais do mercado.
    
    Args:
        ticker: S√≠mbolo da a√ß√£o
    
    Returns:
        M√©tricas de performance e hist√≥rico
    """
    try:
        monitor = PerformanceMonitor(ticker=ticker)
        
        # Carrega hist√≥rico de m√©tricas
        metrics_history = monitor.metrics_history
        
        # Carrega previs√µes (validadas e pendentes)
        predictions_db = monitor.predictions_db
        
        # Conta previs√µes por status
        validated = [p for p in predictions_db.get("predictions", []) if p.get("validated")]
        pending = [p for p in predictions_db.get("predictions", []) if not p.get("validated")]
        
        # Calcula estat√≠sticas das validadas
        if validated:
            errors = [p.get("error", 0) for p in validated if p.get("error") is not None]
            error_pcts = [p.get("error_pct", 0) for p in validated if p.get("error_pct") is not None]
            
            stats = {
                "total_validated": len(validated),
                "total_pending": len(pending),
                "mae": float(np.mean(errors)) if errors else None,
                "mape": float(np.mean(error_pcts)) if error_pcts else None,
                "rmse": float(np.sqrt(np.mean([e**2 for e in errors]))) if errors else None,
                "min_error_pct": float(min(error_pcts)) if error_pcts else None,
                "max_error_pct": float(max(error_pcts)) if error_pcts else None,
                "avg_predicted": float(np.mean([p.get("predicted_value", 0) for p in validated])),
                "avg_actual": float(np.mean([p.get("actual_value", 0) for p in validated if p.get("actual_value")])) if any(p.get("actual_value") for p in validated) else None
            }
        else:
            stats = {
                "total_validated": 0,
                "total_pending": len(pending),
                "mae": None,
                "mape": None,
                "rmse": None,
                "min_error_pct": None,
                "max_error_pct": None,
                "avg_predicted": None,
                "avg_actual": None
            }
        
        return {
            "ticker": ticker,
            "timestamp": datetime.now().isoformat(),
            "summary": metrics_history.get("summary", {}),
            "statistics": stats,
            "daily_metrics": metrics_history.get("daily_metrics", [])[-30:],  # √öltimos 30 dias
            "recent_predictions": [
                {
                    "request_id": p.get("request_id"),
                    "timestamp": p.get("timestamp"),
                    "predicted": p.get("predicted_value"),
                    "actual": p.get("actual_value"),
                    "error_pct": p.get("error_pct"),
                    "validated": p.get("validated")
                }
                for p in sorted(
                    predictions_db.get("predictions", []),
                    key=lambda x: x.get("timestamp", ""),
                    reverse=True
                )[:20]  # √öltimas 20 previs√µes
            ]
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao obter m√©tricas de performance: {str(e)}"
        )


@app.post(
    "/monitoring/validate",
    summary="Validar Previs√µes Pendentes",
    description="Executa valida√ß√£o de previs√µes pendentes contra dados reais do mercado",
    tags=["Monitoramento"]
)
async def validar_previsoes_pendentes(
    ticker: str = "B3SA3.SA",
    days_back: int = 7
) -> Dict[str, Any]:
    """
    Valida previs√µes pendentes comparando com dados reais.
    
    Args:
        ticker: S√≠mbolo da a√ß√£o
        days_back: Quantos dias atr√°s buscar dados reais
    
    Returns:
        Resultado da valida√ß√£o
    """
    try:
        monitor = PerformanceMonitor(ticker=ticker)
        result = monitor.validate_predictions(days_back=days_back)
        
        # Detecta degrada√ß√£o
        degradation = monitor.detect_degradation(threshold_mape=5.0)
        
        return {
            "status": "success",
            "ticker": ticker,
            "timestamp": datetime.now().isoformat(),
            "validation_result": result,
            "degradation_detected": degradation,
            "message": "Valida√ß√£o conclu√≠da com sucesso"
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao validar previs√µes: {str(e)}"
        )


if __name__ == "__main__":
    import uvicorn
    
    print("=" * 60)
    print("   API de Previs√£o B3SA3.SA - LSTM")
    print("=" * 60)
    print("\nüöÄ Iniciando servidor de desenvolvimento...\n")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
