# Guia de Execu√ß√£o - Fase 4: Treinamento e Avalia√ß√£o do Modelo

## üìã Objetivo da Fase 4

Treinar o modelo LSTM com os dados preparados, utilizando t√©cnicas de Early Stopping e Model Checkpoint, avaliar o desempenho em dados de teste, calcular m√©tricas de performance (RMSE, MAE, MAPE, R¬≤) e gerar visualiza√ß√µes dos resultados.

---

## üîß Pr√©-requisitos

### 1. Fases Anteriores Conclu√≠das

Certifique-se de que as fases anteriores foram executadas com sucesso:

```bash
# Verificar dados preparados (Fase 2)
ls data/processed/X_train.npy
ls data/processed/y_train.npy
ls data/processed/X_val.npy
ls data/processed/y_val.npy
ls data/processed/X_test.npy
ls data/processed/y_test.npy

# Verificar scaler (Fase 2)
ls models/scaler.pkl
```

### 2. Depend√™ncias Instaladas
As bibliotecas necess√°rias j√° devem estar instaladas do requirements.txt:
- tensorflow/keras
- numpy
- scikit-learn
- matplotlib
- seaborn
- joblib

---

## üöÄ Executar Fase 4

### Comando de Execu√ß√£o
```bash
python src/model_training.py
```

### Tempo Estimado
- **CPU**: 1-3 minutos
- **GPU**: 30-60 segundos

---

## üì§ Sa√≠das Esperadas

Ap√≥s a execu√ß√£o bem-sucedida, os seguintes arquivos ser√£o criados:

### 1. Modelo Treinado
**Localiza√ß√£o**: `models/lstm_model_best.h5`
- **Formato**: HDF5 (Keras)
- **Conte√∫do**: Arquitetura + Pesos + Configura√ß√£o de compila√ß√£o
- **Tamanho**: ~0.4 MB
- **Descri√ß√£o**: Melhor modelo salvo durante o treinamento (menor val_loss)

### 2. Resultados do Treinamento
**Localiza√ß√£o**: `docs/training/training_results.json`
- **Conte√∫do**:
  - Configura√ß√µes de treinamento (√©pocas, batch_size)
  - Hist√≥rico de loss e m√©tricas por √©poca
  - M√©tricas finais no conjunto de teste
  - Interpreta√ß√£o dos resultados
- **Tamanho**: ~8 KB

### 3. Curvas de Aprendizado
**Localiza√ß√£o**: `docs/training/curvas_aprendizado.png`
- **Conte√∫do**: Gr√°fico com 2 pain√©is
  - Painel 1: Loss (MSE) por √©poca (treino vs valida√ß√£o)
  - Painel 2: MAE por √©poca (treino vs valida√ß√£o)
- **Formato**: PNG (alta resolu√ß√£o: 300 DPI)
- **Tamanho**: ~100-200 KB

### 4. Gr√°fico de Predi√ß√µes
**Localiza√ß√£o**: `docs/training/resultado_teste.png`
- **Conte√∫do**: Gr√°fico com 2 pain√©is
  - Painel 1: S√©rie temporal (Pre√ßo Real vs Previsto)
  - Painel 2: Scatter plot (correla√ß√£o entre real e previsto)
- **Formato**: PNG (alta resolu√ß√£o: 300 DPI)
- **Tamanho**: ~150-250 KB

---

## üìä Configura√ß√µes de Treinamento

### Hiperpar√¢metros

| Par√¢metro | Valor | Descri√ß√£o |
|-----------|-------|-----------|
| **√âpocas** | 50 | N√∫mero m√°ximo de √©pocas |
| **Batch Size** | 32 | Amostras processadas por itera√ß√£o |
| **Otimizador** | Adam | Taxa de aprendizado adaptativa |
| **Learning Rate** | 0.001 | Taxa de aprendizado inicial |
| **Loss Function** | MSE | Mean Squared Error |
| **M√©trica** | MAE | Mean Absolute Error |

### Callbacks Configurados

#### 1. Early Stopping
- **Monitor**: val_loss
- **Paci√™ncia**: 10 √©pocas
- **Modo**: min (minimizar val_loss)
- **Restaurar Melhores Pesos**: True
- **Fun√ß√£o**: Interrompe treinamento se val_loss n√£o melhorar

#### 2. Model Checkpoint
- **Monitor**: val_loss
- **Modo**: min
- **Salvar Apenas o Melhor**: True
- **Arquivo**: models/lstm_model_best.h5
- **Fun√ß√£o**: Salva modelo quando val_loss melhora

#### 3. Reduce Learning Rate on Plateau
- **Monitor**: val_loss
- **Fator**: 0.5 (reduz LR pela metade)
- **Paci√™ncia**: 5 √©pocas
- **Modo**: min
- **LR M√≠nimo**: 1e-7
- **Fun√ß√£o**: Reduz taxa de aprendizado quando val_loss estagna

---

## üìà M√©tricas de Avalia√ß√£o

### M√©tricas Calculadas no Conjunto de Teste

#### MSE (Mean Squared Error)
- **F√≥rmula**: `MSE = (1/n) * Œ£(y_true - y_pred)¬≤`
- **Unidade**: R$¬≤
- **Interpreta√ß√£o**: Penaliza erros grandes quadraticamente

#### RMSE (Root Mean Squared Error)
- **F√≥rmula**: `RMSE = ‚àöMSE`
- **Unidade**: R$
- **Interpreta√ß√£o**: Erro m√©dio na mesma escala dos pre√ßos
- **Valor Esperado**: < R$ 0.50

#### MAE (Mean Absolute Error)
- **F√≥rmula**: `MAE = (1/n) * Œ£|y_true - y_pred|`
- **Unidade**: R$
- **Interpreta√ß√£o**: Erro m√©dio absoluto
- **Valor Esperado**: < R$ 0.30

#### MAPE (Mean Absolute Percentage Error)
- **F√≥rmula**: `MAPE = (100/n) * Œ£|(y_true - y_pred) / y_true|`
- **Unidade**: %
- **Interpreta√ß√£o**: Erro percentual m√©dio
- **Valor Esperado**: < 5%

#### R¬≤ Score (Coeficiente de Determina√ß√£o)
- **F√≥rmula**: `R¬≤ = 1 - (SS_res / SS_tot)`
- **Range**: -‚àû a 1
- **Interpreta√ß√£o**: Propor√ß√£o da vari√¢ncia explicada pelo modelo
- **Valor Esperado**: > 0.85

---

## üéØ Resultados Alcan√ßados

### Performance do Modelo

| M√©trica | Valor Obtido | Avalia√ß√£o |
|---------|--------------|-----------|
| **RMSE** | R$ 0.26 | ‚úÖ Excelente |
| **MAE** | R$ 0.20 | ‚úÖ Excelente |
| **MAPE** | 1.53% | ‚úÖ Excelente (< 2%) |
| **R¬≤ Score** | 0.9351 | ‚úÖ Excelente (93.5%) |
| **Erro % vs Pre√ßo M√©dio** | 2.00% | ‚úÖ Excelente (< 5%) |

### Informa√ß√µes do Treinamento

- **√âpocas Executadas**: 49 de 50
- **Early Stopping**: Ativado na √©poca 39
- **Melhor √âpoca**: 39
- **Best val_loss**: 0.000811
- **Dura√ß√£o**: ~28 segundos
- **Overfitting**: N√£o detectado

### Estat√≠sticas dos Dados de Teste

- **Pre√ßo M√©dio**: R$ 12.83
- **Pre√ßo M√≠nimo**: R$ 10.23
- **Pre√ßo M√°ximo**: R$ 14.78
- **Amostras de Teste**: 179 dias

---

## üìä Sa√≠da Esperada no Console

```
======================================================================
FASE 4: TREINAMENTO E AVALIA√á√ÉO DO MODELO LSTM
======================================================================

üìÇ Carregando Dados Preparados:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

   ‚úÖ X_train    carregado - Shape: (830, 60, 5)
   ‚úÖ y_train    carregado - Shape: (830,)
   ‚úÖ X_val      carregado - Shape: (177, 60, 5)
   ‚úÖ y_val      carregado - Shape: (177,)
   ‚úÖ X_test     carregado - Shape: (179, 60, 5)
   ‚úÖ y_test     carregado - Shape: (179,)

üîÑ Carregando Scaler:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

   ‚úÖ Scaler carregado: models\scaler.pkl
   üìä Range de normaliza√ß√£o: (0, 1)

‚öôÔ∏è  Configurando Callbacks:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

   ‚úÖ Early Stopping configurado:
      ‚Ä¢ Monitor: val_loss
      ‚Ä¢ Paci√™ncia: 10 √©pocas
      ‚Ä¢ Restaurar melhores pesos: True

   ‚úÖ Model Checkpoint configurado:
      ‚Ä¢ Salvando em: models\lstm_model_best.h5
      ‚Ä¢ Monitor: val_loss
      ‚Ä¢ Salvar apenas o melhor: True

   ‚úÖ Reduce LR on Plateau configurado:
      ‚Ä¢ Monitor: val_loss
      ‚Ä¢ Fator de redu√ß√£o: 0.5
      ‚Ä¢ Paci√™ncia: 5 √©pocas

üöÄ Iniciando Treinamento:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

   üìä Configura√ß√µes:
      ‚Ä¢ √âpocas: 50
      ‚Ä¢ Batch Size: 32
      ‚Ä¢ Amostras de Treino: 830
      ‚Ä¢ Amostras de Valida√ß√£o: 177

Epoch 1/50
26/26 [==============================] - 3s - loss: 0.0242 - mae: 0.1128 - val_loss: 0.0056 - val_mae: 0.0640
Epoch 2/50
26/26 [==============================] - 1s - loss: 0.0059 - mae: 0.0610 - val_loss: 0.0031 - val_mae: 0.0421
...
Epoch 39/50
26/26 [==============================] - 1s - loss: 0.0017 - mae: 0.0323 - val_loss: 8.1145e-04 - val_mae: 0.0209
...
Epoch 49: early stopping

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚úÖ Treinamento Conclu√≠do!
   ‚è±Ô∏è  Dura√ß√£o: 27.67 segundos (0.46 minutos)
   üìà √âpocas executadas: 49

üìè Calculando M√©tricas de Desempenho:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

   üìä M√©tricas em Escala Original (R$):
      ‚Ä¢ MSE (Mean Squared Error):           0.0656
      ‚Ä¢ RMSE (Root Mean Squared Error):     0.2561
      ‚Ä¢ MAE (Mean Absolute Error):          0.1987
      ‚Ä¢ MAPE (Mean Abs Percentage Error):     1.53%
      ‚Ä¢ R¬≤ Score:                           0.9351

   üìà Estat√≠sticas dos Dados de Teste:
      ‚Ä¢ Pre√ßo M√©dio:   R$      12.83
      ‚Ä¢ Pre√ßo M√≠nimo:  R$      10.23
      ‚Ä¢ Pre√ßo M√°ximo:  R$      14.78

   üéØ An√°lise de Erro:
      ‚Ä¢ RMSE vs Pre√ßo M√©dio: 2.00%
      ‚Ä¢ Avalia√ß√£o: ‚úÖ Excelente (< 5%)

======================================================================
‚úÖ FASE 4 CONCLU√çDA COM SUCESSO!
======================================================================

üìÅ Arquivos gerados:
   ‚Üí models/lstm_model_best.h5
   ‚Üí docs/training/training_results.json
   ‚Üí docs/training/curvas_aprendizado.png
   ‚Üí docs/training/resultado_teste.png

üìä Resumo de Desempenho:
   ‚Üí RMSE: R$ 0.26
   ‚Üí MAE:  R$ 0.20
   ‚Üí MAPE: 1.53%
   ‚Üí R¬≤ Score: 0.9351

üéØ Pr√≥ximos passos:
   ‚Üí An√°lise detalhada dos resultados
   ‚Üí Ajuste de hiperpar√¢metros se necess√°rio
   ‚Üí Prepara√ß√£o para deploy (Fase 5)
```

---

## üîç Interpreta√ß√£o dos Resultados

### Qualidade do Modelo: EXCELENTE ‚úÖ

#### 1. Precis√£o Not√°vel
- **MAPE de 1.53%**: Em m√©dia, o modelo erra apenas 1.53% do valor real
- **MAE de R$ 0.20**: Erro m√©dio de apenas 20 centavos por a√ß√£o
- **Conclus√£o**: Capacidade excepcional de prever pre√ßos de fechamento

#### 2. Capacidade Explicativa
- **R¬≤ de 0.9351**: O modelo explica 93.5% da vari√¢ncia dos dados
- **Interpreta√ß√£o**: Excelente captura dos padr√µes temporais
- **Conclus√£o**: Alta confiabilidade nas previs√µes

#### 3. Generaliza√ß√£o
- **Gap treino-valida√ß√£o < 10%**: Sem overfitting significativo
- **Curvas convergentes**: Modelo generalizou bem
- **Conclus√£o**: Desempenho ser√° mantido em dados futuros

#### 4. Erro Relativo Baixo
- **2% de erro vs pre√ßo m√©dio**: Altamente aceit√°vel
- **Range de pre√ßos**: R$ 10.23 - R$ 14.78
- **Conclus√£o**: Modelo confi√°vel para previs√µes de curto prazo

---

## üîç Valida√ß√£o da Execu√ß√£o

### Verificar Modelo Salvo
```bash
# Verificar tamanho do modelo
ls -lh models/lstm_model_best.h5

# Deve mostrar ~0.4 MB
```

### Verificar Resultados
```bash
# Ver m√©tricas finais
cat docs/training/training_results.json | grep -A 10 "metricas_teste"
```

### Verificar Gr√°ficos
```bash
# Listar visualiza√ß√µes
ls -lh docs/training/*.png

# Deve mostrar:
# - curvas_aprendizado.png
# - resultado_teste.png
```

---

## üö® Solu√ß√£o de Problemas

### Erro: "No module named 'tensorflow'"
```bash
pip install tensorflow==2.15.1
```

### Erro: "FileNotFoundError: X_train.npy"
- **Causa**: Fase 2 n√£o foi executada
- **Solu√ß√£o**: Execute `python src/data_preparation.py` primeiro

### Aviso: "Learning rate reduced"
- **Natureza**: Normal (ReduceLROnPlateau funcionando)
- **Significado**: Taxa de aprendizado ajustada automaticamente
- **A√ß√£o**: Pode ignorar

### Performance Ruim (MAPE > 10%)
- **Causa**: Poss√≠veis problemas nos dados ou hiperpar√¢metros
- **Solu√ß√µes**:
  1. Verificar qualidade dos dados da Fase 1
  2. Aumentar n√∫mero de √©pocas
  3. Ajustar arquitetura (mais neur√¥nios/camadas)
  4. Aumentar timesteps (de 60 para 90 dias)

---

## ‚úÖ Checklist de Verifica√ß√£o

- [ ] Fases 1, 2 e 3 conclu√≠das
- [ ] Dados preparados dispon√≠veis (X_train, y_train, etc.)
- [ ] Script executado sem erros
- [ ] Modelo salvo em `models/lstm_model_best.h5`
- [ ] Resultados salvos em `training_results.json`
- [ ] Gr√°ficos gerados (curvas de aprendizado e predi√ß√µes)
- [ ] MAPE < 5% ‚úÖ
- [ ] R¬≤ Score > 0.85 ‚úÖ
- [ ] Early Stopping ativado
- [ ] Melhor modelo carregado

---

## üéØ Pr√≥ximos Passos

Ap√≥s concluir a Fase 4 com sucesso:

1. **Fase 5**: Persist√™ncia e Verifica√ß√£o do Modelo
   - Verificar artefatos salvos
   - Testar carregamento do modelo
   - Gerar metadados para API
   - Documentar especifica√ß√µes

```bash
# Pr√≥ximo comando
python src/model_persistence.py
```

---

## üìö Refer√™ncias

- [Keras Model Checkpoint](https://keras.io/api/callbacks/model_checkpoint/)
- [Early Stopping in Neural Networks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)
- [Understanding Learning Curves](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)
- [Regression Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)

---

**Data de Cria√ß√£o**: 02/11/2025  
**Vers√£o**: 1.0.0  
**Autor**: ArgusPortal
