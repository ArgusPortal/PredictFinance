# üìä Fase 8: Monitoramento do Modelo em Produ√ß√£o

**Projeto**: PredictFinance - Sistema de Previs√£o B3SA3.SA  
**Fase**: 8/8 - **FASE FINAL**  
**Status**: ‚úÖ Implementada  
**Data**: Novembro 2025

---

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Pr√©-requisitos](#pr√©-requisitos)
3. [Objetivos da Fase](#objetivos-da-fase)
4. [Componentes do Sistema](#componentes-do-sistema)
5. [1. Logging de Requisi√ß√µes](#1-logging-de-requisi√ß√µes)
6. [2. Monitoramento de Performance](#2-monitoramento-de-performance)
7. [3. Detec√ß√£o de Drift](#3-detec√ß√£o-de-drift)
8. [4. Sistema de Alertas](#4-sistema-de-alertas)
9. [5. Monitoramento de Uptime](#5-monitoramento-de-uptime)
10. [Integra√ß√£o com API](#integra√ß√£o-com-api)
11. [Testes do Sistema](#testes-do-sistema)
12. [Deploy e Produ√ß√£o](#deploy-e-produ√ß√£o)
13. [Automa√ß√£o (Cron Jobs)](#automa√ß√£o-cron-jobs)
14. [Troubleshooting](#troubleshooting)
15. [Checklist de Conclus√£o](#checklist-de-conclus√£o)

---

## üìñ Vis√£o Geral

A **Fase 8** implementa um **sistema completo de monitoramento** do modelo LSTM em produ√ß√£o, garantindo:

‚úÖ **Auditoria**: Logs detalhados de todas as previs√µes  
‚úÖ **Performance**: Acompanhamento cont√≠nuo de m√©tricas (MAE, MAPE)  
‚úÖ **Drift Detection**: Detec√ß√£o de mudan√ßas na distribui√ß√£o dos dados  
‚úÖ **Alertas**: Notifica√ß√µes autom√°ticas de degrada√ß√£o  
‚úÖ **Uptime**: Monitoramento de disponibilidade da API  

### üéØ Por Que Monitorar?

Modelos de ML em produ√ß√£o podem **degradar** ao longo do tempo devido a:

- üìâ **Concept Drift**: Padr√µes de mercado mudam
- üìä **Data Drift**: Distribui√ß√£o dos dados muda
- üîß **Performance Decay**: Acur√°cia diminui com o tempo
- üêõ **Bugs e Erros**: Falhas operacionais

O monitoramento permite detectar esses problemas **antes** que impactem os usu√°rios!

---

## üîß Pr√©-requisitos

### Depend√™ncias

Instale as depend√™ncias de monitoramento:

```bash
pip install -r requirements-monitoring.txt
```

**Conte√∫do** de `requirements-monitoring.txt`:
```
evidently==0.4.38      # Drift detection
scipy==1.11.4          # Testes estat√≠sticos
requests==2.31.0       # Alertas (Slack)
yfinance==0.2.36       # Dados em produ√ß√£o
```

### Fases Anteriores

‚úÖ Fase 1-6: Dados coletados, modelo treinado, API desenvolvida  
‚úÖ Fase 7: API deployada no Render.com  

---

## üéØ Objetivos da Fase

1. ‚úÖ **Logging Estruturado**: Registrar todas as requisi√ß√µes `/predict`
2. ‚úÖ **Performance Tracking**: Comparar previs√µes vs valores reais
3. ‚úÖ **Drift Detection**: Monitorar mudan√ßas nos dados de entrada
4. ‚úÖ **Alertas Autom√°ticos**: Notificar degrada√ß√£o do modelo
5. ‚úÖ **Uptime Monitoring**: Garantir disponibilidade da API

---

## üß© Componentes do Sistema

O sistema de monitoramento √© composto por **5 m√≥dulos**:

```
PredictFinance/
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ monitoring.py               # Logging de requisi√ß√µes
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ performance_monitor.py      # Monitor de performance
‚îÇ   ‚îú‚îÄ‚îÄ drift_detector.py           # Detector de drift
‚îÇ   ‚îî‚îÄ‚îÄ alert_system.py             # Sistema de alertas
‚îÇ
‚îú‚îÄ‚îÄ run_daily_monitoring.py         # Script de monitoramento di√°rio
‚îú‚îÄ‚îÄ test_monitoring.py              # Testes do sistema
‚îÇ
‚îú‚îÄ‚îÄ logs/                           # Logs gerados
‚îÇ   ‚îú‚îÄ‚îÄ predictions.log
‚îÇ   ‚îî‚îÄ‚îÄ metrics.log
‚îÇ
‚îî‚îÄ‚îÄ monitoring/                     # Dados de monitoramento
    ‚îú‚îÄ‚îÄ predictions_tracking.json
    ‚îú‚îÄ‚îÄ performance_metrics.json
    ‚îú‚îÄ‚îÄ reference_statistics.json
    ‚îú‚îÄ‚îÄ drift_reports.json
    ‚îú‚îÄ‚îÄ alert_history.json
    ‚îî‚îÄ‚îÄ daily_summary.json
```

---

## 1. Logging de Requisi√ß√µes

### üìù Objetivo

Registrar **todas** as previs√µes realizadas pela API para:
- Auditoria de uso
- An√°lise posterior
- Debugging
- Compliance

### üîç Implementa√ß√£o

**Arquivo**: `api/monitoring.py`

#### Classes Principais

**1. PredictionLogger**

```python
from api.monitoring import get_prediction_logger

logger = get_prediction_logger()

# Registra previs√£o
request_id = logger.log_prediction(
    input_data=input_array,      # Shape: (60, 5)
    prediction=12.45,             # Valor previsto
    processing_time_ms=25.3       # Lat√™ncia
)
```

**Sa√≠da em `logs/predictions.log`**:
```json
{
  "request_id": "a3f4b2c1",
  "timestamp": "2025-11-02T14:30:15.123456",
  "event": "prediction",
  "input_stats": {
    "mean": 12.34,
    "std": 0.56,
    "min": 11.20,
    "max": 13.10,
    "shape": [60, 5]
  },
  "prediction": 12.45,
  "processing_time_ms": 25.3,
  "status": "success"
}
```

**2. MetricsLogger**

Registra m√©tricas do sistema:

```python
from api.monitoring import get_metrics_logger

metrics_logger = get_metrics_logger()
metrics_logger.increment_request()  # Conta requisi√ß√£o
metrics_logger.increment_error()    # Conta erro
```

### üé® Estat√≠sticas ao Inv√©s de Dados Brutos

**Problema**: Logar 60 valores x 5 features = 300 n√∫meros por previs√£o (muito grande!)

**Solu√ß√£o**: Logar apenas estat√≠sticas resumidas:
- M√©dia (`mean`)
- Desvio padr√£o (`std`)
- M√≠nimo/M√°ximo (`min`, `max`)
- Mediana (`median`)
- Shape dos dados

Isso reduz o tamanho dos logs em **90%** mantendo informa√ß√£o √∫til!

### üìä Integra√ß√£o na API

A API FastAPI foi modificada para incluir logging autom√°tico:

**`api/main.py`** - Endpoint `/predict`:

```python
@app.post("/predict")
async def fazer_previsao(previsao_input: PrevisaoInput):
    # Inicializa loggers
    pred_logger = get_prediction_logger()
    metrics_logger = get_metrics_logger()
    
    # Conta requisi√ß√£o
    metrics_logger.increment_request()
    
    # Marca in√≠cio
    start_time = time.time()
    
    try:
        # ... processamento ...
        
        # Calcula tempo
        processing_time = (time.time() - start_time) * 1000
        
        # LOG DA PREVIS√ÉO
        request_id = pred_logger.log_prediction(
            input_data=input_data,
            prediction=valor_previsto,
            processing_time_ms=processing_time
        )
        
        return PrevisaoOutput(
            preco_previsto=valor_previsto,
            mensagem=f"Previs√£o OK [ID: {request_id}]"
        )
    
    except Exception as e:
        # LOG DO ERRO
        metrics_logger.increment_error()
        pred_logger.log_error(str(e), input_data)
        raise
```

### ‚úÖ Benef√≠cios

1. **Auditoria Completa**: Rastreabilidade de todas as previs√µes
2. **Debugging**: Identificar requisi√ß√µes problem√°ticas
3. **Analytics**: An√°lise de padr√µes de uso
4. **Compliance**: Atende requisitos regulat√≥rios

---

## 2. Monitoramento de Performance

### üìà Objetivo

Avaliar **continuamente** a qualidade das previs√µes comparando com valores reais.

### üîç Como Funciona

```
Dia 1: API prev√™ pre√ßo para Dia 2 ‚Üí Previs√£o = R$ 12.50
        ‚Üì (24 horas)
Dia 2: Mercado fecha ‚Üí Pre√ßo Real = R$ 12.45
        ‚Üì (valida√ß√£o)
Sistema: Calcula erro = |12.50 - 12.45| = R$ 0.05 (0.4%)
```

### üíª Implementa√ß√£o

**Arquivo**: `src/performance_monitor.py`

#### Classe Principal: PerformanceMonitor

**1. Registrar Previs√µes**

```python
from src.performance_monitor import PerformanceMonitor

monitor = PerformanceMonitor(window_days=7)

# Registra previs√£o para valida√ß√£o futura
monitor.register_prediction(
    prediction_value=12.50,
    prediction_date="2025-11-02T10:00:00",
    request_id="abc123"
)
```

**Salva em** `monitoring/predictions_tracking.json`:
```json
{
  "predictions": [
    {
      "request_id": "abc123",
      "timestamp": "2025-11-02T10:00:00",
      "predicted_value": 12.50,
      "validated": false,
      "actual_value": null,
      "error": null
    }
  ]
}
```

**2. Validar Previs√µes**

```python
# Executa valida√ß√£o (busca pre√ßos reais no yfinance)
result = monitor.validate_predictions(days_back=7)

print(f"Validadas: {result['validated']}")
print(f"Pendentes: {result['pending']}")
```

**Processo**:
1. L√™ previs√µes n√£o validadas
2. Para cada previs√£o:
   - Busca pre√ßo real do dia seguinte via `yfinance`
   - Calcula erro absoluto e percentual
   - Marca como validada
3. Salva resultados

**Sa√≠da**:
```
Validadas: 5 previs√µes
   ‚úÖ abc123: Previsto=12.50, Real=12.45, Erro=0.40%
   ‚úÖ def456: Previsto=12.60, Real=12.58, Erro=0.16%
   ...
```

**3. Calcular M√©tricas**

```python
# Calcula MAE, MAPE, RMSE
metrics = monitor.calculate_metrics()
```

**Output**:
```
üìä M√âTRICAS DE PERFORMANCE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Janela: √öltimos 7 dias
MAE:  0.0523
MAPE: 0.42%
RMSE: 0.0681
Erro M√≠nimo: 0.08%
Erro M√°ximo: 0.95%
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

**Salva em** `monitoring/performance_metrics.json`:
```json
{
  "daily_metrics": [
    {
      "timestamp": "2025-11-02T12:00:00",
      "window_days": 7,
      "mae": 0.0523,
      "mape": 0.42,
      "rmse": 0.0681,
      "total_validated": 35
    }
  ],
  "summary": {
    "last_update": "2025-11-02T12:00:00",
    "current_mae": 0.0523,
    "current_mape": 0.42
  }
}
```

**4. Detectar Degrada√ß√£o**

```python
# Verifica se MAPE excedeu threshold
is_degrading = monitor.detect_degradation(threshold_mape=5.0)

if is_degrading:
    print("‚ö†Ô∏è  ALERTA: Modelo degradando!")
```

**5. Analisar Tend√™ncia**

```python
# Analisa tend√™ncia dos √∫ltimos 7 dias
trend = monitor.get_performance_trend(days=7)

print(f"Tend√™ncia: {trend['trend']}")  # "improving", "stable", "degrading"
print(f"MAPE Inicial: {trend['initial_mape']:.2f}%")
print(f"MAPE Final: {trend['final_mape']:.2f}%")
```

### üîÑ Execu√ß√£o Di√°ria

O script `run_daily_monitoring.py` automatiza esse processo:

```bash
python run_daily_monitoring.py
```

**Sa√≠da Esperada**:
```
üîç MONITORAMENTO DI√ÅRIO DO MODELO B3SA3
üìÖ Data: 2025-11-02 12:00:00
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1Ô∏è‚É£  VALIDA√á√ÉO DE PERFORMANCE
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üìä Previs√µes pendentes: 5
üìà Baixando dados reais de B3SA3.SA...
   ‚úÖ abc123: Previsto=12.50, Real=12.45, Erro=0.40%
   ‚úÖ def456: Previsto=12.60, Real=12.58, Erro=0.16%
   ...

‚úÖ Validadas: 5 previs√µes
‚è≥ Pendentes: 2

üìä M√âTRICAS DE PERFORMANCE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Janela: √öltimos 7 dias
MAE:  0.0523
MAPE: 0.42%
RMSE: 0.0681
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìà Tend√™ncia de Performance:
   ‚û°Ô∏è  Status: STABLE
   MAPE Inicial: 0.45%
   MAPE Final: 0.42%
   MAPE M√©dio: 0.43%

‚úÖ Performance do modelo dentro do esperado
```

### ‚úÖ Benef√≠cios

1. **Feedback Cont√≠nuo**: Sabe se modelo est√° funcionando bem
2. **Detec√ß√£o Precoce**: Identifica degrada√ß√£o antes de piorar
3. **Decis√£o Data-Driven**: Baseada em m√©tricas reais, n√£o suposi√ß√µes
4. **Hist√≥rico**: Mant√©m registro de performance ao longo do tempo

---

## 3. Detec√ß√£o de Drift

### üåä O Que √© Data Drift?

**Data Drift** ocorre quando a **distribui√ß√£o estat√≠stica** dos dados muda ao longo do tempo.

**Exemplo no mercado financeiro**:
- **Treinamento (2020-2024)**: Pre√ßos entre R$ 10-15, m√©dia R$ 12.50
- **Produ√ß√£o (2025)**: Pre√ßos entre R$ 20-25, m√©dia R$ 22.50

O modelo foi treinado em um padr√£o, mas est√° recebendo **outro padr√£o** em produ√ß√£o!

### üîç Tipos de Drift

1. **Drift de Entrada (Input Drift)**: Features mudam
2. **Drift de Sa√≠da (Prediction Drift)**: Distribui√ß√£o das previs√µes muda
3. **Concept Drift**: Rela√ß√£o entre input e output muda

### üíª Implementa√ß√£o

**Arquivo**: `src/drift_detector.py`

#### Classe Principal: DriftDetector

**1. Configurar Refer√™ncia (Baseline)**

Primeiro, precisamos estabelecer **estat√≠sticas de refer√™ncia** dos dados de treinamento:

```python
from src.drift_detector import DriftDetector
import numpy as np

detector = DriftDetector(significance_level=0.05)

# Carrega dados de treinamento
train_data = np.load("data/processed/train_data.npy")  # Exemplo

# Configura refer√™ncia
detector.set_reference_statistics(train_data)
```

**Sa√≠da**:
```
üìä CALCULANDO ESTAT√çSTICAS DE REFER√äNCIA
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ Estat√≠sticas calculadas:
   Amostras: 830
   M√©dia: 12.3456
   Desvio Padr√£o: 0.7890
   Min/Max: 10.2000 / 14.5000
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

**Salva em** `monitoring/reference_statistics.json`:
```json
{
  "timestamp": "2025-11-02T10:00:00",
  "n_samples": 830,
  "mean": 12.3456,
  "std": 0.7890,
  "min": 10.2000,
  "max": 14.5000,
  "median": 12.3200,
  "q1": 11.8000,
  "q3": 12.9000,
  "iqr": 1.1000
}
```

**2. Detectar Drift**

```python
# Dados atuais de produ√ß√£o (√∫ltimos 100 valores)
current_data = np.array([12.5, 12.6, ..., 13.1])

# Detecta drift
report = detector.detect_drift(current_data, window_name="last_100_predictions")
```

**Testes Realizados**:

**A. Teste de Diferen√ßa de M√©dia**
```python
mean_diff_pct = |(atual - refer√™ncia)| / refer√™ncia * 100

if mean_diff_pct > 10%:
    drift_detected = True
```

**B. Teste de Diferen√ßa de Desvio Padr√£o**
```python
std_diff_pct = |(std_atual - std_ref)| / std_ref * 100

if std_diff_pct > 20%:
    drift_detected = True
```

**C. Teste Kolmogorov-Smirnov (KS)**

Compara distribui√ß√µes completas:
```python
from scipy.stats import ks_2samp

statistic, p_value = ks_2samp(reference_sample, current_data)

if p_value < 0.05:  # Signific√¢ncia 5%
    drift_detected = True  # Distribui√ß√µes s√£o diferentes
```

**Sa√≠da**:
```
üîç DETEC√á√ÉO DE DRIFT: last_100_predictions
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ö†Ô∏è  DRIFT DETECTADO!
   ‚Ä¢ M√©dia mudou 12.30%
   ‚Ä¢ KS test: p-value=0.0023 < 0.05

Compara√ß√µes:
   M√©dia: Ref=12.3456, Atual=13.8640 (Œî 12.30%)
   Std:   Ref=0.7890, Atual=0.9120 (Œî 15.59%)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

**Salva em** `monitoring/drift_reports.json`:
```json
{
  "reports": [
    {
      "timestamp": "2025-11-02T14:00:00",
      "window_name": "last_100_predictions",
      "drift_detected": true,
      "alerts": [
        "M√©dia mudou 12.30%",
        "KS test: p-value=0.0023 < 0.05"
      ],
      "current_stats": {
        "mean": 13.8640,
        "std": 0.9120
      },
      "reference_stats": {
        "mean": 12.3456,
        "std": 0.7890
      },
      "comparisons": {
        "mean_diff_pct": 12.30,
        "std_diff_pct": 15.59
      }
    }
  ]
}
```

**3. Monitorar Distribui√ß√£o de Previs√µes**

```python
# Lista de previs√µes recentes
predictions = [12.45, 12.50, 12.48, ..., 12.52]

# Analisa distribui√ß√£o
analysis = detector.monitor_prediction_distribution(predictions)

print(f"Outliers: {analysis['outliers']['count']}")
print(f"Porcentagem: {analysis['outliers']['percentage']:.1f}%")
```

Detecta valores **muito fora do padr√£o** usando boxplot (IQR method):

```
Outliers = valores < Q1 - 1.5*IQR  OU  valores > Q3 + 1.5*IQR
```

**4. Resumo de Drift**

```python
# √öltimos 7 dias
summary = detector.get_drift_summary(days=7)

print(f"Total de checagens: {summary['total_checks']}")
print(f"Drift detectado: {summary['drift_detected_count']} vezes")
print(f"Taxa de drift: {summary['drift_rate']:.1f}%")
```

### üîÑ Uso no Monitoramento Di√°rio

O script `run_daily_monitoring.py` executa drift detection automaticamente:

```bash
python run_daily_monitoring.py
```

**Sa√≠da**:
```
2Ô∏è‚É£  DETEC√á√ÉO DE DRIFT DE DADOS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üìä Resumo de Drift (√∫ltimos 7 dias):
   Checagens: 7
   Drift detectado: 2 vezes
   Taxa de drift: 28.6%
```

### üö® Quando Agir?

**Taxa de Drift > 50%**: Modelo est√° recebendo dados **muito diferentes** do treinamento
‚Üí **A√á√ÉO**: Re-treinar modelo com dados mais recentes

**M√©dia mudou > 10%**: Padr√£o de mercado mudou significativamente
‚Üí **A√á√ÉO**: Investigar causa e considerar re-treinamento

### ‚úÖ Benef√≠cios

1. **Detec√ß√£o Proativa**: Identifica problemas antes de afetar performance
2. **Explicabilidade**: Mostra **por qu√™** modelo est√° errando
3. **Decis√£o Informada**: Sabe quando re-treinar (n√£o √© "chute")
4. **Testes Estat√≠sticos**: Baseado em ci√™ncia, n√£o heur√≠sticas

---

## 4. Sistema de Alertas

### üîî Objetivo

Notificar automaticamente quando **thresholds** s√£o excedidos.

### üíª Implementa√ß√£o

**Arquivo**: `src/alert_system.py`

#### Thresholds Configur√°veis

```python
from src.alert_system import AlertThresholds

thresholds = AlertThresholds(
    mae_threshold=2.0,           # MAE m√°ximo (R$)
    mape_threshold=5.0,          # MAPE m√°ximo (%)
    drift_mean_pct=10.0,         # Mudan√ßa de m√©dia (%)
    drift_std_pct=20.0,          # Mudan√ßa de desvio (%)
    error_rate_threshold=0.05    # Taxa de erro (5%)
)
```

#### Classe Principal: AlertSystem

**1. Verificar M√©tricas de Performance**

```python
from src.alert_system import AlertSystem

alert_system = AlertSystem(thresholds)

# M√©tricas atuais
metrics = {
    "mae": 2.5,   # ACIMA do threshold (2.0)
    "mape": 6.0   # ACIMA do threshold (5.0)
}

# Verifica viola√ß√µes
violations = alert_system.check_performance_metrics(metrics)

print(violations)
# ['MAE alto: 2.5000 > 2.0', 'MAPE alto: 6.00% > 5.00%']
```

**2. Verificar Drift**

```python
drift_report = {
    "drift_detected": True,
    "alerts": ["M√©dia mudou 12.30%"]
}

violations = alert_system.check_drift_metrics(drift_report)
# ['Drift: M√©dia mudou 12.30%']
```

**3. Enviar Alertas**

```python
alert_system.send_alert(
    alert_type="performance_degradation",
    message="MAPE alto: 6.00% > 5.00%",
    severity="WARNING",
    metadata=metrics
)
```

**Sa√≠da (Logs)**:
```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ö†Ô∏è  ALERTA: PERFORMANCE_DEGRADATION
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Severidade: WARNING
Timestamp:  2025-11-02T14:30:00
Mensagem:   MAPE alto: 6.00% > 5.00%
Detalhes:   {
  "mae": 2.5,
  "mape": 6.0
}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

#### Canais de Notifica√ß√£o

**A. Logs (Padr√£o)**

Sempre ativado, registra em `logs/` e stdout.

**B. Slack (Opcional)**

```python
# Configurar webhook do Slack
from src.alert_system import configure_slack_webhook

configure_slack_webhook("https://hooks.slack.com/services/YOUR/WEBHOOK/URL")
```

**Formato da mensagem Slack**:
```
‚ö†Ô∏è  PERFORMANCE_DEGRADATION Alert

Severity: WARNING
Time: 2025-11-02T14:30:00

Message:
MAPE alto: 6.00% > 5.00%
```

**C. Email (Placeholder)**

Implementa√ß√£o b√°sica inclu√≠da. Para ativar:

1. Edite `monitoring/alert_config.json`:
```json
{
  "enable_email": true,
  "email_config": {
    "smtp_server": "smtp.gmail.com",
    "smtp_port": 587,
    "sender_email": "your-email@gmail.com",
    "receiver_emails": ["team@company.com"],
    "password": "your-app-password"
  }
}
```

2. Implemente envio SMTP em `_send_email_alert()`

#### Hist√≥rico de Alertas

```python
# Alertas das √∫ltimas 24 horas
recent = alert_system.get_recent_alerts(hours=24)

# Resumo
summary = alert_system.get_alert_summary()

print(f"Total de alertas: {summary['total_alerts']}")
print(f"Por tipo: {summary['by_type']}")
print(f"Por severidade: {summary['by_severity']}")
```

**Sa√≠da**:
```
Total de alertas: 15
Por tipo: {'performance_degradation': 5, 'data_drift': 8, 'error': 2}
Por severidade: {'WARNING': 12, 'CRITICAL': 3}
```

**Salva em** `monitoring/alert_history.json`

### üîÑ Integra√ß√£o no Monitoramento Di√°rio

```python
# Script: run_daily_monitoring.py

# 1. Calcula m√©tricas
metrics = perf_monitor.calculate_metrics()

# 2. Verifica violations
violations = alert_system.check_performance_metrics(metrics)

# 3. Envia alertas se necess√°rio
if violations:
    for violation in violations:
        alert_system.send_alert(
            alert_type="performance_degradation",
            message=violation,
            severity="WARNING"
        )
```

### üìä Plano de A√ß√£o

Quando **alerta** √© disparado:

1. **Investigar Causa**:
   - Logs de previs√µes
   - Dados de entrada
   - Drift reports

2. **Validar Problema**:
   - Confirmar degrada√ß√£o em m√∫ltiplas m√©tricas
   - Verificar tend√™ncia (n√£o √© anomalia pontual)

3. **Tomar A√ß√£o**:
   - **MAPE > 5%**: Re-treinar modelo
   - **Drift > 50%**: Coletar dados recentes e re-treinar
   - **Error Rate Alto**: Investigar bugs na API

### ‚úÖ Benef√≠cios

1. **Proatividade**: Detecta problemas em horas (n√£o semanas)
2. **Automa√ß√£o**: N√£o depende de checagem manual
3. **Escal√°vel**: Funciona 24/7
4. **Rastre√°vel**: Hist√≥rico de todos os alertas

---

## 5. Monitoramento de Uptime

### üåê Objetivo

Garantir que a **API est√° dispon√≠vel e respondendo** 24/7.

### üîç Componentes

#### A. Endpoint de Health Check

J√° implementado na **Fase 6**:

```python
# api/main.py

@app.get("/health")
async def health_check():
    """Retorna status de sa√∫de da API."""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "model_loaded": model is not None,
        "scaler_loaded": scaler is not None
    }
```

**Teste**:
```bash
curl https://b3sa3-api.onrender.com/health
```

**Resposta**:
```json
{
  "status": "healthy",
  "timestamp": "2025-11-02T14:00:00",
  "model_loaded": true,
  "scaler_loaded": true
}
```

#### B. Monitoramento Externo (UptimeRobot)

**Servi√ßo Gratuito**: https://uptimerobot.com

**Setup**:

1. **Criar Conta** no UptimeRobot

2. **Adicionar Monitor**:
   - **Type**: HTTP(S)
   - **URL**: `https://b3sa3-api.onrender.com/health`
   - **Interval**: 5 minutos
   - **Alert Contacts**: Seu email

3. **Configurar Alertas**:
   - Email quando API cai
   - Email quando API volta

**Benef√≠cios**:
- ‚úÖ Monitoramento 24/7 externo
- ‚úÖ Alertas de downtime
- ‚úÖ Estat√≠sticas de uptime (%)
- ‚úÖ Hist√≥rico de indisponibilidade

#### C. Logs de Disponibilidade

O sistema de monitoramento tamb√©m registra disponibilidade:

```python
# Verifica health endpoint
import requests

response = requests.get("https://b3sa3-api.onrender.com/health", timeout=10)

if response.status_code == 200:
    print("‚úÖ API est√° UP")
else:
    print(f"‚ùå API est√° DOWN (status: {response.status_code})")
```

### üîÑ Comportamento do Free Tier (Render)

**Importante**: Render Free Tier tem **sleep mode**:

- Ap√≥s **15 minutos** sem requisi√ß√µes ‚Üí API "hiberna"
- Pr√≥xima requisi√ß√£o ‚Üí API "acorda" (leva ~30-60 segundos)
- Isso √© **normal** e n√£o √© downtime

**Solu√ß√£o**:

1. **Aceitar** (se o delay √© aceit√°vel)
2. **Ping Peri√≥dico**: Script que faz requisi√ß√£o a cada 10 min
3. **Upgrade** para plano pago (sem sleep)

**Script de Keep-Alive** (opcional):

```python
# keep_alive.py
import requests
import time

while True:
    try:
        requests.get("https://b3sa3-api.onrender.com/health")
        print("‚úÖ Ping enviado")
    except:
        print("‚ùå Falha no ping")
    
    time.sleep(600)  # 10 minutos
```

Execute em servidor 24/7 (n√£o no Render, pois dormiria tamb√©m):
```bash
nohup python keep_alive.py &
```

### üìä M√©tricas de Uptime

**Ideal**:
- **Uptime > 99.5%** (considerando sleep mode normal)
- **Response Time < 500ms** (quando acordada)
- **Error Rate < 1%**

**UptimeRobot** calcula automaticamente:
```
Last 30 days: 99.87% uptime
Average response time: 245ms
Downtimes: 2 (total 45 minutes)
```

### ‚úÖ Benef√≠cios

1. **Confiabilidade**: Sabe quando API est√° fora
2. **SLA**: Pode reportar uptime aos usu√°rios
3. **Debugging**: Identifica causas de downtime
4. **Compliance**: Atende requisitos de disponibilidade

---

## üîó Integra√ß√£o com API

### Modifica√ß√µes na API (Fase 8)

**Arquivo**: `api/main.py`

```python
# Imports adicionados
from api.monitoring import get_prediction_logger, get_metrics_logger
import time

# No endpoint /predict
@app.post("/predict")
async def fazer_previsao(previsao_input: PrevisaoInput):
    # Loggers
    pred_logger = get_prediction_logger()
    metrics_logger = get_metrics_logger()
    
    # Conta requisi√ß√£o
    metrics_logger.increment_request()
    
    # Tempo inicial
    start_time = time.time()
    
    try:
        # ... processamento da previs√£o ...
        
        # Calcula tempo
        processing_time = (time.time() - start_time) * 1000
        
        # LOG DA PREVIS√ÉO
        request_id = pred_logger.log_prediction(
            input_data=input_for_log,
            prediction=valor_previsto,
            processing_time_ms=processing_time
        )
        
        return PrevisaoOutput(
            preco_previsto=valor_previsto,
            mensagem=f"Previs√£o OK [ID: {request_id}]"
        )
    
    except Exception as e:
        # Conta erro
        metrics_logger.increment_error()
        
        # Log erro
        pred_logger.log_error(str(e), input_data)
        
        raise HTTPException(...)
```

### Testando Localmente

```bash
# 1. Instala depend√™ncias
pip install -r requirements-monitoring.txt

# 2. Inicia API
python run_api.py

# 3. Em outro terminal, faz requisi√ß√£o
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "prices": [12.1, 12.2, ..., 12.5]  # 60 valores
  }'

# 4. Verifica logs
cat logs/predictions.log

# Output:
# 2025-11-02 14:30:15 | INFO | {"request_id": "a3f4b2c1", ...}
```

---

## üß™ Testes do Sistema

### Script de Teste

**Arquivo**: `test_monitoring.py`

```bash
python test_monitoring.py
```

**Sa√≠da Esperada**:
```
üß™ TESTE DO SISTEMA DE MONITORAMENTO - FASE 8
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

TEST 1: Prediction Logging
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ Logged prediction with ID: a3f4b2c1
   Logs salvos em: logs/predictions.log
‚úÖ Logged error

TEST 2: Performance Monitor
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ Registered 2 test predictions
   Database: monitoring/predictions_tracking.json
‚úÖ Validation attempted
   Validated: 0
   Pending: 2

TEST 3: Drift Detector
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ Reference statistics set
‚úÖ Drift detection completed
   Similar data drift: False
   Different data drift: True
‚úÖ Prediction distribution analyzed
   Outliers: 0

TEST 4: Alert System
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ Performance check completed
   Violations found: 2
   ‚Ä¢ MAE alto: 2.5000 > 2.0
   ‚Ä¢ MAPE alto: 6.00% > 5.00%
‚úÖ Alert sent successfully

üìä Alert Summary:
   Total alerts: 1
   By type: {'test': 1}
   By severity: {'INFO': 1}

TEST 5: Integration Test
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
1Ô∏è‚É£  Prediction logged: a3f4b2c1
2Ô∏è‚É£  Prediction registered for validation
3Ô∏è‚É£  Drift detection: DETECTED
4Ô∏è‚É£  Alerts: None (system healthy)

‚úÖ Integration test completed successfully

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ TODOS OS TESTES PASSARAM!
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìÅ Arquivos gerados:
   ‚Ä¢ logs/predictions.log
   ‚Ä¢ logs/metrics.log
   ‚Ä¢ monitoring/predictions_tracking.json
   ‚Ä¢ monitoring/performance_metrics.json
   ‚Ä¢ monitoring/reference_statistics.json
   ‚Ä¢ monitoring/drift_reports.json
   ‚Ä¢ monitoring/alert_history.json
   ‚Ä¢ monitoring/alert_config.json
```

### Testes Manuais

**1. Testar Logging**

```python
from api.monitoring import get_prediction_logger
import numpy as np

logger = get_prediction_logger()
fake_input = np.random.rand(60, 5).tolist()

request_id = logger.log_prediction(
    input_data=fake_input,
    prediction=12.45,
    processing_time_ms=25.0
)

print(f"ID: {request_id}")

# Verifica logs/predictions.log
```

**2. Testar Performance Monitor**

```python
from src.performance_monitor import PerformanceMonitor

monitor = PerformanceMonitor()

# Registra previs√£o
monitor.register_prediction(12.50, request_id="test-001")

# Valida (precisa aguardar dados reais)
result = monitor.validate_predictions(days_back=1)
```

**3. Testar Drift Detector**

```python
from src.drift_detector import DriftDetector
import numpy as np

detector = DriftDetector()

# Configura refer√™ncia
ref_data = np.random.normal(12.0, 1.0, 1000)
detector.set_reference_statistics(ref_data)

# Detecta drift
current_data = np.random.normal(15.0, 1.5, 100)
report = detector.detect_drift(current_data, "test")

print(f"Drift: {report['drift_detected']}")
```

**4. Testar Alertas**

```python
from src.alert_system import AlertSystem, AlertThresholds

thresholds = AlertThresholds(mape_threshold=5.0)
alert_system = AlertSystem(thresholds)

metrics = {"mape": 6.0}  # Acima do threshold
violations = alert_system.check_performance_metrics(metrics)

for v in violations:
    alert_system.send_alert("test", v, "WARNING")
```

---

## üöÄ Deploy e Produ√ß√£o

### Atualizar API no Render

Ap√≥s modifica√ß√µes na API (`api/main.py`):

```bash
# 1. Commit
git add .
git commit -m "feat: Sistema de monitoramento (Fase 8)"

# 2. Push
git push origin main

# Render faz deploy autom√°tico (~5 min)
```

### Verificar Logs no Render

**Dashboard Render** ‚Üí Sua API ‚Üí **Logs**

Voc√™ ver√°:
```
INFO:     Started server process
INFO:     Waiting for application startup.
üöÄ Iniciando API...
üìÇ Carregando artefatos do modelo...
   ‚úÖ Modelo carregado com sucesso!
   ‚úÖ Scaler carregado com sucesso!
‚úÖ API pronta para receber requisi√ß√µes!

INFO:     Application startup complete.
```

Quando fizer requisi√ß√µes `/predict`:
```
2025-11-02 14:30:15 | INFO | {"request_id": "a3f4b2c1", "event": "prediction", ...}
```

### Baixar Logs do Render

Render n√£o persiste logs indefinidamente. Para salvar:

```bash
# Via dashboard: Logs ‚Üí Download
# Ou via CLI do Render (se instalado)
render logs --tail 1000 > logs_render.txt
```

### Configurar Monitoramento Di√°rio

**Op√ß√£o 1: Servidor Externo (Recomendado)**

Execute `run_daily_monitoring.py` em um servidor 24/7:

```bash
# Em seu servidor/VPS/computador pessoal

# Cron job (Linux/Mac)
crontab -e

# Adicione:
0 12 * * * cd /path/to/PredictFinance && /path/to/python run_daily_monitoring.py >> monitoring_cron.log 2>&1
# Executa todo dia √†s 12:00
```

**Op√ß√£o 2: GitHub Actions (Gr√°tis)**

```yaml
# .github/workflows/daily_monitoring.yml
name: Daily Model Monitoring

on:
  schedule:
    - cron: '0 12 * * *'  # 12:00 UTC diariamente
  workflow_dispatch:  # Permite execu√ß√£o manual

jobs:
  monitor:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-monitoring.txt
      
      - name: Run daily monitoring
        run: python run_daily_monitoring.py
      
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: monitoring-results
          path: monitoring/
```

**Op√ß√£o 3: Task Scheduler (Windows)**

1. Abra **Task Scheduler**
2. Create Task:
   - **Trigger**: Daily 12:00
   - **Action**: `python C:\path\to\run_daily_monitoring.py`

### Armazenamento de Dados

**Problema**: Render Free Tier √© **ef√™mero** (arquivos s√£o perdidos em redeploy)

**Solu√ß√µes**:

**A. Banco de Dados (PostgreSQL, MongoDB)**

Use banco gratuito (Supabase, MongoDB Atlas) para persistir:
- `predictions_tracking.json`
- `performance_metrics.json`
- `drift_reports.json`

**B. Object Storage (S3, Backblaze)**

Salve JSONs em cloud storage.

**C. Execute Monitoramento Externamente**

Monitore de fora do Render (GitHub Actions, seu computador).

### UptimeRobot Setup

1. **Acesse**: https://uptimerobot.com
2. **Create Account**
3. **Add Monitor**:
   - Friendly Name: `B3SA3 API`
   - URL: `https://b3sa3-api.onrender.com/health`
   - Monitoring Interval: 5 minutes
   - Monitor Type: HTTP(S)
   - Alert Contacts: seu email
4. **Save**

Voc√™ receber√° email se API ficar offline > 5 min.

---

## ‚è∞ Automa√ß√£o (Cron Jobs)

### Linux/Mac

```bash
# Edita crontab
crontab -e

# Adiciona jobs:

# Monitoramento di√°rio √†s 12:00
0 12 * * * cd /path/to/PredictFinance && python run_daily_monitoring.py >> monitoring.log 2>&1

# Valida√ß√£o de previs√µes √†s 18:00 (ap√≥s mercado fechar)
0 18 * * * cd /path/to/PredictFinance && python -c "from src.performance_monitor import PerformanceMonitor; m=PerformanceMonitor(); m.validate_predictions(days_back=1)"

# Backup semanal (domingo 00:00)
0 0 * * 0 cd /path/to/PredictFinance && tar -czf backups/monitoring_$(date +\%Y\%m\%d).tar.gz monitoring/
```

### Windows (Task Scheduler)

**PowerShell Script** (`daily_monitoring.ps1`):
```powershell
cd C:\path\to\PredictFinance
& "C:\path\to\python.exe" run_daily_monitoring.py
```

**Task Scheduler**:
1. Open Task Scheduler
2. Create Basic Task:
   - **Name**: Daily Model Monitoring
   - **Trigger**: Daily 12:00 PM
   - **Action**: Start a program
     - **Program**: `powershell.exe`
     - **Arguments**: `-File C:\path\to\daily_monitoring.ps1`

### GitHub Actions (Gr√°tis, Cloud)

Crie `.github/workflows/monitoring.yml`:

```yaml
name: Daily Monitoring

on:
  schedule:
    - cron: '0 12 * * *'  # 12:00 UTC
  workflow_dispatch:

jobs:
  monitor:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install deps
        run: |
          pip install -r requirements.txt
          pip install -r requirements-monitoring.txt
      
      - name: Run monitoring
        run: python run_daily_monitoring.py
      
      - name: Commit results
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add monitoring/
          git commit -m "chore: Update monitoring data" || echo "No changes"
          git push
```

**Importante**: GitHub Actions tem **limite de 2000 min/m√™s** (gr√°tis).
Rodando 1x/dia = ~30 min/m√™s = OK!

---

## üîß Troubleshooting

### Problema 1: Logs n√£o sendo criados

**Sintoma**: `logs/predictions.log` n√£o existe

**Causa**: Permiss√µes ou diret√≥rio n√£o criado

**Solu√ß√£o**:
```python
# monitoring.py cria diret√≥rio automaticamente
LOGS_DIR = Path(__file__).parent.parent / "logs"
LOGS_DIR.mkdir(exist_ok=True)  # ‚Üê Isso

# Se ainda n√£o funcionar:
import os
os.makedirs("logs", exist_ok=True)
```

### Problema 2: yfinance n√£o retorna dados

**Sintoma**: `validate_predictions()` n√£o encontra dados reais

**Causa**: Ticker errado ou sem conex√£o

**Solu√ß√£o**:
```python
import yfinance as yf

# Teste manual
data = yf.download("B3SA3.SA", start="2025-11-01", end="2025-11-02")
print(data)

# Se vazio:
# 1. Verifique ticker: "B3SA3.SA" (correto para Yahoo Finance)
# 2. Verifique data: mercado fecha 18h (dados dispon√≠veis no dia seguinte)
# 3. Verifique conex√£o internet
```

### Problema 3: Drift detector sem refer√™ncia

**Sintoma**: "Reference statistics not set"

**Causa**: N√£o configurou baseline

**Solu√ß√£o**:
```python
from src.drift_detector import setup_reference_from_file
from pathlib import Path

# Carrega dados de treinamento
data_file = Path("data/processed/B3SA3_2020-11-03_2025-10-31.csv")
setup_reference_from_file(data_file)

# Agora pode usar detector
```

### Problema 4: Alertas do Slack n√£o funcionam

**Sintoma**: Alertas n√£o chegam no Slack

**Causa**: Webhook URL inv√°lido ou canal desativado

**Solu√ß√£o**:
```bash
# 1. Teste webhook manualmente
curl -X POST https://hooks.slack.com/services/YOUR/WEBHOOK/URL \
  -H 'Content-Type: application/json' \
  -d '{"text":"Test from PredictFinance"}'

# Se aparecer no Slack = webhook OK
# Se n√£o aparecer = webhook inv√°lido ou canal deletado

# 2. Verifique configura√ß√£o
cat monitoring/alert_config.json

# 3. Reconfigure
python -c "from src.alert_system import configure_slack_webhook; configure_slack_webhook('NEW_URL')"
```

### Problema 5: Performance Monitor n√£o valida

**Sintoma**: `validated: 0` sempre

**Causa**: Dados reais ainda n√£o dispon√≠veis (mercado n√£o fechou)

**Solu√ß√£o**:
```python
# Mercado B3 fecha √†s 18h BRT
# Dados dispon√≠veis ~21h BRT

# Execute valida√ß√£o DEPOIS das 21h
# Ou ajuste days_back:
monitor.validate_predictions(days_back=7)  # Pega √∫ltimos 7 dias
```

### Problema 6: Arquivo JSON corrompido

**Sintoma**: `JSONDecodeError`

**Causa**: Escrita interrompida

**Solu√ß√£o**:
```bash
# Backup primeiro
cp monitoring/predictions_tracking.json monitoring/predictions_tracking.json.bak

# Tente corrigir:
# 1. Abra arquivo
# 2. Verifique √∫ltima linha (pode estar incompleta)
# 3. Remova linha incompleta
# 4. Salve

# Ou resete:
echo '{"predictions": []}' > monitoring/predictions_tracking.json
```

### Problema 7: Muitos logs (disco cheio)

**Sintoma**: Disco do servidor cheio

**Causa**: Logs acumulando sem rota√ß√£o

**Solu√ß√£o**:
```python
# Adicione log rotation
import logging
from logging.handlers import RotatingFileHandler

handler = RotatingFileHandler(
    LOG_FILE,
    maxBytes=10*1024*1024,  # 10 MB
    backupCount=5           # Mant√©m 5 arquivos
)
```

Ou use `logrotate` (Linux):
```bash
# /etc/logrotate.d/predictfinance
/path/to/PredictFinance/logs/*.log {
    daily
    rotate 7
    compress
    delaycompress
    notifempty
    missingok
}
```

---

## ‚úÖ Checklist de Conclus√£o

### Implementa√ß√£o

- [ ] **Logging**
  - [x] `api/monitoring.py` criado
  - [x] Integrado em `api/main.py`
  - [ ] Testado localmente
  - [ ] Logs aparecendo em `logs/predictions.log`

- [ ] **Performance Monitor**
  - [x] `src/performance_monitor.py` criado
  - [ ] Previs√µes sendo registradas
  - [ ] Valida√ß√£o funcionando com yfinance
  - [ ] M√©tricas sendo calculadas

- [ ] **Drift Detector**
  - [x] `src/drift_detector.py` criado
  - [ ] Estat√≠sticas de refer√™ncia configuradas
  - [ ] Drift detection testado
  - [ ] Relat√≥rios sendo salvos

- [ ] **Sistema de Alertas**
  - [x] `src/alert_system.py` criado
  - [ ] Thresholds configurados
  - [ ] Alertas via logs funcionando
  - [ ] (Opcional) Slack webhook configurado

- [ ] **Uptime**
  - [x] Endpoint `/health` funcionando
  - [ ] UptimeRobot configurado
  - [ ] Alertas de downtime testados

### Testes

- [ ] `test_monitoring.py` executado com sucesso
- [ ] Todos os 5 testes passando
- [ ] Arquivos de monitoramento criados:
  - [ ] `logs/predictions.log`
  - [ ] `logs/metrics.log`
  - [ ] `monitoring/predictions_tracking.json`
  - [ ] `monitoring/performance_metrics.json`
  - [ ] `monitoring/reference_statistics.json`
  - [ ] `monitoring/drift_reports.json`
  - [ ] `monitoring/alert_history.json`

### Automa√ß√£o

- [ ] `run_daily_monitoring.py` executado manualmente
- [ ] Cron job / Task Scheduler / GitHub Actions configurado
- [ ] Primeiro relat√≥rio di√°rio gerado
- [ ] Alertas disparados corretamente (se thresholds excedidos)

### Produ√ß√£o

- [ ] API no Render atualizada com logging
- [ ] Logs de produ√ß√£o verificados
- [ ] UptimeRobot monitorando API
- [ ] Primeiro ciclo de valida√ß√£o de previs√µes completo

### Documenta√ß√£o

- [x] `docs/FASE_8_GUIA.md` criado
- [ ] README.md atualizado
- [ ] INDEX.md atualizado
- [ ] Equipe treinada em monitoramento

### Extras (Opcional)

- [ ] Slack webhook configurado
- [ ] Email alerts configurados
- [ ] Backup autom√°tico de dados de monitoramento
- [ ] Dashboard Grafana/Evidently configurado

---

## üéØ Pr√≥ximos Passos

### Imediatos

1. **Executar Testes**
   ```bash
   python test_monitoring.py
   ```

2. **Configurar Estat√≠sticas de Refer√™ncia**
   ```python
   from src.drift_detector import setup_reference_from_file
   setup_reference_from_file(Path("data/processed/B3SA3_2020-11-03_2025-10-31.csv"))
   ```

3. **Primeiro Monitoramento Manual**
   ```bash
   python run_daily_monitoring.py
   ```

4. **Deploy no Render**
   ```bash
   git add .
   git commit -m "feat: Sistema de monitoramento (Fase 8)"
   git push origin main
   ```

5. **Configurar UptimeRobot**
   - URL: https://b3sa3-api.onrender.com/health
   - Interval: 5 min

### Curto Prazo (Pr√≥xima Semana)

6. **Automatizar Monitoramento**
   - Configurar cron job / GitHub Actions

7. **Primeira Valida√ß√£o Real**
   - Aguardar 1 dia ap√≥s previs√µes
   - Executar valida√ß√£o

8. **Ajustar Thresholds**
   - Baseado em m√©tricas reais

### M√©dio Prazo (Pr√≥ximo M√™s)

9. **Analisar Tend√™ncias**
   - Verificar se modelo est√° degradando
   - Decidir se precisa re-treinar

10. **Otimiza√ß√µes**
    - Slack/Email alerts
    - Dashboard visual (Grafana)
    - Banco de dados para persist√™ncia

---

## üìö Refer√™ncias

- **Evidently AI**: https://evidentlyai.com
- **FastAPI Monitoring**: https://fastapi.tiangolo.com/advanced/middleware/
- **MLOps Best Practices**: https://ml-ops.org
- **Data Drift Detection**: https://towardsdatascience.com/understanding-data-drift-monitoring
- **UptimeRobot**: https://uptimerobot.com
- **Render Logs**: https://render.com/docs/logs

---

## üéâ Conclus√£o da Fase 8

Parab√©ns! Voc√™ implementou um **sistema completo de monitoramento de ML em produ√ß√£o**!

### O Que Foi Alcan√ßado

‚úÖ **Observabilidade Total**: Logs de todas as requisi√ß√µes  
‚úÖ **Performance Tracking**: M√©tricas de erro cont√≠nuas  
‚úÖ **Drift Detection**: Detec√ß√£o de mudan√ßas nos dados  
‚úÖ **Alertas Proativos**: Notifica√ß√£o de problemas  
‚úÖ **Uptime Monitoring**: Disponibilidade 24/7  

### Import√¢ncia

Este sistema garante que:

1. **Voc√™ sabe se o modelo est√° funcionando** (n√£o √© "caixa preta")
2. **Problemas s√£o detectados precocemente** (antes de impactar usu√°rios)
3. **Decis√µes s√£o data-driven** (quando re-treinar √© baseado em dados)
4. **Sistema √© confi√°vel** (uptime monitorado)

### üèÜ Projeto Completo (100%)!

**Fase 8 = √öltima Fase do Projeto PredictFinance!**

Voc√™ agora tem um **sistema completo de ML em produ√ß√£o** com:

- ‚úÖ Coleta de dados (Fase 1)
- ‚úÖ Prepara√ß√£o de dados (Fase 2)
- ‚úÖ Explora√ß√£o de dados (Fase 3)
- ‚úÖ Treinamento de modelo (Fase 4)
- ‚úÖ Persist√™ncia (Fase 5)
- ‚úÖ API REST (Fase 6)
- ‚úÖ Deploy em produ√ß√£o (Fase 7)
- ‚úÖ **Monitoramento 24/7 (Fase 8)** ‚Üê VOC√ä EST√Å AQUI!

**Pr√≥ximo passo**: Manter o sistema rodando e aprender com os dados de produ√ß√£o! üöÄ

---

**Documenta√ß√£o criada por**: GitHub Copilot  
**Data**: Novembro 2025  
**Vers√£o**: 1.0  
