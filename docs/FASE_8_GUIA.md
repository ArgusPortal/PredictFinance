# ğŸ“Š Fase 8: Monitoramento do Modelo em ProduÃ§Ã£o

**Autor:** Argus  
**Projeto**: PredictFinance - Sistema de PrevisÃ£o B3SA3.SA  
**Fase**: 8/8 - **FASE FINAL**  
**Status**: âœ… Implementada  
**Data**: Novembro 2025  
**Ãšltima atualizaÃ§Ã£o:** 21/12/2025 (Drift Detection - Janela Deslizante)

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [PrÃ©-requisitos](#prÃ©-requisitos)
3. [Objetivos da Fase](#objetivos-da-fase)
4. [Componentes do Sistema](#componentes-do-sistema)
5. [1. Logging de RequisiÃ§Ãµes](#1-logging-de-requisiÃ§Ãµes)
6. [2. Monitoramento de Performance](#2-monitoramento-de-performance)
7. [3. DetecÃ§Ã£o de Drift](#3-detecÃ§Ã£o-de-drift)
8. [4. Sistema de Alertas](#4-sistema-de-alertas)
9. [5. Monitoramento de Uptime](#5-monitoramento-de-uptime)
10. [IntegraÃ§Ã£o com API](#integraÃ§Ã£o-com-api)
11. [Testes do Sistema](#testes-do-sistema)
12. [Deploy e ProduÃ§Ã£o](#deploy-e-produÃ§Ã£o)
13. [AutomaÃ§Ã£o (Cron Jobs)](#automaÃ§Ã£o-cron-jobs)
14. [Troubleshooting](#troubleshooting)
15. [Checklist de ConclusÃ£o](#checklist-de-conclusÃ£o)

---

## ğŸ“– VisÃ£o Geral

A **Fase 8** implementa um **sistema completo de monitoramento** do modelo LSTM em produÃ§Ã£o, garantindo:

âœ… **Auditoria**: Logs detalhados de todas as previsÃµes  
âœ… **Performance**: Acompanhamento contÃ­nuo de mÃ©tricas (MAE, MAPE)  
âœ… **Drift Detection**: DetecÃ§Ã£o de mudanÃ§as na distribuiÃ§Ã£o dos dados  
âœ… **Alertas**: NotificaÃ§Ãµes automÃ¡ticas de degradaÃ§Ã£o  
âœ… **Uptime**: Monitoramento de disponibilidade da API  

### ğŸ¯ Por Que Monitorar?

Modelos de ML em produÃ§Ã£o podem **degradar** ao longo do tempo devido a:

- ğŸ“‰ **Concept Drift**: PadrÃµes de mercado mudam
- ğŸ“Š **Data Drift**: DistribuiÃ§Ã£o dos dados muda
- ğŸ”§ **Performance Decay**: AcurÃ¡cia diminui com o tempo
- ğŸ› **Bugs e Erros**: Falhas operacionais

O monitoramento permite detectar esses problemas **antes** que impactem os usuÃ¡rios!

---

## ğŸ”§ PrÃ©-requisitos

### DependÃªncias

Instale as dependÃªncias de monitoramento:

```bash
pip install -r requirements-monitoring.txt
```

**ConteÃºdo** de `requirements-monitoring.txt`:
```
evidently==0.4.38      # Drift detection
scipy==1.11.4          # Testes estatÃ­sticos
requests==2.31.0       # Alertas (Slack)
yfinance==0.2.36       # Dados em produÃ§Ã£o
```

### Fases Anteriores

âœ… Fase 1-6: Dados coletados, modelo treinado, API desenvolvida  
âœ… Fase 7: API deployada no Render.com  

---

## ğŸ¯ Objetivos da Fase

1. âœ… **Logging Estruturado**: Registrar todas as requisiÃ§Ãµes `/predict`
2. âœ… **Performance Tracking**: Comparar previsÃµes vs valores reais
3. âœ… **Drift Detection**: Monitorar mudanÃ§as nos dados de entrada
4. âœ… **Alertas AutomÃ¡ticos**: Notificar degradaÃ§Ã£o do modelo
5. âœ… **Uptime Monitoring**: Garantir disponibilidade da API

---

## ğŸ§© Componentes do Sistema

O sistema de monitoramento Ã© composto por **5 mÃ³dulos**:

```
PredictFinance/
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ monitoring.py               # Logging de requisiÃ§Ãµes
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ performance_monitor.py      # Monitor de performance
â”‚   â”œâ”€â”€ drift_detector.py           # Detector de drift
â”‚   â””â”€â”€ alert_system.py             # Sistema de alertas
â”‚
â”œâ”€â”€ run_daily_monitoring.py         # Script de monitoramento diÃ¡rio
â”œâ”€â”€ test_monitoring.py              # Testes do sistema
â”‚
â”œâ”€â”€ logs/                           # Logs gerados
â”‚   â”œâ”€â”€ predictions.log
â”‚   â””â”€â”€ metrics.log
â”‚
â””â”€â”€ monitoring/                     # Dados de monitoramento
    â”œâ”€â”€ predictions_tracking.json
    â”œâ”€â”€ performance_metrics.json
    â”œâ”€â”€ reference_statistics.json
    â”œâ”€â”€ drift_reports.json
    â”œâ”€â”€ alert_history.json
    â””â”€â”€ daily_summary.json
```

---

## 1. Logging de RequisiÃ§Ãµes

### ğŸ“ Objetivo

Registrar **todas** as previsÃµes realizadas pela API para:
- Auditoria de uso
- AnÃ¡lise posterior
- Debugging
- Compliance

### ğŸ” ImplementaÃ§Ã£o

**Arquivo**: `api/monitoring.py`

#### Classes Principais

**1. PredictionLogger**

```python
from api.monitoring import get_prediction_logger

logger = get_prediction_logger()

# Registra previsÃ£o
request_id = logger.log_prediction(
    input_data=input_array,      # Shape: (60, 5)
    prediction=12.45,             # Valor previsto
    processing_time_ms=25.3       # LatÃªncia
)
```

**SaÃ­da em `logs/predictions.log`**:
```json
{
  "request_id": "a3f4b2c1",
  "timestamp": "2025-11-02T14:30:15.123456",
  "event": "prediction",
  "input_stats": {
    "mean": 12.34,
    "std": 0.56,
    "min": 11.20,
    "max": 13.10,
    "shape": [60, 5]
  },
  "prediction": 12.45,
  "processing_time_ms": 25.3,
  "status": "success"
}
```

**2. MetricsLogger**

Registra mÃ©tricas do sistema:

```python
from api.monitoring import get_metrics_logger

metrics_logger = get_metrics_logger()
metrics_logger.increment_request()  # Conta requisiÃ§Ã£o
metrics_logger.increment_error()    # Conta erro
```

### ğŸ¨ EstatÃ­sticas ao InvÃ©s de Dados Brutos

**Problema**: Logar 60 valores x 5 features = 300 nÃºmeros por previsÃ£o (muito grande!)

**SoluÃ§Ã£o**: Logar apenas estatÃ­sticas resumidas:
- MÃ©dia (`mean`)
- Desvio padrÃ£o (`std`)
- MÃ­nimo/MÃ¡ximo (`min`, `max`)
- Mediana (`median`)
- Shape dos dados

Isso reduz o tamanho dos logs em **90%** mantendo informaÃ§Ã£o Ãºtil!

### ğŸ“Š IntegraÃ§Ã£o na API

A API FastAPI foi modificada para incluir logging automÃ¡tico:

**`api/main.py`** - Endpoint `/predict`:

```python
@app.post("/predict")
async def fazer_previsao(previsao_input: PrevisaoInput):
    # Inicializa loggers
    pred_logger = get_prediction_logger()
    metrics_logger = get_metrics_logger()
    
    # Conta requisiÃ§Ã£o
    metrics_logger.increment_request()
    
    # Marca inÃ­cio
    start_time = time.time()
    
    try:
        # ... processamento ...
        
        # Calcula tempo
        processing_time = (time.time() - start_time) * 1000
        
        # LOG DA PREVISÃƒO
        request_id = pred_logger.log_prediction(
            input_data=input_data,
            prediction=valor_previsto,
            processing_time_ms=processing_time
        )
        
        return PrevisaoOutput(
            preco_previsto=valor_previsto,
            mensagem=f"PrevisÃ£o OK [ID: {request_id}]"
        )
    
    except Exception as e:
        # LOG DO ERRO
        metrics_logger.increment_error()
        pred_logger.log_error(str(e), input_data)
        raise
```

### âœ… BenefÃ­cios

1. **Auditoria Completa**: Rastreabilidade de todas as previsÃµes
2. **Debugging**: Identificar requisiÃ§Ãµes problemÃ¡ticas
3. **Analytics**: AnÃ¡lise de padrÃµes de uso
4. **Compliance**: Atende requisitos regulatÃ³rios

---

## 2. Monitoramento de Performance

### ğŸ“ˆ Objetivo

Avaliar **continuamente** a qualidade das previsÃµes comparando com valores reais.

### ğŸ” Como Funciona

```
Dia 1: API prevÃª preÃ§o para Dia 2 â†’ PrevisÃ£o = R$ 12.50
        â†“ (24 horas)
Dia 2: Mercado fecha â†’ PreÃ§o Real = R$ 12.45
        â†“ (validaÃ§Ã£o)
Sistema: Calcula erro = |12.50 - 12.45| = R$ 0.05 (0.4%)
```

### ğŸ’» ImplementaÃ§Ã£o

**Arquivo**: `src/performance_monitor.py`

#### Classe Principal: PerformanceMonitor

**1. Registrar PrevisÃµes**

```python
from src.performance_monitor import PerformanceMonitor

monitor = PerformanceMonitor(window_days=7)

# Registra previsÃ£o para validaÃ§Ã£o futura
monitor.register_prediction(
    prediction_value=12.50,
    prediction_date="2025-11-02T10:00:00",
    request_id="abc123"
)
```

**Salva em** `monitoring/predictions_tracking.json`:
```json
{
  "predictions": [
    {
      "request_id": "abc123",
      "timestamp": "2025-11-02T10:00:00",
      "predicted_value": 12.50,
      "validated": false,
      "actual_value": null,
      "error": null
    }
  ]
}
```

**2. Validar PrevisÃµes**

```python
# Executa validaÃ§Ã£o (busca preÃ§os reais no yfinance)
result = monitor.validate_predictions(days_back=7)

print(f"Validadas: {result['validated']}")
print(f"Pendentes: {result['pending']}")
```

**Processo**:
1. LÃª previsÃµes nÃ£o validadas
2. Para cada previsÃ£o:
   - Busca preÃ§o real do dia seguinte via `yfinance`
   - Calcula erro absoluto e percentual
   - Marca como validada
3. Salva resultados

**SaÃ­da**:
```
Validadas: 5 previsÃµes
   âœ… abc123: Previsto=12.50, Real=12.45, Erro=0.40%
   âœ… def456: Previsto=12.60, Real=12.58, Erro=0.16%
   ...
```

**3. Calcular MÃ©tricas**

```python
# Calcula MAE, MAPE, RMSE
metrics = monitor.calculate_metrics()
```

**Output**:
```
ğŸ“Š MÃ‰TRICAS DE PERFORMANCE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Janela: Ãšltimos 7 dias
MAE:  0.0523
MAPE: 0.42%
RMSE: 0.0681
Erro MÃ­nimo: 0.08%
Erro MÃ¡ximo: 0.95%
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Salva em** `monitoring/performance_metrics.json`:
```json
{
  "daily_metrics": [
    {
      "timestamp": "2025-11-02T12:00:00",
      "window_days": 7,
      "mae": 0.0523,
      "mape": 0.42,
      "rmse": 0.0681,
      "total_validated": 35
    }
  ],
  "summary": {
    "last_update": "2025-11-02T12:00:00",
    "current_mae": 0.0523,
    "current_mape": 0.42
  }
}
```

**4. Detectar DegradaÃ§Ã£o**

```python
# Verifica se MAPE excedeu threshold
is_degrading = monitor.detect_degradation(threshold_mape=5.0)

if is_degrading:
    print("âš ï¸  ALERTA: Modelo degradando!")
```

**5. Analisar TendÃªncia**

```python
# Analisa tendÃªncia dos Ãºltimos 7 dias
trend = monitor.get_performance_trend(days=7)

print(f"TendÃªncia: {trend['trend']}")  # "improving", "stable", "degrading"
print(f"MAPE Inicial: {trend['initial_mape']:.2f}%")
print(f"MAPE Final: {trend['final_mape']:.2f}%")
```

### ğŸ”„ ExecuÃ§Ã£o DiÃ¡ria

O script `run_daily_monitoring.py` automatiza esse processo:

```bash
python run_daily_monitoring.py
```

**SaÃ­da Esperada**:
```
ğŸ” MONITORAMENTO DIÃRIO DO MODELO B3SA3
ğŸ“… Data: 2025-11-02 12:00:00
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1ï¸âƒ£  VALIDAÃ‡ÃƒO DE PERFORMANCE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Š PrevisÃµes pendentes: 5
ğŸ“ˆ Baixando dados reais de B3SA3.SA...
   âœ… abc123: Previsto=12.50, Real=12.45, Erro=0.40%
   âœ… def456: Previsto=12.60, Real=12.58, Erro=0.16%
   ...

âœ… Validadas: 5 previsÃµes
â³ Pendentes: 2

ğŸ“Š MÃ‰TRICAS DE PERFORMANCE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Janela: Ãšltimos 7 dias
MAE:  0.0523
MAPE: 0.42%
RMSE: 0.0681
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ˆ TendÃªncia de Performance:
   â¡ï¸  Status: STABLE
   MAPE Inicial: 0.45%
   MAPE Final: 0.42%
   MAPE MÃ©dio: 0.43%

âœ… Performance do modelo dentro do esperado
```

### âœ… BenefÃ­cios

1. **Feedback ContÃ­nuo**: Sabe se modelo estÃ¡ funcionando bem
2. **DetecÃ§Ã£o Precoce**: Identifica degradaÃ§Ã£o antes de piorar
3. **DecisÃ£o Data-Driven**: Baseada em mÃ©tricas reais, nÃ£o suposiÃ§Ãµes
4. **HistÃ³rico**: MantÃ©m registro de performance ao longo do tempo

---

## 3. DetecÃ§Ã£o de Drift

### ğŸŒŠ O Que Ã© Data Drift?

**Data Drift** ocorre quando a **distribuiÃ§Ã£o estatÃ­stica** dos dados muda ao longo do tempo.

**âŒ ABORDAGEM INCORRETA (Problema do projeto original)**:
- Comparar dados de **treinamento (2020-2023)** com dados de **teste/produÃ§Ã£o (2025)**
- Resultado: **SEMPRE** mostrarÃ¡ drift alto (~28% na mÃ©dia, ~47% no desvio padrÃ£o)
- Motivo: Mercado financeiro **naturalmente evolui** (inflaÃ§Ã£o, mudanÃ§as econÃ´micas)
- ConclusÃ£o: Esta diferenÃ§a **NÃƒO indica problema no modelo**!

**âœ… ABORDAGEM CORRETA (Janela Deslizante)**:
- Comparar **janela atual (7 dias)** com **janela de referÃªncia (30 dias anteriores)**
- Objetivo: Detectar **mudanÃ§as abruptas e recentes**, nÃ£o evoluÃ§Ã£o gradual
- Exemplo:
  - Se preÃ§o estava R$ 13.90 nos Ãºltimos 30 dias
  - E de repente caiu para R$ 10.00 nos Ãºltimos 7 dias
  - **ESTE Ã© um drift significativo** que pode afetar as previsÃµes

### ğŸ” Tipos de Drift

1. **Drift de Entrada (Input Drift)**: Features mudam abruptamente
2. **Drift de SaÃ­da (Prediction Drift)**: DistribuiÃ§Ã£o das previsÃµes muda
3. **Concept Drift**: RelaÃ§Ã£o entre input e output muda

### ğŸ’» Nova ImplementaÃ§Ã£o - Janela Deslizante

**Arquivo**: `src/drift_detector.py`

#### Classe: SlidingWindowDriftDetector

**Uso BÃ¡sico:**
```python
from src.drift_detector import analyze_drift_from_yahoo

# AnÃ¡lise automÃ¡tica com dados do Yahoo Finance
result = analyze_drift_from_yahoo("B3SA3.SA")

print(f"Drift detectado: {result['drift_detected']}")
print(f"Severidade: {result['severity']}")  # 'none', 'medium', 'high'
print(f"Alertas: {result['alerts']}")
```

**Janelas de ComparaÃ§Ã£o:**
- **Janela Atual**: Ãšltimos 7 dias de pregÃ£o
- **Janela ReferÃªncia**: 30 dias anteriores
- **Threshold Î” MÃ©dia**: 5% (mudanÃ§as maiores indicam drift)
- **Threshold Î” Volatilidade**: 50% (volatilidade Ã© mais variÃ¡vel)

**Uso AvanÃ§ado com ConfiguraÃ§Ã£o:**
```python
from src.drift_detector import SlidingWindowDriftDetector
import yfinance as yf

# Inicializa detector com configuraÃ§Ãµes personalizadas
detector = SlidingWindowDriftDetector(
    current_window_days=7,
    reference_window_days=30,
    mean_threshold_pct=5.0,
    std_threshold_pct=50.0
)

# Busca dados
df = yf.download("B3SA3.SA", start="2025-09-01", end="2025-12-21")
prices = df['Close'].values

# Executa anÃ¡lise
report = detector.detect_drift(prices, "B3SA3.SA")

# Exibe resultados
if report['drift_detected']:
    print(f"âš ï¸ Drift detectado! Severidade: {report['severity']}")
    for alert in report['alerts']:
        print(f"  â€¢ {alert}")
else:
    print("âœ… Mercado estÃ¡vel")
```

**SaÃ­da Exemplo:**
```
ğŸ” DETECÃ‡ÃƒO DE DRIFT (JANELA DESLIZANTE)
============================================================

ğŸ“… Janela Atual: 11/12 a 19/12
   MÃ©dia: R$ 13.81
   Volatilidade: R$ 0.48

ğŸ“… Janela ReferÃªncia: 29/10 a 10/12
   MÃ©dia: R$ 13.92
   Volatilidade: R$ 0.77

ğŸ“Š ComparaÃ§Ã£o:
   Î” MÃ©dia: 0.7% (threshold: 5.0%)
   Î” Volatilidade: 37.6% (threshold: 50.0%)

âœ… Sem drift significativo - Mercado estÃ¡vel
============================================================
```

**Salva em** `monitoring/drift_reports.json`:
```json
{
  "reports": [
    {
      "timestamp": "2025-12-21T15:00:00",
      "ticker": "B3SA3.SA",
      "drift_detected": false,
      "severity": "none",
      "alerts": [],
      "current_window": {
        "start": "2025-12-11",
        "end": "2025-12-19",
        "mean": 13.81,
        "std": 0.48,
        "n_samples": 7
      },
      "reference_window": {
        "start": "2025-10-29",
        "end": "2025-12-10",
        "mean": 13.92,
        "std": 0.77,
        "n_samples": 30
      },
      "comparisons": {
        "mean_diff_pct": 0.7,
        "std_diff_pct": 37.6
      },
      "config": {
        "current_window_days": 7,
        "reference_window_days": 30,
        "mean_threshold_pct": 5.0,
        "std_threshold_pct": 50.0
      }
    }
  ]
}
```

**NÃ­veis de Severidade:**

| Severidade | CondiÃ§Ã£o | AÃ§Ã£o Recomendada |
|------------|----------|------------------|
| ğŸŸ¢ **None** | Ambas mÃ©tricas abaixo do threshold | Continuar monitoramento normal |
| ğŸŸ¡ **Medium** | Uma mÃ©trica acima do threshold | Monitorar mais de perto, investigar causa |
| ğŸ”´ **High** | Ambas mÃ©tricas acima do threshold | Considerar retreino urgente do modelo |

**IntegraÃ§Ã£o com API:**

O endpoint `/monitoring/drift` executa esta anÃ¡lise em tempo real:

print(f"Outliers: {analysis['outliers']['count']}")
print(f"Porcentagem: {analysis['outliers']['percentage']:.1f}%")
```

Detecta valores **muito fora do padrÃ£o** usando boxplot (IQR method):

```
Outliers = valores < Q1 - 1.5*IQR  OU  valores > Q3 + 1.5*IQR
```

**4. Resumo de Drift**

```python
# Ãšltimos 7 dias
summary = detector.get_drift_summary(days=7)

print(f"Total de checagens: {summary['total_checks']}")
print(f"Drift detectado: {summary['drift_detected_count']} vezes")
print(f"Taxa de drift: {summary['drift_rate']:.1f}%")
```

### ğŸ”„ Uso no Monitoramento DiÃ¡rio

O script `run_daily_monitoring.py` executa drift detection automaticamente:

```bash
python run_daily_monitoring.py
```

**SaÃ­da**:
```
2ï¸âƒ£  DETECÃ‡ÃƒO DE DRIFT DE DADOS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Š Resumo de Drift (Ãºltimos 7 dias):
   Checagens: 7
   Drift detectado: 2 vezes
   Taxa de drift: 28.6%
```

### ğŸš¨ Quando Agir?

**Taxa de Drift > 50%**: Modelo estÃ¡ recebendo dados **muito diferentes** do treinamento
â†’ **AÃ‡ÃƒO**: Re-treinar modelo com dados mais recentes

**MÃ©dia mudou > 10%**: PadrÃ£o de mercado mudou significativamente
â†’ **AÃ‡ÃƒO**: Investigar causa e considerar re-treinamento

### âœ… BenefÃ­cios

1. **DetecÃ§Ã£o Proativa**: Identifica problemas antes de afetar performance
2. **Explicabilidade**: Mostra **por quÃª** modelo estÃ¡ errando
3. **DecisÃ£o Informada**: Sabe quando re-treinar (nÃ£o Ã© "chute")
4. **Testes EstatÃ­sticos**: Baseado em ciÃªncia, nÃ£o heurÃ­sticas

---

## 4. Sistema de Alertas

### ğŸ”” Objetivo

Notificar automaticamente quando **thresholds** sÃ£o excedidos.

### ğŸ’» ImplementaÃ§Ã£o

**Arquivo**: `src/alert_system.py`

#### Thresholds ConfigurÃ¡veis

```python
from src.alert_system import AlertThresholds

thresholds = AlertThresholds(
    mae_threshold=2.0,           # MAE mÃ¡ximo (R$)
    mape_threshold=5.0,          # MAPE mÃ¡ximo (%)
    drift_mean_pct=10.0,         # MudanÃ§a de mÃ©dia (%)
    drift_std_pct=20.0,          # MudanÃ§a de desvio (%)
    error_rate_threshold=0.05    # Taxa de erro (5%)
)
```

#### Classe Principal: AlertSystem

**1. Verificar MÃ©tricas de Performance**

```python
from src.alert_system import AlertSystem

alert_system = AlertSystem(thresholds)

# MÃ©tricas atuais
metrics = {
    "mae": 2.5,   # ACIMA do threshold (2.0)
    "mape": 6.0   # ACIMA do threshold (5.0)
}

# Verifica violaÃ§Ãµes
violations = alert_system.check_performance_metrics(metrics)

print(violations)
# ['MAE alto: 2.5000 > 2.0', 'MAPE alto: 6.00% > 5.00%']
```

**2. Verificar Drift**

```python
drift_report = {
    "drift_detected": True,
    "alerts": ["MÃ©dia mudou 12.30%"]
}

violations = alert_system.check_drift_metrics(drift_report)
# ['Drift: MÃ©dia mudou 12.30%']
```

**3. Enviar Alertas**

```python
alert_system.send_alert(
    alert_type="performance_degradation",
    message="MAPE alto: 6.00% > 5.00%",
    severity="WARNING",
    metadata=metrics
)
```

**SaÃ­da (Logs)**:
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸  ALERTA: PERFORMANCE_DEGRADATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Severidade: WARNING
Timestamp:  2025-11-02T14:30:00
Mensagem:   MAPE alto: 6.00% > 5.00%
Detalhes:   {
  "mae": 2.5,
  "mape": 6.0
}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

#### Canais de NotificaÃ§Ã£o

**A. Logs (PadrÃ£o)**

Sempre ativado, registra em `logs/` e stdout.

**B. Slack (Opcional)**

```python
# Configurar webhook do Slack
from src.alert_system import configure_slack_webhook

configure_slack_webhook("https://hooks.slack.com/services/YOUR/WEBHOOK/URL")
```

**Formato da mensagem Slack**:
```
âš ï¸  PERFORMANCE_DEGRADATION Alert

Severity: WARNING
Time: 2025-11-02T14:30:00

Message:
MAPE alto: 6.00% > 5.00%
```

**C. Email (Placeholder)**

ImplementaÃ§Ã£o bÃ¡sica incluÃ­da. Para ativar:

1. Edite `monitoring/alert_config.json`:
```json
{
  "enable_email": true,
  "email_config": {
    "smtp_server": "smtp.gmail.com",
    "smtp_port": 587,
    "sender_email": "your-email@gmail.com",
    "receiver_emails": ["team@company.com"],
    "password": "your-app-password"
  }
}
```

2. Implemente envio SMTP em `_send_email_alert()`

#### HistÃ³rico de Alertas

```python
# Alertas das Ãºltimas 24 horas
recent = alert_system.get_recent_alerts(hours=24)

# Resumo
summary = alert_system.get_alert_summary()

print(f"Total de alertas: {summary['total_alerts']}")
print(f"Por tipo: {summary['by_type']}")
print(f"Por severidade: {summary['by_severity']}")
```

**SaÃ­da**:
```
Total de alertas: 15
Por tipo: {'performance_degradation': 5, 'data_drift': 8, 'error': 2}
Por severidade: {'WARNING': 12, 'CRITICAL': 3}
```

**Salva em** `monitoring/alert_history.json`

### ğŸ”„ IntegraÃ§Ã£o no Monitoramento DiÃ¡rio

```python
# Script: run_daily_monitoring.py

# 1. Calcula mÃ©tricas
metrics = perf_monitor.calculate_metrics()

# 2. Verifica violations
violations = alert_system.check_performance_metrics(metrics)

# 3. Envia alertas se necessÃ¡rio
if violations:
    for violation in violations:
        alert_system.send_alert(
            alert_type="performance_degradation",
            message=violation,
            severity="WARNING"
        )
```

### ğŸ“Š Plano de AÃ§Ã£o

Quando **alerta** Ã© disparado:

1. **Investigar Causa**:
   - Logs de previsÃµes
   - Dados de entrada
   - Drift reports

2. **Validar Problema**:
   - Confirmar degradaÃ§Ã£o em mÃºltiplas mÃ©tricas
   - Verificar tendÃªncia (nÃ£o Ã© anomalia pontual)

3. **Tomar AÃ§Ã£o**:
   - **MAPE > 5%**: Re-treinar modelo
   - **Drift > 50%**: Coletar dados recentes e re-treinar
   - **Error Rate Alto**: Investigar bugs na API

### âœ… BenefÃ­cios

1. **Proatividade**: Detecta problemas em horas (nÃ£o semanas)
2. **AutomaÃ§Ã£o**: NÃ£o depende de checagem manual
3. **EscalÃ¡vel**: Funciona 24/7
4. **RastreÃ¡vel**: HistÃ³rico de todos os alertas

---

## 5. Monitoramento de Uptime

### ğŸŒ Objetivo

Garantir que a **API estÃ¡ disponÃ­vel e respondendo** 24/7.

### ğŸ” Componentes

#### A. Endpoint de Health Check

JÃ¡ implementado na **Fase 6**:

```python
# api/main.py

@app.get("/health")
async def health_check():
    """Retorna status de saÃºde da API."""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "model_loaded": model is not None,
        "scaler_loaded": scaler is not None
    }
```

**Teste**:
```bash
curl https://b3sa3-api.onrender.com/health
```

**Resposta**:
```json
{
  "status": "healthy",
  "timestamp": "2025-11-02T14:00:00",
  "model_loaded": true,
  "scaler_loaded": true
}
```

#### B. Monitoramento Externo (UptimeRobot)

**ServiÃ§o Gratuito**: https://uptimerobot.com

**Setup**:

1. **Criar Conta** no UptimeRobot

2. **Adicionar Monitor**:
   - **Type**: HTTP(S)
   - **URL**: `https://b3sa3-api.onrender.com/health`
   - **Interval**: 5 minutos
   - **Alert Contacts**: Seu email

3. **Configurar Alertas**:
   - Email quando API cai
   - Email quando API volta

**BenefÃ­cios**:
- âœ… Monitoramento 24/7 externo
- âœ… Alertas de downtime
- âœ… EstatÃ­sticas de uptime (%)
- âœ… HistÃ³rico de indisponibilidade

#### C. Logs de Disponibilidade

O sistema de monitoramento tambÃ©m registra disponibilidade:

```python
# Verifica health endpoint
import requests

response = requests.get("https://b3sa3-api.onrender.com/health", timeout=10)

if response.status_code == 200:
    print("âœ… API estÃ¡ UP")
else:
    print(f"âŒ API estÃ¡ DOWN (status: {response.status_code})")
```

### ğŸ”„ Comportamento do Free Tier (Render)

**Importante**: Render Free Tier tem **sleep mode**:

- ApÃ³s **15 minutos** sem requisiÃ§Ãµes â†’ API "hiberna"
- PrÃ³xima requisiÃ§Ã£o â†’ API "acorda" (leva ~30-60 segundos)
- Isso Ã© **normal** e nÃ£o Ã© downtime

**SoluÃ§Ã£o**:

1. **Aceitar** (se o delay Ã© aceitÃ¡vel)
2. **Ping PeriÃ³dico**: Script que faz requisiÃ§Ã£o a cada 10 min
3. **Upgrade** para plano pago (sem sleep)

**Script de Keep-Alive** (opcional):

```python
# keep_alive.py
import requests
import time

while True:
    try:
        requests.get("https://b3sa3-api.onrender.com/health")
        print("âœ… Ping enviado")
    except:
        print("âŒ Falha no ping")
    
    time.sleep(600)  # 10 minutos
```

Execute em servidor 24/7 (nÃ£o no Render, pois dormiria tambÃ©m):
```bash
nohup python keep_alive.py &
```

### ğŸ“Š MÃ©tricas de Uptime

**Ideal**:
- **Uptime > 99.5%** (considerando sleep mode normal)
- **Response Time < 500ms** (quando acordada)
- **Error Rate < 1%**

**UptimeRobot** calcula automaticamente:
```
Last 30 days: 99.87% uptime
Average response time: 245ms
Downtimes: 2 (total 45 minutes)
```

### âœ… BenefÃ­cios

1. **Confiabilidade**: Sabe quando API estÃ¡ fora
2. **SLA**: Pode reportar uptime aos usuÃ¡rios
3. **Debugging**: Identifica causas de downtime
4. **Compliance**: Atende requisitos de disponibilidade

---

## ğŸ”— IntegraÃ§Ã£o com API

### ModificaÃ§Ãµes na API (Fase 8)

**Arquivo**: `api/main.py`

```python
# Imports adicionados
from api.monitoring import get_prediction_logger, get_metrics_logger
import time

# No endpoint /predict
@app.post("/predict")
async def fazer_previsao(previsao_input: PrevisaoInput):
    # Loggers
    pred_logger = get_prediction_logger()
    metrics_logger = get_metrics_logger()
    
    # Conta requisiÃ§Ã£o
    metrics_logger.increment_request()
    
    # Tempo inicial
    start_time = time.time()
    
    try:
        # ... processamento da previsÃ£o ...
        
        # Calcula tempo
        processing_time = (time.time() - start_time) * 1000
        
        # LOG DA PREVISÃƒO
        request_id = pred_logger.log_prediction(
            input_data=input_for_log,
            prediction=valor_previsto,
            processing_time_ms=processing_time
        )
        
        return PrevisaoOutput(
            preco_previsto=valor_previsto,
            mensagem=f"PrevisÃ£o OK [ID: {request_id}]"
        )
    
    except Exception as e:
        # Conta erro
        metrics_logger.increment_error()
        
        # Log erro
        pred_logger.log_error(str(e), input_data)
        
        raise HTTPException(...)
```

### Testando Localmente

```bash
# 1. Instala dependÃªncias
pip install -r requirements-monitoring.txt

# 2. Inicia API
python run_api.py

# 3. Em outro terminal, faz requisiÃ§Ã£o
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "prices": [12.1, 12.2, ..., 12.5]  # 60 valores
  }'

# 4. Verifica logs
cat logs/predictions.log

# Output:
# 2025-11-02 14:30:15 | INFO | {"request_id": "a3f4b2c1", ...}
```

---

## ğŸ§ª Testes do Sistema

### Script de Teste

**Arquivo**: `test_monitoring.py`

```bash
python test_monitoring.py
```

**SaÃ­da Esperada**:
```
ğŸ§ª TESTE DO SISTEMA DE MONITORAMENTO - FASE 8
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TEST 1: Prediction Logging
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Logged prediction with ID: a3f4b2c1
   Logs salvos em: logs/predictions.log
âœ… Logged error

TEST 2: Performance Monitor
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Registered 2 test predictions
   Database: monitoring/predictions_tracking.json
âœ… Validation attempted
   Validated: 0
   Pending: 2

TEST 3: Drift Detector
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Reference statistics set
âœ… Drift detection completed
   Similar data drift: False
   Different data drift: True
âœ… Prediction distribution analyzed
   Outliers: 0

TEST 4: Alert System
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Performance check completed
   Violations found: 2
   â€¢ MAE alto: 2.5000 > 2.0
   â€¢ MAPE alto: 6.00% > 5.00%
âœ… Alert sent successfully

ğŸ“Š Alert Summary:
   Total alerts: 1
   By type: {'test': 1}
   By severity: {'INFO': 1}

TEST 5: Integration Test
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1ï¸âƒ£  Prediction logged: a3f4b2c1
2ï¸âƒ£  Prediction registered for validation
3ï¸âƒ£  Drift detection: DETECTED
4ï¸âƒ£  Alerts: None (system healthy)

âœ… Integration test completed successfully

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… TODOS OS TESTES PASSARAM!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Arquivos gerados:
   â€¢ logs/predictions.log
   â€¢ logs/metrics.log
   â€¢ monitoring/predictions_tracking.json
   â€¢ monitoring/performance_metrics.json
   â€¢ monitoring/reference_statistics.json
   â€¢ monitoring/drift_reports.json
   â€¢ monitoring/alert_history.json
   â€¢ monitoring/alert_config.json
```

### Testes Manuais

**1. Testar Logging**

```python
from api.monitoring import get_prediction_logger
import numpy as np

logger = get_prediction_logger()
fake_input = np.random.rand(60, 5).tolist()

request_id = logger.log_prediction(
    input_data=fake_input,
    prediction=12.45,
    processing_time_ms=25.0
)

print(f"ID: {request_id}")

# Verifica logs/predictions.log
```

**2. Testar Performance Monitor**

```python
from src.performance_monitor import PerformanceMonitor

monitor = PerformanceMonitor()

# Registra previsÃ£o
monitor.register_prediction(12.50, request_id="test-001")

# Valida (precisa aguardar dados reais)
result = monitor.validate_predictions(days_back=1)
```

**3. Testar Drift Detector**

```python
from src.drift_detector import DriftDetector
import numpy as np

detector = DriftDetector()

# Configura referÃªncia
ref_data = np.random.normal(12.0, 1.0, 1000)
detector.set_reference_statistics(ref_data)

# Detecta drift
current_data = np.random.normal(15.0, 1.5, 100)
report = detector.detect_drift(current_data, "test")

print(f"Drift: {report['drift_detected']}")
```

**4. Testar Alertas**

```python
from src.alert_system import AlertSystem, AlertThresholds

thresholds = AlertThresholds(mape_threshold=5.0)
alert_system = AlertSystem(thresholds)

metrics = {"mape": 6.0}  # Acima do threshold
violations = alert_system.check_performance_metrics(metrics)

for v in violations:
    alert_system.send_alert("test", v, "WARNING")
```

---

## ğŸš€ Deploy e ProduÃ§Ã£o

### Atualizar API no Render

ApÃ³s modificaÃ§Ãµes na API (`api/main.py`):

```bash
# 1. Commit
git add .
git commit -m "feat: Sistema de monitoramento (Fase 8)"

# 2. Push
git push origin main

# Render faz deploy automÃ¡tico (~5 min)
```

### Verificar Logs no Render

**Dashboard Render** â†’ Sua API â†’ **Logs**

VocÃª verÃ¡:
```
INFO:     Started server process
INFO:     Waiting for application startup.
ğŸš€ Iniciando API...
ğŸ“‚ Carregando artefatos do modelo...
   âœ… Modelo carregado com sucesso!
   âœ… Scaler carregado com sucesso!
âœ… API pronta para receber requisiÃ§Ãµes!

INFO:     Application startup complete.
```

Quando fizer requisiÃ§Ãµes `/predict`:
```
2025-11-02 14:30:15 | INFO | {"request_id": "a3f4b2c1", "event": "prediction", ...}
```

### Baixar Logs do Render

Render nÃ£o persiste logs indefinidamente. Para salvar:

```bash
# Via dashboard: Logs â†’ Download
# Ou via CLI do Render (se instalado)
render logs --tail 1000 > logs_render.txt
```

### Configurar Monitoramento DiÃ¡rio

**OpÃ§Ã£o 1: Servidor Externo (Recomendado)**

Execute `run_daily_monitoring.py` em um servidor 24/7:

```bash
# Em seu servidor/VPS/computador pessoal

# Cron job (Linux/Mac)
crontab -e

# Adicione:
0 12 * * * cd /path/to/PredictFinance && /path/to/python run_daily_monitoring.py >> monitoring_cron.log 2>&1
# Executa todo dia Ã s 12:00
```

**OpÃ§Ã£o 2: GitHub Actions (GrÃ¡tis)**

```yaml
# .github/workflows/daily_monitoring.yml
name: Daily Model Monitoring

on:
  schedule:
    - cron: '0 12 * * *'  # 12:00 UTC diariamente
  workflow_dispatch:  # Permite execuÃ§Ã£o manual

jobs:
  monitor:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-monitoring.txt
      
      - name: Run daily monitoring
        run: python run_daily_monitoring.py
      
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: monitoring-results
          path: monitoring/
```

**OpÃ§Ã£o 3: Task Scheduler (Windows)**

1. Abra **Task Scheduler**
2. Create Task:
   - **Trigger**: Daily 12:00
   - **Action**: `python C:\path\to\run_daily_monitoring.py`

### Armazenamento de Dados

**Problema**: Render Free Tier Ã© **efÃªmero** (arquivos sÃ£o perdidos em redeploy)

**SoluÃ§Ãµes**:

**A. Banco de Dados (PostgreSQL, MongoDB)**

Use banco gratuito (Supabase, MongoDB Atlas) para persistir:
- `predictions_tracking.json`
- `performance_metrics.json`
- `drift_reports.json`

**B. Object Storage (S3, Backblaze)**

Salve JSONs em cloud storage.

**C. Execute Monitoramento Externamente**

Monitore de fora do Render (GitHub Actions, seu computador).

### UptimeRobot Setup

1. **Acesse**: https://uptimerobot.com
2. **Create Account**
3. **Add Monitor**:
   - Friendly Name: `B3SA3 API`
   - URL: `https://b3sa3-api.onrender.com/health`
   - Monitoring Interval: 5 minutes
   - Monitor Type: HTTP(S)
   - Alert Contacts: seu email
4. **Save**

VocÃª receberÃ¡ email se API ficar offline > 5 min.

---

## â° AutomaÃ§Ã£o (Cron Jobs)

### Linux/Mac

```bash
# Edita crontab
crontab -e

# Adiciona jobs:

# Monitoramento diÃ¡rio Ã s 12:00
0 12 * * * cd /path/to/PredictFinance && python run_daily_monitoring.py >> monitoring.log 2>&1

# ValidaÃ§Ã£o de previsÃµes Ã s 18:00 (apÃ³s mercado fechar)
0 18 * * * cd /path/to/PredictFinance && python -c "from src.performance_monitor import PerformanceMonitor; m=PerformanceMonitor(); m.validate_predictions(days_back=1)"

# Backup semanal (domingo 00:00)
0 0 * * 0 cd /path/to/PredictFinance && tar -czf backups/monitoring_$(date +\%Y\%m\%d).tar.gz monitoring/
```

### Windows (Task Scheduler)

**PowerShell Script** (`daily_monitoring.ps1`):
```powershell
cd C:\path\to\PredictFinance
& "C:\path\to\python.exe" run_daily_monitoring.py
```

**Task Scheduler**:
1. Open Task Scheduler
2. Create Basic Task:
   - **Name**: Daily Model Monitoring
   - **Trigger**: Daily 12:00 PM
   - **Action**: Start a program
     - **Program**: `powershell.exe`
     - **Arguments**: `-File C:\path\to\daily_monitoring.ps1`

### GitHub Actions (GrÃ¡tis, Cloud)

Crie `.github/workflows/monitoring.yml`:

```yaml
name: Daily Monitoring

on:
  schedule:
    - cron: '0 12 * * *'  # 12:00 UTC
  workflow_dispatch:

jobs:
  monitor:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install deps
        run: |
          pip install -r requirements.txt
          pip install -r requirements-monitoring.txt
      
      - name: Run monitoring
        run: python run_daily_monitoring.py
      
      - name: Commit results
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add monitoring/
          git commit -m "chore: Update monitoring data" || echo "No changes"
          git push
```

**Importante**: GitHub Actions tem **limite de 2000 min/mÃªs** (grÃ¡tis).
Rodando 1x/dia = ~30 min/mÃªs = OK!

---

## ğŸ”§ Troubleshooting

### Problema 1: Logs nÃ£o sendo criados

**Sintoma**: `logs/predictions.log` nÃ£o existe

**Causa**: PermissÃµes ou diretÃ³rio nÃ£o criado

**SoluÃ§Ã£o**:
```python
# monitoring.py cria diretÃ³rio automaticamente
LOGS_DIR = Path(__file__).parent.parent / "logs"
LOGS_DIR.mkdir(exist_ok=True)  # â† Isso

# Se ainda nÃ£o funcionar:
import os
os.makedirs("logs", exist_ok=True)
```

### Problema 2: yfinance nÃ£o retorna dados

**Sintoma**: `validate_predictions()` nÃ£o encontra dados reais

**Causa**: Ticker errado ou sem conexÃ£o

**SoluÃ§Ã£o**:
```python
import yfinance as yf

# Teste manual
data = yf.download("B3SA3.SA", start="2025-11-01", end="2025-11-02")
print(data)

# Se vazio:
# 1. Verifique ticker: "B3SA3.SA" (correto para Yahoo Finance)
# 2. Verifique data: mercado fecha 18h (dados disponÃ­veis no dia seguinte)
# 3. Verifique conexÃ£o internet
```

### Problema 3: Drift detector sem referÃªncia

**Sintoma**: "Reference statistics not set"

**Causa**: NÃ£o configurou baseline

**SoluÃ§Ã£o**:
```python
from src.drift_detector import setup_reference_from_file
from pathlib import Path

# Carrega dados de treinamento
data_file = Path("data/processed/B3SA3_2020-11-03_2025-10-31.csv")
setup_reference_from_file(data_file)

# Agora pode usar detector
```

### Problema 4: Alertas do Slack nÃ£o funcionam

**Sintoma**: Alertas nÃ£o chegam no Slack

**Causa**: Webhook URL invÃ¡lido ou canal desativado

**SoluÃ§Ã£o**:
```bash
# 1. Teste webhook manualmente
curl -X POST https://hooks.slack.com/services/YOUR/WEBHOOK/URL \
  -H 'Content-Type: application/json' \
  -d '{"text":"Test from PredictFinance"}'

# Se aparecer no Slack = webhook OK
# Se nÃ£o aparecer = webhook invÃ¡lido ou canal deletado

# 2. Verifique configuraÃ§Ã£o
cat monitoring/alert_config.json

# 3. Reconfigure
python -c "from src.alert_system import configure_slack_webhook; configure_slack_webhook('NEW_URL')"
```

### Problema 5: Performance Monitor nÃ£o valida

**Sintoma**: `validated: 0` sempre

**Causa**: Dados reais ainda nÃ£o disponÃ­veis (mercado nÃ£o fechou)

**SoluÃ§Ã£o**:
```python
# Mercado B3 fecha Ã s 18h BRT
# Dados disponÃ­veis ~21h BRT

# Execute validaÃ§Ã£o DEPOIS das 21h
# Ou ajuste days_back:
monitor.validate_predictions(days_back=7)  # Pega Ãºltimos 7 dias
```

### Problema 6: Arquivo JSON corrompido

**Sintoma**: `JSONDecodeError`

**Causa**: Escrita interrompida

**SoluÃ§Ã£o**:
```bash
# Backup primeiro
cp monitoring/predictions_tracking.json monitoring/predictions_tracking.json.bak

# Tente corrigir:
# 1. Abra arquivo
# 2. Verifique Ãºltima linha (pode estar incompleta)
# 3. Remova linha incompleta
# 4. Salve

# Ou resete:
echo '{"predictions": []}' > monitoring/predictions_tracking.json
```

### Problema 7: Muitos logs (disco cheio)

**Sintoma**: Disco do servidor cheio

**Causa**: Logs acumulando sem rotaÃ§Ã£o

**SoluÃ§Ã£o**:
```python
# Adicione log rotation
import logging
from logging.handlers import RotatingFileHandler

handler = RotatingFileHandler(
    LOG_FILE,
    maxBytes=10*1024*1024,  # 10 MB
    backupCount=5           # MantÃ©m 5 arquivos
)
```

Ou use `logrotate` (Linux):
```bash
# /etc/logrotate.d/predictfinance
/path/to/PredictFinance/logs/*.log {
    daily
    rotate 7
    compress
    delaycompress
    notifempty
    missingok
}
```

---

## âœ… Checklist de ConclusÃ£o

### ImplementaÃ§Ã£o

- [ ] **Logging**
  - [x] `api/monitoring.py` criado
  - [x] Integrado em `api/main.py`
  - [ ] Testado localmente
  - [ ] Logs aparecendo em `logs/predictions.log`

- [ ] **Performance Monitor**
  - [x] `src/performance_monitor.py` criado
  - [ ] PrevisÃµes sendo registradas
  - [ ] ValidaÃ§Ã£o funcionando com yfinance
  - [ ] MÃ©tricas sendo calculadas

- [ ] **Drift Detector**
  - [x] `src/drift_detector.py` criado
  - [ ] EstatÃ­sticas de referÃªncia configuradas
  - [ ] Drift detection testado
  - [ ] RelatÃ³rios sendo salvos

- [ ] **Sistema de Alertas**
  - [x] `src/alert_system.py` criado
  - [ ] Thresholds configurados
  - [ ] Alertas via logs funcionando
  - [ ] (Opcional) Slack webhook configurado

- [ ] **Uptime**
  - [x] Endpoint `/health` funcionando
  - [ ] UptimeRobot configurado
  - [ ] Alertas de downtime testados

### Testes

- [ ] `test_monitoring.py` executado com sucesso
- [ ] Todos os 5 testes passando
- [ ] Arquivos de monitoramento criados:
  - [ ] `logs/predictions.log`
  - [ ] `logs/metrics.log`
  - [ ] `monitoring/predictions_tracking.json`
  - [ ] `monitoring/performance_metrics.json`
  - [ ] `monitoring/reference_statistics.json`
  - [ ] `monitoring/drift_reports.json`
  - [ ] `monitoring/alert_history.json`

### AutomaÃ§Ã£o

- [ ] `run_daily_monitoring.py` executado manualmente
- [ ] Cron job / Task Scheduler / GitHub Actions configurado
- [ ] Primeiro relatÃ³rio diÃ¡rio gerado
- [ ] Alertas disparados corretamente (se thresholds excedidos)

### ProduÃ§Ã£o

- [ ] API no Render atualizada com logging
- [ ] Logs de produÃ§Ã£o verificados
- [ ] UptimeRobot monitorando API
- [ ] Primeiro ciclo de validaÃ§Ã£o de previsÃµes completo

### DocumentaÃ§Ã£o

- [x] `docs/FASE_8_GUIA.md` criado
- [ ] README.md atualizado
- [ ] INDEX.md atualizado
- [ ] Equipe treinada em monitoramento

### Extras (Opcional)

- [ ] Slack webhook configurado
- [ ] Email alerts configurados
- [ ] Backup automÃ¡tico de dados de monitoramento
- [ ] Dashboard Grafana/Evidently configurado

---

## ğŸ¯ PrÃ³ximos Passos

### Imediatos

1. **Executar Testes**
   ```bash
   python test_monitoring.py
   ```

2. **Configurar EstatÃ­sticas de ReferÃªncia**
   ```python
   from src.drift_detector import setup_reference_from_file
   setup_reference_from_file(Path("data/processed/B3SA3_2020-11-03_2025-10-31.csv"))
   ```

3. **Primeiro Monitoramento Manual**
   ```bash
   python run_daily_monitoring.py
   ```

4. **Deploy no Render**
   ```bash
   git add .
   git commit -m "feat: Sistema de monitoramento (Fase 8)"
   git push origin main
   ```

5. **Configurar UptimeRobot**
   - URL: https://b3sa3-api.onrender.com/health
   - Interval: 5 min

### Curto Prazo (PrÃ³xima Semana)

6. **Automatizar Monitoramento**
   - Configurar cron job / GitHub Actions

7. **Primeira ValidaÃ§Ã£o Real**
   - Aguardar 1 dia apÃ³s previsÃµes
   - Executar validaÃ§Ã£o

8. **Ajustar Thresholds**
   - Baseado em mÃ©tricas reais

### MÃ©dio Prazo (PrÃ³ximo MÃªs)

9. **Analisar TendÃªncias**
   - Verificar se modelo estÃ¡ degradando
   - Decidir se precisa re-treinar

10. **OtimizaÃ§Ãµes**
    - Slack/Email alerts
    - Dashboard visual (Grafana)
    - Banco de dados para persistÃªncia

---

## ğŸ“š ReferÃªncias

- **Evidently AI**: https://evidentlyai.com
- **FastAPI Monitoring**: https://fastapi.tiangolo.com/advanced/middleware/
- **MLOps Best Practices**: https://ml-ops.org
- **Data Drift Detection**: https://towardsdatascience.com/understanding-data-drift-monitoring
- **UptimeRobot**: https://uptimerobot.com
- **Render Logs**: https://render.com/docs/logs

---

## ğŸ‰ ConclusÃ£o da Fase 8

ParabÃ©ns! VocÃª implementou um **sistema completo de monitoramento de ML em produÃ§Ã£o**!

### O Que Foi AlcanÃ§ado

âœ… **Observabilidade Total**: Logs de todas as requisiÃ§Ãµes  
âœ… **Performance Tracking**: MÃ©tricas de erro contÃ­nuas  
âœ… **Drift Detection**: DetecÃ§Ã£o de mudanÃ§as nos dados  
âœ… **Alertas Proativos**: NotificaÃ§Ã£o de problemas  
âœ… **Uptime Monitoring**: Disponibilidade 24/7  

### ImportÃ¢ncia

Este sistema garante que:

1. **VocÃª sabe se o modelo estÃ¡ funcionando** (nÃ£o Ã© "caixa preta")
2. **Problemas sÃ£o detectados precocemente** (antes de impactar usuÃ¡rios)
3. **DecisÃµes sÃ£o data-driven** (quando re-treinar Ã© baseado em dados)
4. **Sistema Ã© confiÃ¡vel** (uptime monitorado)

### ğŸ† Projeto Completo (100%)!

**Fase 8 = Ãšltima Fase do Projeto PredictFinance!**

VocÃª agora tem um **sistema completo de ML em produÃ§Ã£o** com:

- âœ… Coleta de dados (Fase 1)
- âœ… PreparaÃ§Ã£o de dados (Fase 2)
- âœ… ExploraÃ§Ã£o de dados (Fase 3)
- âœ… Treinamento de modelo (Fase 4)
- âœ… PersistÃªncia (Fase 5)
- âœ… API REST (Fase 6)
- âœ… Deploy em produÃ§Ã£o (Fase 7)
- âœ… **Monitoramento 24/7 (Fase 8)** â† VOCÃŠ ESTÃ AQUI!

**PrÃ³ximo passo**: Manter o sistema rodando e aprender com os dados de produÃ§Ã£o! ğŸš€

---

**DocumentaÃ§Ã£o criada por**: GitHub Copilot  
**Data**: Novembro 2025  
**VersÃ£o**: 1.0  
