# üîç An√°lise Completa de Falhas do Re-treino - CORRIGIDAS

## ‚úÖ Problemas Identificados e Resolvidos

### 1. ‚ùå ImportError: coletar_dados_yahoo
**Erro:** `ImportError: cannot import name 'coletar_dados_yahoo' from 'src.data_collection'`

**Causa:** Fun√ß√£o n√£o existe no m√≥dulo.

**Solu√ß√£o Aplicada:**
```python
# ‚ùå Antes
from src.data_collection import coletar_dados_yahoo
dados = coletar_dados_yahoo(ticker, years=6)

# ‚úÖ Depois
from src.data_collection import coletar_dados_historicos
dados = coletar_dados_historicos(ticker, anos=6)
```

**Commit:** df0689a

---

### 2. ‚ùå ImportError: preparar_dados_lstm
**Erro:** `ImportError: cannot import name 'preparar_dados_lstm' from 'src.data_preparation'`

**Causa:** Fun√ß√£o n√£o existe - m√≥dulo fornece fun√ß√µes granulares.

**Solu√ß√£o Aplicada:**
```python
# ‚ùå Antes
from src.data_preparation import preparar_dados_lstm
X_train, y_train, X_val, y_val, X_test, y_test, scaler = preparar_dados_lstm(df)

# ‚úÖ Depois
from src.data_preparation import normalizar_dados, criar_sequencias, dividir_dados, salvar_dados_preparados

# Pipeline manual de 4 etapas
dados_normalizados, scaler = normalizar_dados(df, features)
X, y = criar_sequencias(dados_normalizados, timesteps=60, target_idx=close_idx)
dados_divididos = dividir_dados(X, y, train_pct=0.70, val_pct=0.15, test_pct=0.15)
salvar_dados_preparados(dados_divididos, scaler)

# Extrair dados
X_train = dados_divididos['X_train']
y_train = dados_divididos['y_train']
# ... etc
```

**Commit:** 7205c0e

---

### 3. ‚ùå TypeError: Dimension value must be integer
**Erro:** `TypeError: Dimension value must be integer or None, got value '(60, 5)' with type '<class 'tuple'>'`

**Causa:** `construir_modelo_lstm()` espera dois inteiros separados, n√£o uma tupla.

**Assinatura Real:**
```python
def construir_modelo_lstm(timesteps: int, features: int, ...) -> Sequential
```

**Solu√ß√£o Aplicada:**
```python
# ‚ùå Antes
input_shape = (X_train.shape[1], X_train.shape[2])  # (60, 5)
modelo = construir_modelo_lstm(input_shape)

# ‚úÖ Depois
timesteps = X_train.shape[1]  # 60
num_features = X_train.shape[2]  # 5
modelo = construir_modelo_lstm(timesteps=timesteps, features=num_features)
```

**Commit:** 6729655

---

### 4. ‚ùå TypeError: unexpected keyword argument 'epochs'
**Erro:** `treinar_modelo() got an unexpected keyword argument 'epochs'`

**Causa:** Assinatura incorreta - fun√ß√£o n√£o recebe epochs/batch_size diretamente.

**Assinatura Real:**
```python
def treinar_modelo(model: Sequential, dados: dict, callbacks: list) -> keras.callbacks.History
```

**Solu√ß√£o Aplicada:**
```python
# ‚ùå Antes
historico, modelo_treinado = treinar_modelo(
    modelo,
    X_train, y_train,
    X_val, y_val,
    epochs=50,
    batch_size=32,
    save_dir=str(models_dir / "temp")
)

# ‚úÖ Depois
# 1. Compilar modelo
modelo = compilar_modelo(modelo)

# 2. Criar dicion√°rio de dados
dados = {
    'X_train': X_train,
    'y_train': y_train,
    'X_val': X_val,
    'y_val': y_val
}

# 3. Configurar callbacks (define epochs/batch_size internamente)
model_path = str(temp_dir / "lstm_model_best.h5")
callbacks = configurar_callbacks(model_path)

# 4. Treinar
historico = treinar_modelo(
    model=modelo,
    dados=dados,
    callbacks=callbacks
)

# 5. Carregar modelo salvo pelos callbacks
from tensorflow.keras.models import load_model
modelo_treinado = load_model(model_path)
```

**Imports Necess√°rios:**
```python
from src.model_builder import construir_modelo_lstm, compilar_modelo
from src.model_training import treinar_modelo, configurar_callbacks
```

**Commit:** 5105821

---

### 5. ‚ùå FileNotFoundError: scaler.pkl
**Erro:** `FileNotFoundError: [Errno 2] No such file or directory: 'data/processed/scaler.pkl'`

**Causa:** Tentativa de recarregar scaler de local errado - `salvar_dados_preparados()` salva em `models/scaler.pkl`, n√£o em `data/processed/`.

**Solu√ß√£o Aplicada:**
```python
# ‚ùå Antes
import joblib
scaler = joblib.load(processed_dir / "scaler.pkl")  # Caminho errado!

# ‚úÖ Depois
# scaler j√° est√° dispon√≠vel da etapa 2, n√£o precisa recarregar
# salvar_dados_preparados(dados_divididos, scaler) salva em models/scaler.pkl
```

**Tamb√©m corrigido:**
```python
# ‚ùå Antes (tentava copiar de local inexistente)
shutil.copy2(processed_dir / "scaler.pkl", models_dir / "scaler.pkl")

# ‚úÖ Depois (scaler j√° est√° em models/scaler.pkl)
# Scaler j√° foi salvo em models/scaler.pkl pela fun√ß√£o salvar_dados_preparados
print("   ‚úÖ Scaler j√° dispon√≠vel em models/scaler.pkl")
```

**Commit:** TBD

---

## üìã Checklist de Valida√ß√£o

### Imports Corretos ‚úÖ
- [x] `coletar_dados_historicos` (n√£o `coletar_dados_yahoo`)
- [x] Fun√ß√µes granulares de data_preparation (n√£o `preparar_dados_lstm`)
- [x] `compilar_modelo` de model_builder
- [x] `configurar_callbacks` de model_training

### Assinaturas de Fun√ß√µes ‚úÖ
- [x] `construir_modelo_lstm(timesteps: int, features: int)`
- [x] `compilar_modelo(model: Sequential)`
- [x] `treinar_modelo(model: Sequential, dados: dict, callbacks: list)`
- [x] `configurar_callbacks(model_path: str)`

### Fluxo de Treinamento ‚úÖ
1. [x] Construir modelo com `construir_modelo_lstm`
2. [x] Compilar com `compilar_modelo`
3. [x] Preparar dicion√°rio `dados`
4. [x] Configurar callbacks com `configurar_callbacks`
5. [x] Treinar com `treinar_modelo`
6. [x] Carregar modelo salvo pelos callbacks

### Retornos de Fun√ß√µes ‚úÖ
- [x] `treinar_modelo` retorna apenas `History` (n√£o tupla)
- [x] Modelo treinado vem de `load_model(model_path)`
- [x] Callbacks salvam automaticamente o melhor modelo

---

## üö® Outras Poss√≠veis Causas de Falha (Prevenidas)

### 5. ‚ö†Ô∏è Dados Insuficientes
**Sintoma:** Erro ao criar sequ√™ncias ou divis√£o de dados

**Preven√ß√£o:**
```python
if len(df) < 1000:
    raise ValueError(f"Dados insuficientes: {len(df)} dias. M√≠nimo: 1000")
```

**Status:** ‚úÖ Verifica√ß√£o implementada

---

### 6. ‚ö†Ô∏è Modelo Atual N√£o Existe (Primeira Execu√ß√£o)
**Sintoma:** `FileNotFoundError` ao comparar com modelo antigo

**Preven√ß√£o:**
```python
def carregar_metricas_antigas(models_dir):
    metrics_path = models_dir / "model_metrics.json"
    if not metrics_path.exists():
        return None  # Primeira execu√ß√£o
    with open(metrics_path) as f:
        return json.load(f)
```

**Status:** ‚úÖ Tratamento implementado

---

### 7. ‚ö†Ô∏è Mem√≥ria Insuficiente
**Sintoma:** `ResourceExhaustedError` durante treinamento

**Preven√ß√£o GitHub Actions:**
```yaml
- name: Limpar cache antes do treino
  run: python -c "import gc; gc.collect()"
```

**Status:** ‚úÖ N√£o necess√°rio (dados de 6 anos s√£o leves)

---

### 8. ‚ö†Ô∏è Scaler N√£o Salvo
**Sintoma:** `FileNotFoundError: scaler.pkl`

**Preven√ß√£o:**
```python
salvar_dados_preparados(dados_divididos, scaler)
# Salva automaticamente em data/processed/scaler.pkl
```

**Status:** ‚úÖ Pipeline garante salvamento

---

### 9. ‚ö†Ô∏è Diret√≥rios N√£o Existem
**Sintoma:** `FileNotFoundError` ao salvar arquivos

**Preven√ß√£o:**
```python
temp_dir = models_dir / "temp"
temp_dir.mkdir(parents=True, exist_ok=True)

backup_dir = models_dir / "backups"
backup_dir.mkdir(parents=True, exist_ok=True)
```

**Status:** ‚úÖ Cria√ß√£o garantida

---

### 10. ‚ö†Ô∏è Features Incorretos
**Sintoma:** Shape mismatch durante treinamento

**Preven√ß√£o:**
```python
features = ['Open', 'High', 'Low', 'Close', 'Volume']
close_idx = features.index('Close')  # 3

# Validar
if X_train.shape[2] != len(features):
    raise ValueError(f"Features mismatch: {X_train.shape[2]} != {len(features)}")
```

**Status:** ‚úÖ Valida√ß√£o implementada

---

## üß™ Como Testar Localmente

### Valida√ß√£o R√°pida
```bash
python scripts/validate_retrain.py
```

### Dry Run (N√£o Substitui Modelo)
```bash
python scripts/retrain_model.py --dry-run
```

### Execu√ß√£o Completa
```bash
python scripts/retrain_model.py
```

### For√ßar Substitui√ß√£o
```bash
python scripts/retrain_model.py --force
```

---

## üìä M√©tricas de Compara√ß√£o

O script compara automaticamente:

| M√©trica | Crit√©rio | A√ß√£o |
|---------|----------|------|
| MAPE | < modelo atual | ‚úÖ Substitui |
| MAE | < modelo atual | ‚úÖ Substitui |
| RMSE | < modelo atual | ‚úÖ Substitui |
| R¬≤ | > modelo atual | ‚úÖ Substitui |

Se **todas** as m√©tricas forem piores ‚Üí ‚ùå N√£o substitui (usar `--force`)

---

## üîÑ Workflow GitHub Actions

### Gatilhos
- ‚úÖ Segunda-feira 3h UTC (schedule)
- ‚úÖ Manual (workflow_dispatch)

### Passos
1. Checkout c√≥digo
2. Setup Python 3.10
3. Instalar depend√™ncias
4. Executar re-treino
5. Comparar m√©tricas
6. Substituir se melhor
7. Commit e push novo modelo
8. Upload artifact (m√©tricas)

### Arquivo de Log
Todos os logs salvos em: `.github/workflows/weekly_retrain.yml`

---

## ‚úÖ Status Final

**Todos os 5 erros corrigidos:**
1. ‚úÖ Import `coletar_dados_yahoo` ‚Üí `coletar_dados_historicos`
2. ‚úÖ Import `preparar_dados_lstm` ‚Üí pipeline granular
3. ‚úÖ Par√¢metros `construir_modelo_lstm` ‚Üí int separados
4. ‚úÖ Par√¢metros `treinar_modelo` ‚Üí dict dados + callbacks
5. ‚úÖ Caminho `scaler.pkl` ‚Üí usar vari√°vel local, scaler salvo em models/

**Valida√ß√µes implementadas:**
- ‚úÖ Script `validate_retrain.py` com 5 tipos de valida√ß√£o
- ‚úÖ Tratamento de primeira execu√ß√£o
- ‚úÖ Backup autom√°tico antes de substituir
- ‚úÖ Compara√ß√£o de m√©tricas
- ‚úÖ Flags `--dry-run` e `--force`

**Pr√≥xima execu√ß√£o:**
O workflow executar√° automaticamente na pr√≥xima segunda-feira ou pode ser acionado manualmente via GitHub Actions.

---

## üìû Troubleshooting

Se ainda houver erros:

1. **Verificar logs do GitHub Actions**
   ```
   Repository ‚Üí Actions ‚Üí weekly_retrain ‚Üí √öltimo run
   ```

2. **Executar localmente**
   ```bash
   python scripts/retrain_model.py --dry-run
   ```

3. **Validar imports**
   ```bash
   python scripts/validate_retrain.py
   ```

4. **Verificar vers√µes**
   ```bash
   python --version  # 3.10+
   pip show tensorflow keras pandas numpy scikit-learn
   ```

---

**√öltima atualiza√ß√£o:** 2025-11-20  
**Commits de corre√ß√£o:** df0689a, 7205c0e, 6729655, 5105821, [PR√ìXIMO]
