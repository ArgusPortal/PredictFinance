# üöÄ Deploy da API B3SA3.SA no Render

## üìã Pr√©-requisitos Completos

Antes de iniciar o deploy, certifique-se de que todos os artefatos est√£o prontos:

### ‚úÖ Checklist de Arquivos

- [x] `api/main.py` - Aplica√ß√£o FastAPI
- [x] `api/schemas.py` - Modelos Pydantic
- [x] `api/__init__.py` - Inicializa√ß√£o do m√≥dulo
- [x] `models/lstm_model_best.h5` - Modelo treinado (0.39 MB)
- [x] `models/scaler.pkl` - Scaler MinMax (0.86 KB)
- [x] `requirements-render.txt` - Depend√™ncias otimizadas
- [x] `render.yaml` - Configura√ß√£o do Render
- [x] `Procfile` - Comando de inicializa√ß√£o (backup)
- [x] `.gitignore` - Configurado para incluir modelos

---

## üì¶ Prepara√ß√£o dos Arquivos

### 1. Verificar Artefatos do Modelo

```bash
# Verificar exist√™ncia e tamanho dos arquivos
ls -lh models/

# Sa√≠da esperada:
# lstm_model_best.h5     (0.39 MB)
# scaler.pkl             (0.86 KB)
# model_architecture.json
```

### 2. Depend√™ncias Otimizadas

O arquivo `requirements-render.txt` foi criado com depend√™ncias otimizadas:

```txt
# Core Framework
fastapi==0.109.2
uvicorn[standard]==0.27.1
pydantic==2.5.3

# Machine Learning (CPU only)
tensorflow-cpu==2.15.1
scikit-learn==1.3.2
numpy==1.24.4

# Data Processing
pandas==2.0.3

# Model Persistence
joblib==1.5.2
```

**Motivo do tensorflow-cpu**: Reduz significativamente o tamanho do build (~500MB vs ~2GB).

### 3. Configura√ß√£o do Render

Arquivo `render.yaml` criado:

```yaml
services:
  - type: web
    name: b3sa3-api
    env: python
    region: oregon
    plan: free
    buildCommand: pip install -r requirements-render.txt
    startCommand: uvicorn api.main:app --host 0.0.0.0 --port $PORT
    envVars:
      - key: PYTHON_VERSION
        value: 3.10.11
```

---

## üîß Configura√ß√£o do Reposit√≥rio GitHub

### Passo 1: Commitar Arquivos

```bash
# Verificar status
git status

# Adicionar novos arquivos de deploy
git add requirements-render.txt
git add render.yaml
git add Procfile
git add .gitignore

# Adicionar modelos (necess√°rios para deploy)
git add models/lstm_model_best.h5
git add models/scaler.pkl
git add models/model_architecture.json

# Adicionar c√≥digo da API
git add api/
git add run_api.py

# Commit
git commit -m "feat: Adicionar configura√ß√£o para deploy no Render (Fase 7)"

# Push para GitHub
git push origin main
```

**‚ö†Ô∏è IMPORTANTE**: Certifique-se de que o reposit√≥rio est√° configurado:

```bash
# Verificar remote
git remote -v

# Se necess√°rio, adicionar remote
git remote add origin https://github.com/ArgusPortal/PredictFinance.git
```

---

## üåê Deploy no Render

### Passo 1: Criar Conta no Render

1. Acesse: https://render.com/
2. Clique em **"Get Started for Free"**
3. Fa√ßa login com sua conta GitHub
4. Autorize o Render a acessar seus reposit√≥rios

### Passo 2: Criar Novo Web Service

1. No Dashboard do Render, clique em **"New +"**
2. Selecione **"Web Service"**
3. Conecte seu reposit√≥rio:
   - Se aparecer a lista, selecione **"PredictFinance"**
   - Se n√£o aparecer, clique em **"Configure account"** e autorize acesso

### Passo 3: Configurar o Service

Preencha os campos:

| Campo | Valor |
|-------|-------|
| **Name** | `b3sa3-api` (ou nome de sua prefer√™ncia) |
| **Region** | `Oregon (US West)` (free tier) |
| **Branch** | `main` |
| **Root Directory** | (deixar em branco) |
| **Runtime** | `Python 3` |
| **Build Command** | `pip install -r requirements-render.txt` |
| **Start Command** | `uvicorn api.main:app --host 0.0.0.0 --port $PORT` |
| **Plan** | `Free` |

### Passo 4: Vari√°veis de Ambiente (Opcional)

N√£o s√£o necess√°rias vari√°veis de ambiente adicionais, pois:
- ‚úÖ Modelo e scaler est√£o no reposit√≥rio
- ‚úÖ N√£o h√° credenciais externas
- ‚úÖ PORT √© definido automaticamente pelo Render

Se quiser adicionar (opcional):

| Key | Value |
|-----|-------|
| `PYTHON_VERSION` | `3.10.11` |

### Passo 5: Iniciar Deploy

1. Clique em **"Create Web Service"**
2. O Render iniciar√° o build automaticamente
3. Acompanhe os logs em tempo real

---

## üìä Monitoramento do Build

### Logs Esperados

Durante o build, voc√™ ver√°:

```
==> Cloning from https://github.com/ArgusPortal/PredictFinance...
==> Checking out commit abc123...
==> Installing dependencies from requirements-render.txt
    Collecting fastapi==0.109.2
    Collecting uvicorn[standard]==0.27.1
    Collecting tensorflow-cpu==2.15.1
    ...
==> Build successful
==> Starting service with: uvicorn api.main:app --host 0.0.0.0 --port $PORT
üöÄ Iniciando API...
üìÇ Carregando artefatos do modelo...
   ‚îî‚îÄ Carregando modelo: models/lstm_model_best.h5
   ‚úÖ Modelo carregado com sucesso!
   ‚îî‚îÄ Carregando scaler: models/scaler.pkl
   ‚úÖ Scaler carregado com sucesso!
‚úÖ API pronta para receber requisi√ß√µes!
INFO:     Uvicorn running on http://0.0.0.0:10000
```

### Tempo de Build Estimado

- **Install dependencies**: 3-5 minutos
- **Start service**: 10-15 segundos
- **Total**: ~5 minutos

---

## üß™ Testes da API em Produ√ß√£o

### Obter URL da API

Ap√≥s deploy bem-sucedido:

1. No Dashboard do Render, copie a URL do servi√ßo
2. Formato: `https://b3sa3-api.onrender.com`

### Teste 1: Health Check

```bash
curl https://b3sa3-api.onrender.com/
```

**Resposta esperada**:
```json
{
  "status": "ativo",
  "mensagem": "API de previs√£o B3SA3.SA operacional",
  "versao": "1.0.0",
  "modelo_carregado": true
}
```

### Teste 2: Informa√ß√µes do Modelo

```bash
curl https://b3sa3-api.onrender.com/info
```

**Resposta esperada**:
```json
{
  "nome": "LSTM_B3SA3_Predictor",
  "arquitetura": "LSTM - 2 camadas (64 ‚Üí 32 unidades) + Dropout (0.2)",
  "parametros": 30369,
  "metricas": {
    "RMSE": "R$ 0.26",
    "MAE": "R$ 0.20",
    "MAPE": "1.53%",
    "R2": "0.9351"
  }
}
```

### Teste 3: Fazer Previs√£o

```bash
# Op√ß√£o 1: Previs√£o AUTOM√ÅTICA (recomendado)
curl -X POST https://b3sa3-api.onrender.com/predict/auto \
  -H "Content-Type: application/json" \
  -d '{"ticker": "B3SA3.SA"}'

# Op√ß√£o 2: Previs√£o com dados manuais (60 dias √ó 5 features)
# Veja docs/FASE_7_GUIA.md para exemplo completo
```

**Resposta esperada**:
```json
{
  "preco_previsto": 11.52,
  "confianca": "alta",
  "mensagem": "Previs√£o para B3SA3.SA gerada com sucesso. Modelo MAPE 1.53%..."
}
```

### Teste 4: Documenta√ß√£o Swagger

Acesse no navegador:

```
https://b3sa3-api.onrender.com/docs
```

Voc√™ ver√° a interface interativa do Swagger UI.

---

## üêç Script de Teste Python

Criar arquivo `test_production.py`:

```python
"""
Script de Teste da API em Produ√ß√£o (Render)
"""

import requests
import json

# Substituir pela sua URL do Render
API_URL = "https://b3sa3-api.onrender.com"

def testar_api_producao():
    """Testa todos os endpoints da API em produ√ß√£o."""
    
    print("=" * 70)
    print(" " * 15 + "üß™ TESTE DA API EM PRODU√á√ÉO")
    print("=" * 70)
    print(f"\nüìç URL: {API_URL}\n")
    
    # Teste 1: Health Check
    print("1Ô∏è‚É£  Health Check")
    print("-" * 70)
    try:
        response = requests.get(f"{API_URL}/")
        print(f"Status: {response.status_code}")
        print(f"Resposta: {json.dumps(response.json(), indent=2, ensure_ascii=False)}")
        print("‚úÖ Passou!\n")
    except Exception as e:
        print(f"‚ùå Erro: {e}\n")
        return False
    
    # Teste 2: Info do Modelo
    print("2Ô∏è‚É£  Informa√ß√µes do Modelo")
    print("-" * 70)
    try:
        response = requests.get(f"{API_URL}/info")
        data = response.json()
        print(f"Nome: {data['nome']}")
        print(f"MAPE: {data['metricas']['MAPE']}")
        print("‚úÖ Passou!\n")
    except Exception as e:
        print(f"‚ùå Erro: {e}\n")
        return False
    
    # Teste 3: Previs√£o
    print("3Ô∏è‚É£  Fazer Previs√£o")
    print("-" * 70)
    try:
        import numpy as np
        np.random.seed(42)
        prices = [12.5 + np.random.randn() * 0.3 for _ in range(60)]
        
        response = requests.post(
            f"{API_URL}/predict",
            json={"prices": prices}
        )
        
        data = response.json()
        print(f"Pre√ßo Previsto: R$ {data['preco_previsto']:.2f}")
        print(f"Confian√ßa: {data['confianca']}")
        print("‚úÖ Passou!\n")
    except Exception as e:
        print(f"‚ùå Erro: {e}\n")
        return False
    
    print("=" * 70)
    print(" " * 20 + "‚úÖ TODOS OS TESTES PASSARAM!")
    print("=" * 70)
    print(f"\nüìñ Documenta√ß√£o: {API_URL}/docs")
    return True

if __name__ == "__main__":
    testar_api_producao()
```

**Executar**:
```bash
python test_production.py
```

---

## ‚öôÔ∏è Configura√ß√µes Adicionais (Opcional)

### Auto-Deploy

O Render automaticamente faz redeploy quando voc√™:
- Faz push para a branch `main`
- Atualiza o c√≥digo no GitHub

### Monitoramento

No Dashboard do Render:
- **Logs**: Ver logs em tempo real
- **Metrics**: CPU, mem√≥ria, requisi√ß√µes
- **Events**: Hist√≥rico de deploys

### Dom√≠nio Customizado (Opcional)

1. No Render Dashboard, v√° em **Settings**
2. Em **Custom Domain**, adicione seu dom√≠nio
3. Configure DNS conforme instru√ß√µes

---

## üö® Troubleshooting

### Problema 1: Build Falha por Falta de Mem√≥ria

**Sintoma**: `MemoryError during pip install`

**Solu√ß√£o**:
- O `tensorflow-cpu` j√° est√° otimizado
- Considere usar `tensorflow-cpu==2.15.1` (vers√£o atual)
- Free tier do Render tem limite de 512MB RAM

### Problema 2: Modelo N√£o Carrega

**Sintoma**: `FileNotFoundError: modelo n√£o encontrado`

**Solu√ß√£o**:
```bash
# Verificar se modelos est√£o no Git
git ls-files | grep models/

# Adicionar se necess√°rio
git add -f models/lstm_model_best.h5
git add -f models/scaler.pkl
git commit -m "fix: Adicionar modelos para deploy"
git push
```

### Problema 3: Porta Incorreta

**Sintoma**: Service n√£o inicia

**Solu√ß√£o**: Sempre use `$PORT` no comando:
```bash
uvicorn api.main:app --host 0.0.0.0 --port $PORT
```

### Problema 4: Import Error

**Sintoma**: `ModuleNotFoundError: No module named 'api'`

**Solu√ß√£o**: Certifique-se de que `api/__init__.py` existe no reposit√≥rio.

### Problema 5: Service em Sleep (Free Tier)

**Sintoma**: API demora para responder ap√≥s inatividade

**Explica√ß√£o**: 
- Free tier do Render coloca servi√ßos inativos em "sleep" ap√≥s 15 minutos
- Primeira requisi√ß√£o ap√≥s sleep leva ~30 segundos
- Requisi√ß√µes subsequentes s√£o r√°pidas

**Solu√ß√µes**:
1. Aceitar o delay (comportamento normal do free tier)
2. Fazer ping peri√≥dico (n√£o recomendado, viola ToS)
3. Upgrade para plano pago ($7/m√™s)

---

## üìä Limita√ß√µes do Free Tier

| Recurso | Free Tier |
|---------|-----------|
| **RAM** | 512 MB |
| **CPU** | Shared |
| **Bandwidth** | 100 GB/m√™s |
| **Build Time** | 500 horas/m√™s |
| **Sleep ap√≥s inatividade** | 15 minutos |
| **Custom Domain** | ‚úÖ Sim |
| **HTTPS** | ‚úÖ Sim (autom√°tico) |

---

## üéØ Checklist de Deploy

- [ ] C√≥digo commitado no GitHub
- [ ] Modelos (`lstm_model_best.h5`, `scaler.pkl`) no reposit√≥rio
- [ ] `requirements-render.txt` configurado
- [ ] `render.yaml` criado
- [ ] Conta criada no Render.com
- [ ] Web Service criado
- [ ] Build conclu√≠do com sucesso
- [ ] API respondendo na URL p√∫blica
- [ ] Health check funcionando
- [ ] Endpoint `/predict` testado
- [ ] Documenta√ß√£o Swagger acess√≠vel

---

## üîó URLs de Refer√™ncia

- **Render Docs**: https://render.com/docs/deploy-fastapi
- **Render Dashboard**: https://dashboard.render.com/
- **GitHub Repo**: https://github.com/ArgusPortal/PredictFinance

---

## üìù Pr√≥ximos Passos

Ap√≥s deploy bem-sucedido:

1. ‚úÖ Anotar URL p√∫blica da API
2. ‚úÖ Testar todos os endpoints
3. ‚úÖ Atualizar documenta√ß√£o com URL de produ√ß√£o
4. ‚û°Ô∏è Prosseguir para Fase 8 (Monitoramento e Finaliza√ß√£o)

---

**Elaborado por**: Sistema PredictFinance  
**Data**: 02/11/2025  
**Vers√£o**: 1.0.0
