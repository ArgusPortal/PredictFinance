"""
===================================================================
PredictFinance - M√≥dulo de Treinamento e Avalia√ß√£o do Modelo LSTM
Treinamento, predi√ß√£o e c√°lculo de m√©tricas de desempenho
===================================================================

Este m√≥dulo √© respons√°vel pela Fase 4 do projeto:
- Carregamento dos dados preparados e do modelo
- Treinamento do modelo LSTM com validation_data
- Avalia√ß√£o em dados de teste
- C√°lculo de m√©tricas (MSE, RMSE, MAE)
- Visualiza√ß√£o de resultados (real vs previsto)
- An√°lise e interpreta√ß√£o dos resultados

Autor: ArgusPortal
Data: 02/11/2025
Vers√£o: 1.0.0
"""

import os
import json
import warnings
from datetime import datetime
from typing import Tuple, Dict

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

# Importar fun√ß√£o de constru√ß√£o do modelo
import sys
sys.path.append(os.path.dirname(__file__))
from model_builder import construir_modelo_lstm, compilar_modelo

warnings.filterwarnings('ignore')

# ===================================================================
# CONFIGURA√á√ïES
# ===================================================================

# Diret√≥rios
PROCESSED_DIR = "data/processed"
MODELS_DIR = "models"
DOCS_DIR = "docs/training"

# Par√¢metros de treinamento
EPOCHS = 50           # N√∫mero de √©pocas
BATCH_SIZE = 32       # Tamanho do batch
VERBOSE = 1           # N√≠vel de verbosidade (0=silencioso, 1=barra de progresso, 2=uma linha por √©poca)

# Early Stopping
EARLY_STOPPING_PATIENCE = 10  # Paci√™ncia para early stopping
RESTORE_BEST_WEIGHTS = True   # Restaurar melhores pesos

# Criar diret√≥rios
os.makedirs(MODELS_DIR, exist_ok=True)
os.makedirs(DOCS_DIR, exist_ok=True)

# Configura√ß√£o de visualiza√ß√µes
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")


# ===================================================================
# FUN√á√ïES DE CARREGAMENTO
# ===================================================================

def carregar_dados_preparados() -> Dict[str, np.ndarray]:
    """
    Carrega os dados preparados da Fase 2.
    
    Retorna:
    --------
    dict
        Dicion√°rio com arrays X_train, y_train, X_val, y_val, X_test, y_test
    """
    print(f"\n{'='*70}")
    print(f"FASE 4: TREINAMENTO E AVALIA√á√ÉO DO MODELO LSTM")
    print(f"{'='*70}\n")
    
    print(f"üìÇ Carregando Dados Preparados:")
    print(f"{'‚îÄ'*70}\n")
    
    dados = {}
    arquivos = ['X_train', 'y_train', 'X_val', 'y_val', 'X_test', 'y_test']
    
    for arquivo in arquivos:
        filepath = os.path.join(PROCESSED_DIR, f"{arquivo}.npy")
        dados[arquivo] = np.load(filepath)
        print(f"   ‚úÖ {arquivo:10s} carregado - Shape: {dados[arquivo].shape}")
    
    print()
    return dados


def carregar_scaler():
    """
    Carrega o scaler salvo na Fase 2.
    
    Retorna:
    --------
    MinMaxScaler
        Scaler ajustado
    """
    print(f"üîÑ Carregando Scaler:")
    print(f"{'‚îÄ'*70}\n")
    
    scaler_path = os.path.join(MODELS_DIR, "scaler.pkl")
    scaler = joblib.load(scaler_path)
    
    print(f"   ‚úÖ Scaler carregado: {scaler_path}")
    print(f"   üìä Range de normaliza√ß√£o: {scaler.feature_range}\n")
    
    return scaler


# ===================================================================
# FUN√á√ïES DE TREINAMENTO
# ===================================================================

def configurar_callbacks(model_path: str) -> list:
    """
    Configura callbacks para o treinamento.
    
    Par√¢metros:
    -----------
    model_path : str
        Caminho para salvar o melhor modelo
        
    Retorna:
    --------
    list
        Lista de callbacks configurados
    """
    print(f"‚öôÔ∏è  Configurando Callbacks:")
    print(f"{'‚îÄ'*70}\n")
    
    callbacks = []
    
    # Early Stopping
    early_stop = EarlyStopping(
        monitor='val_loss',
        patience=EARLY_STOPPING_PATIENCE,
        restore_best_weights=RESTORE_BEST_WEIGHTS,
        verbose=1,
        mode='min'
    )
    callbacks.append(early_stop)
    print(f"   ‚úÖ Early Stopping configurado:")
    print(f"      ‚Ä¢ Monitor: val_loss")
    print(f"      ‚Ä¢ Paci√™ncia: {EARLY_STOPPING_PATIENCE} √©pocas")
    print(f"      ‚Ä¢ Restaurar melhores pesos: {RESTORE_BEST_WEIGHTS}\n")
    
    # Model Checkpoint
    checkpoint = ModelCheckpoint(
        filepath=model_path,
        monitor='val_loss',
        save_best_only=True,
        verbose=1,
        mode='min'
    )
    callbacks.append(checkpoint)
    print(f"   ‚úÖ Model Checkpoint configurado:")
    print(f"      ‚Ä¢ Salvando em: {model_path}")
    print(f"      ‚Ä¢ Monitor: val_loss")
    print(f"      ‚Ä¢ Salvar apenas o melhor: True\n")
    
    # Reduce Learning Rate on Plateau
    reduce_lr = ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1,
        mode='min'
    )
    callbacks.append(reduce_lr)
    print(f"   ‚úÖ Reduce LR on Plateau configurado:")
    print(f"      ‚Ä¢ Monitor: val_loss")
    print(f"      ‚Ä¢ Fator de redu√ß√£o: 0.5")
    print(f"      ‚Ä¢ Paci√™ncia: 5 √©pocas\n")
    
    return callbacks


def treinar_modelo(model: Sequential, dados: dict, callbacks: list) -> keras.callbacks.History:
    """
    Treina o modelo LSTM.
    
    Par√¢metros:
    -----------
    model : Sequential
        Modelo compilado
    dados : dict
        Dicion√°rio com dados de treino e valida√ß√£o
    callbacks : list
        Lista de callbacks
        
    Retorna:
    --------
    History
        Hist√≥rico do treinamento
    """
    print(f"üöÄ Iniciando Treinamento:")
    print(f"{'‚îÄ'*70}\n")
    
    print(f"   üìä Configura√ß√µes:")
    print(f"      ‚Ä¢ √âpocas: {EPOCHS}")
    print(f"      ‚Ä¢ Batch Size: {BATCH_SIZE}")
    print(f"      ‚Ä¢ Amostras de Treino: {len(dados['X_train'])}")
    print(f"      ‚Ä¢ Amostras de Valida√ß√£o: {len(dados['X_val'])}\n")
    
    print(f"{'‚îÄ'*70}")
    print(f"Treinamento em andamento...\n")
    
    inicio = datetime.now()
    
    history = model.fit(
        dados['X_train'], 
        dados['y_train'],
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        validation_data=(dados['X_val'], dados['y_val']),
        callbacks=callbacks,
        verbose=VERBOSE
    )
    
    fim = datetime.now()
    duracao = (fim - inicio).total_seconds()
    
    print(f"\n{'‚îÄ'*70}")
    print(f"‚úÖ Treinamento Conclu√≠do!")
    print(f"   ‚è±Ô∏è  Dura√ß√£o: {duracao:.2f} segundos ({duracao/60:.2f} minutos)")
    print(f"   üìà √âpocas executadas: {len(history.history['loss'])}\n")
    
    return history


# ===================================================================
# FUN√á√ïES DE AVALIA√á√ÉO
# ===================================================================

def fazer_predicoes(model: Sequential, X_test: np.ndarray, 
                    scaler, feature_idx: int = 3) -> Tuple[np.ndarray, np.ndarray]:
    """
    Faz predi√ß√µes no conjunto de teste e inverte a escala.
    
    Par√¢metros:
    -----------
    model : Sequential
        Modelo treinado
    X_test : np.ndarray
        Dados de teste
    scaler : MinMaxScaler
        Scaler para inverter normaliza√ß√£o
    feature_idx : int
        √çndice da feature Close (padr√£o: 3)
        
    Retorna:
    --------
    tuple
        (predi√ß√µes_escala_original, reais_escala_original)
    """
    print(f"üîÆ Fazendo Predi√ß√µes:")
    print(f"{'‚îÄ'*70}\n")
    
    # Predi√ß√µes normalizadas
    print(f"   üìä Predizendo em {len(X_test)} amostras...")
    predicoes_norm = model.predict(X_test, verbose=0)
    print(f"   ‚úÖ Predi√ß√µes conclu√≠das - Shape: {predicoes_norm.shape}\n")
    
    # Inverter escala das predi√ß√µes
    print(f"   üîÑ Invertendo normaliza√ß√£o...")
    
    # Criar array com todas as features (usar √∫ltimos valores de X_test)
    # e substituir apenas a coluna Close pelas predi√ß√µes
    ultima_sequencia = X_test[:, -1, :]  # Pegar √∫ltimo timestep de cada sequ√™ncia
    
    # Criar c√≥pia para predi√ß√µes
    predicoes_full = np.copy(ultima_sequencia)
    predicoes_full[:, feature_idx] = predicoes_norm.flatten()
    
    # Inverter escala
    predicoes_original = scaler.inverse_transform(predicoes_full)[:, feature_idx]
    
    print(f"   ‚úÖ Escala invertida - Predi√ß√µes em valores originais\n")
    
    return predicoes_original, predicoes_norm


def calcular_metricas(y_true: np.ndarray, y_pred: np.ndarray, 
                      y_true_norm: np.ndarray, y_pred_norm: np.ndarray) -> dict:
    """
    Calcula m√©tricas de desempenho.
    
    Par√¢metros:
    -----------
    y_true : np.ndarray
        Valores reais (escala original)
    y_pred : np.ndarray
        Valores preditos (escala original)
    y_true_norm : np.ndarray
        Valores reais (normalizados)
    y_pred_norm : np.ndarray
        Valores preditos (normalizados)
        
    Retorna:
    --------
    dict
        Dicion√°rio com m√©tricas calculadas
    """
    print(f"üìè Calculando M√©tricas de Desempenho:")
    print(f"{'‚îÄ'*70}\n")
    
    # M√©tricas em escala original
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    # MAPE (Mean Absolute Percentage Error)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    
    # Estat√≠sticas dos dados
    preco_medio = np.mean(y_true)
    preco_min = np.min(y_true)
    preco_max = np.max(y_true)
    
    # Erro percentual em rela√ß√£o ao pre√ßo m√©dio
    erro_pct_medio = (rmse / preco_medio) * 100
    
    print(f"   üìä M√©tricas em Escala Original (R$):")
    print(f"      ‚Ä¢ MSE (Mean Squared Error):     {mse:>12.4f}")
    print(f"      ‚Ä¢ RMSE (Root Mean Squared Error): {rmse:>10.4f}")
    print(f"      ‚Ä¢ MAE (Mean Absolute Error):    {mae:>12.4f}")
    print(f"      ‚Ä¢ MAPE (Mean Abs Percentage Error): {mape:>8.2f}%")
    print(f"      ‚Ä¢ R¬≤ Score:                     {r2:>12.4f}\n")
    
    print(f"   üìà Estat√≠sticas dos Dados de Teste:")
    print(f"      ‚Ä¢ Pre√ßo M√©dio:   R$ {preco_medio:>10.2f}")
    print(f"      ‚Ä¢ Pre√ßo M√≠nimo:  R$ {preco_min:>10.2f}")
    print(f"      ‚Ä¢ Pre√ßo M√°ximo:  R$ {preco_max:>10.2f}\n")
    
    print(f"   üéØ An√°lise de Erro:")
    print(f"      ‚Ä¢ RMSE vs Pre√ßo M√©dio: {erro_pct_medio:.2f}%")
    
    if erro_pct_medio < 5:
        print(f"      ‚Ä¢ Avalia√ß√£o: ‚úÖ Excelente (< 5%)")
    elif erro_pct_medio < 10:
        print(f"      ‚Ä¢ Avalia√ß√£o: ‚úÖ Bom (5-10%)")
    elif erro_pct_medio < 15:
        print(f"      ‚Ä¢ Avalia√ß√£o: ‚ö†Ô∏è Aceit√°vel (10-15%)")
    else:
        print(f"      ‚Ä¢ Avalia√ß√£o: ‚ùå Necessita melhorias (> 15%)")
    
    print()
    
    metricas = {
        'mse': float(mse),
        'rmse': float(rmse),
        'mae': float(mae),
        'mape': float(mape),
        'r2_score': float(r2),
        'preco_medio': float(preco_medio),
        'preco_min': float(preco_min),
        'preco_max': float(preco_max),
        'erro_pct_medio': float(erro_pct_medio)
    }
    
    return metricas


# ===================================================================
# FUN√á√ïES DE VISUALIZA√á√ÉO
# ===================================================================

def visualizar_curvas_aprendizado(history: keras.callbacks.History) -> None:
    """
    Visualiza curvas de aprendizado (loss e MAE).
    
    Par√¢metros:
    -----------
    history : History
        Hist√≥rico do treinamento
    """
    print(f"üìä Gerando Curvas de Aprendizado:")
    print(f"{'‚îÄ'*70}\n")
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    fig.suptitle('Curvas de Aprendizado - Treinamento LSTM', 
                 fontsize=16, fontweight='bold')
    
    # Loss
    ax1 = axes[0]
    ax1.plot(history.history['loss'], label='Treino', linewidth=2)
    ax1.plot(history.history['val_loss'], label='Valida√ß√£o', linewidth=2)
    ax1.set_title('Fun√ß√£o de Perda (MSE)', fontweight='bold', fontsize=12)
    ax1.set_xlabel('√âpoca')
    ax1.set_ylabel('Loss (MSE)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # MAE
    ax2 = axes[1]
    ax2.plot(history.history['mae'], label='Treino', linewidth=2)
    ax2.plot(history.history['val_mae'], label='Valida√ß√£o', linewidth=2)
    ax2.set_title('Erro Absoluto M√©dio (MAE)', fontweight='bold', fontsize=12)
    ax2.set_xlabel('√âpoca')
    ax2.set_ylabel('MAE')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # Salvar
    plot_path = os.path.join(DOCS_DIR, 'curvas_aprendizado.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    print(f"   üíæ Curvas salvas: {plot_path}\n")
    
    plt.close()


def visualizar_predicoes(y_true: np.ndarray, y_pred: np.ndarray, 
                        metricas: dict) -> None:
    """
    Visualiza predi√ß√µes vs valores reais.
    
    Par√¢metros:
    -----------
    y_true : np.ndarray
        Valores reais
    y_pred : np.ndarray
        Valores preditos
    metricas : dict
        M√©tricas calculadas
    """
    print(f"üìà Gerando Gr√°fico de Predi√ß√µes:")
    print(f"{'‚îÄ'*70}\n")
    
    fig, axes = plt.subplots(2, 1, figsize=(15, 10))
    fig.suptitle('Avalia√ß√£o do Modelo LSTM - B3SA3.SA', 
                 fontsize=16, fontweight='bold')
    
    # Gr√°fico 1: S√©rie temporal
    ax1 = axes[0]
    indices = np.arange(len(y_true))
    
    ax1.plot(indices, y_true, label='Pre√ßo Real', 
             linewidth=2, alpha=0.7, color='blue')
    ax1.plot(indices, y_pred, label='Pre√ßo Previsto', 
             linewidth=2, alpha=0.7, color='red')
    
    ax1.set_title('Compara√ß√£o: Pre√ßo Real vs Previsto (Conjunto de Teste)', 
                  fontweight='bold', fontsize=12)
    ax1.set_xlabel('Amostras (Dias)')
    ax1.set_ylabel('Pre√ßo de Fechamento (R$)')
    ax1.legend(loc='best')
    ax1.grid(True, alpha=0.3)
    
    # Adicionar m√©tricas no gr√°fico
    textstr = f'RMSE: R$ {metricas["rmse"]:.2f}\nMAE: R$ {metricas["mae"]:.2f}\nMAPE: {metricas["mape"]:.2f}%\nR¬≤: {metricas["r2_score"]:.4f}'
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
    ax1.text(0.02, 0.98, textstr, transform=ax1.transAxes, fontsize=10,
             verticalalignment='top', bbox=props)
    
    # Gr√°fico 2: Scatter plot
    ax2 = axes[1]
    ax2.scatter(y_true, y_pred, alpha=0.5, s=30)
    
    # Linha de identidade (predi√ß√£o perfeita)
    min_val = min(y_true.min(), y_pred.min())
    max_val = max(y_true.max(), y_pred.max())
    ax2.plot([min_val, max_val], [min_val, max_val], 
             'r--', linewidth=2, label='Predi√ß√£o Perfeita')
    
    ax2.set_title('Dispers√£o: Valores Reais vs Previstos', 
                  fontweight='bold', fontsize=12)
    ax2.set_xlabel('Pre√ßo Real (R$)')
    ax2.set_ylabel('Pre√ßo Previsto (R$)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # Salvar
    plot_path = os.path.join(DOCS_DIR, 'resultado_teste.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    print(f"   üíæ Gr√°fico salvo: {plot_path}\n")
    
    plt.close()


# ===================================================================
# FUN√á√ïES DE PERSIST√äNCIA
# ===================================================================

def salvar_resultados(history: keras.callbacks.History, metricas: dict) -> None:
    """
    Salva resultados do treinamento e avalia√ß√£o.
    
    Par√¢metros:
    -----------
    history : History
        Hist√≥rico do treinamento
    metricas : dict
        M√©tricas calculadas
    """
    print(f"üíæ Salvando Resultados:")
    print(f"{'‚îÄ'*70}\n")
    
    # Preparar dados do hist√≥rico
    historico = {
        'loss': [float(x) for x in history.history['loss']],
        'val_loss': [float(x) for x in history.history['val_loss']],
        'mae': [float(x) for x in history.history['mae']],
        'val_mae': [float(x) for x in history.history['val_mae']],
        'epocas': len(history.history['loss'])
    }
    
    # Criar log completo
    log_data = {
        'timestamp': datetime.now().isoformat(),
        'treinamento': {
            'epocas_configuradas': EPOCHS,
            'epocas_executadas': historico['epocas'],
            'batch_size': BATCH_SIZE,
            'early_stopping_patience': EARLY_STOPPING_PATIENCE,
            'final_train_loss': historico['loss'][-1],
            'final_val_loss': historico['val_loss'][-1],
            'final_train_mae': historico['mae'][-1],
            'final_val_mae': historico['val_mae'][-1],
            'best_val_loss': float(min(historico['val_loss'])),
            'best_epoch': int(np.argmin(historico['val_loss']) + 1)
        },
        'metricas_teste': metricas,
        'historico': historico,
        'interpretacao': interpretar_resultados(metricas, historico)
    }
    
    # Salvar JSON
    log_path = os.path.join(DOCS_DIR, 'training_results.json')
    with open(log_path, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, indent=4, ensure_ascii=False)
    
    tamanho_kb = os.path.getsize(log_path) / 1024
    print(f"   ‚úÖ Resultados salvos: {log_path} ({tamanho_kb:.2f} KB)\n")


def interpretar_resultados(metricas: dict, historico: dict) -> dict:
    """
    Interpreta resultados e gera an√°lise qualitativa.
    
    Par√¢metros:
    -----------
    metricas : dict
        M√©tricas calculadas
    historico : dict
        Hist√≥rico do treinamento
        
    Retorna:
    --------
    dict
        Interpreta√ß√£o dos resultados
    """
    interpretacao = {}
    
    # Avaliar qualidade do modelo
    erro_pct = metricas['erro_pct_medio']
    
    if erro_pct < 5:
        interpretacao['qualidade'] = 'Excelente'
        interpretacao['comentario'] = 'O modelo apresenta erro muito baixo em rela√ß√£o ao pre√ßo m√©dio.'
    elif erro_pct < 10:
        interpretacao['qualidade'] = 'Boa'
        interpretacao['comentario'] = 'O modelo apresenta erro aceit√°vel e bom desempenho preditivo.'
    elif erro_pct < 15:
        interpretacao['qualidade'] = 'Aceit√°vel'
        interpretacao['comentario'] = 'O modelo funciona mas pode ser melhorado com ajustes.'
    else:
        interpretacao['qualidade'] = 'Requer melhorias'
        interpretacao['comentario'] = 'O modelo precisa de ajustes significativos na arquitetura ou dados.'
    
    # Avaliar overfitting
    val_loss = historico['val_loss']
    train_loss = historico['loss']
    
    gap_final = val_loss[-1] - train_loss[-1]
    gap_pct = (gap_final / train_loss[-1]) * 100
    
    if gap_pct < 10:
        interpretacao['overfitting'] = 'N√£o detectado'
    elif gap_pct < 30:
        interpretacao['overfitting'] = 'Leve'
    else:
        interpretacao['overfitting'] = 'Moderado a Alto'
    
    # Avaliar R¬≤
    r2 = metricas['r2_score']
    
    if r2 > 0.9:
        interpretacao['capacidade_explicativa'] = 'Excelente (R¬≤ > 0.9)'
    elif r2 > 0.7:
        interpretacao['capacidade_explicativa'] = 'Boa (R¬≤ > 0.7)'
    elif r2 > 0.5:
        interpretacao['capacidade_explicativa'] = 'Moderada (R¬≤ > 0.5)'
    else:
        interpretacao['capacidade_explicativa'] = 'Baixa (R¬≤ < 0.5)'
    
    return interpretacao


# ===================================================================
# FUN√á√ÉO PRINCIPAL
# ===================================================================

def main():
    """
    Fun√ß√£o principal que executa todo o pipeline de treinamento e avalia√ß√£o.
    """
    try:
        # 1. Carregar dados e scaler
        dados = carregar_dados_preparados()
        scaler = carregar_scaler()
        
        # 2. Construir e compilar modelo
        model = construir_modelo_lstm()
        model = compilar_modelo(model)
        
        # 3. Configurar callbacks
        model_path = os.path.join(MODELS_DIR, 'lstm_model_best.h5')
        callbacks = configurar_callbacks(model_path)
        
        # 4. Treinar modelo
        history = treinar_modelo(model, dados, callbacks)
        
        # 5. Carregar melhor modelo
        print(f"üì• Carregando Melhor Modelo:")
        print(f"{'‚îÄ'*70}\n")
        print(f"   Carregando: {model_path}")
        model = keras.models.load_model(model_path)
        print(f"   ‚úÖ Melhor modelo carregado\n")
        
        # 6. Fazer predi√ß√µes
        y_pred_original, y_pred_norm = fazer_predicoes(model, dados['X_test'], scaler)
        
        # Inverter escala dos valores reais de teste
        # Pegar √∫ltimo timestep de cada sequ√™ncia
        ultima_sequencia_test = dados['X_test'][:, -1, :]
        y_test_full = scaler.inverse_transform(ultima_sequencia_test)
        y_test_original = y_test_full[:, 3]  # √çndice 3 = Close
        
        # 7. Calcular m√©tricas
        metricas = calcular_metricas(y_test_original, y_pred_original,
                                     dados['y_test'], y_pred_norm)
        
        # 8. Visualizar resultados
        visualizar_curvas_aprendizado(history)
        visualizar_predicoes(y_test_original, y_pred_original, metricas)
        
        # 9. Salvar resultados
        salvar_resultados(history, metricas)
        
        # 10. Exibir resumo final
        print(f"{'='*70}")
        print(f"‚úÖ FASE 4 CONCLU√çDA COM SUCESSO!")
        print(f"{'='*70}\n")
        print(f"üìÅ Arquivos gerados:")
        print(f"   ‚Üí models/lstm_model_best.h5")
        print(f"   ‚Üí docs/training/training_results.json")
        print(f"   ‚Üí docs/training/curvas_aprendizado.png")
        print(f"   ‚Üí docs/training/resultado_teste.png")
        print(f"\nüìä Resumo de Desempenho:")
        print(f"   ‚Üí RMSE: R$ {metricas['rmse']:.2f}")
        print(f"   ‚Üí MAE:  R$ {metricas['mae']:.2f}")
        print(f"   ‚Üí MAPE: {metricas['mape']:.2f}%")
        print(f"   ‚Üí R¬≤ Score: {metricas['r2_score']:.4f}")
        print(f"\nüéØ Pr√≥ximos passos:")
        print(f"   ‚Üí An√°lise detalhada dos resultados")
        print(f"   ‚Üí Ajuste de hiperpar√¢metros se necess√°rio")
        print(f"   ‚Üí Prepara√ß√£o para deploy (Fase 5)\n")
        
    except Exception as e:
        print(f"\n{'='*70}")
        print(f"‚ùå ERRO NA FASE 4: {str(e)}")
        print(f"{'='*70}\n")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
