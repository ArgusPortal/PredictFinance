"""
Sistema de Monitoramento de Performance do Modelo em ProduÃ§Ã£o

Compara previsÃµes realizadas com valores reais obtidos posteriormente.
Calcula mÃ©tricas de erro (MAE, MAPE) e detecta degradaÃ§Ã£o do modelo.

IMPORTANTE: Hierarquia de persistÃªncia:
1. PostgreSQL Render (produÃ§Ã£o na nuvem - persistente)
2. SQLite local (fallback se PostgreSQL nÃ£o disponÃ­vel)
3. JSON local (backup adicional)
"""

import json
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import deque

# Importar API v8 para busca de dados reais
try:
    from src.yahoo_finance_v8 import coletar_dados_yahoo_v8_custom_range
    API_V8_DISPONIVEL = True
except ImportError:
    API_V8_DISPONIVEL = False

# Importar banco de dados (suporta PostgreSQL + SQLite)
try:
    from database.db_manager import get_db
    DB_DISPONIVEL = True
except ImportError:
    DB_DISPONIVEL = False
    def get_db():
        return None


# DiretÃ³rios
ROOT_DIR = Path(__file__).parent.parent
LOGS_DIR = ROOT_DIR / "logs"
MONITORING_DIR = ROOT_DIR / "monitoring"
MONITORING_DIR.mkdir(exist_ok=True)

# Arquivo para armazenar previsÃµes aguardando validaÃ§Ã£o (fallback local)
PREDICTIONS_DB = MONITORING_DIR / "predictions_tracking.json"
PERFORMANCE_METRICS = MONITORING_DIR / "performance_metrics.json"


class PerformanceMonitor:
    """
    Monitora performance do modelo comparando previsÃµes vs valores reais.
    
    Funcionalidades:
    - Armazena previsÃµes para validaÃ§Ã£o posterior
    - Coleta preÃ§os reais do mercado
    - Calcula mÃ©tricas de erro (MAE, MAPE, RMSE)
    - MantÃ©m histÃ³rico de performance
    - Detecta degradaÃ§Ã£o do modelo
    
    IMPORTANTE: O db_manager.py jÃ¡ suporta PostgreSQL (quando DATABASE_URL estÃ¡ definida)
    com fallback automÃ¡tico para SQLite local.
    """
    
    def __init__(self, ticker: str = "B3SA3.SA", window_days: int = 7):
        """
        Inicializa o monitor de performance.
        
        Args:
            ticker: SÃ­mbolo da aÃ§Ã£o
            window_days: Janela mÃ³vel para cÃ¡lculo de mÃ©tricas (dias)
        """
        self.ticker = ticker
        self.window_days = window_days
        
        # Inicializar banco de dados (PostgreSQL ou SQLite - gerenciado pelo db_manager)
        self.db = None
        if DB_DISPONIVEL:
            try:
                self.db = get_db()
                if self.db and getattr(self.db, 'pg_enabled', False):
                    print("â˜ï¸ Usando PostgreSQL Render para persistÃªncia")
                elif self.db:
                    print("ğŸ’¾ Usando SQLite local para persistÃªncia")
            except Exception as e:
                print(f"âš ï¸ Banco de dados nÃ£o disponÃ­vel: {e}")
        
        # Carregar dados
        self.predictions_db = self._load_predictions_db()
        self.metrics_history = self._load_metrics_history()
    
    def _load_predictions_db(self) -> Dict:
        """
        Carrega banco de previsÃµes aguardando validaÃ§Ã£o.
        Hierarquia: Banco de dados (PostgreSQL/SQLite) > JSON local.
        
        Returns:
            DicionÃ¡rio com previsÃµes
        """
        # Prioridade 1: Banco de dados (PostgreSQL ou SQLite via db_manager)
        if self.db is not None:
            try:
                predictions = self.db.get_predictions(ticker=self.ticker, limit=500)
                if predictions:
                    db_type = "PostgreSQL" if getattr(self.db, 'pg_enabled', False) else "SQLite"
                    print(f"ğŸ“Š Carregadas {len(predictions)} previsÃµes do {db_type}")
                    return {"predictions": predictions}
            except Exception as e:
                print(f"âš ï¸ Erro ao carregar do banco: {e}")
        
        # Prioridade 2: Arquivo JSON local (fallback)
        if PREDICTIONS_DB.exists():
            with open(PREDICTIONS_DB, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"ğŸ“ Carregadas {len(data.get('predictions', []))} previsÃµes do JSON local")
                return data
        
        print("ğŸ“­ Nenhuma previsÃ£o encontrada")
        return {"predictions": []}
    
    def _save_predictions_db(self):
        """
        Salva banco de previsÃµes.
        JSON local Ã© mantido como backup adicional.
        """
        # Sempre salva no JSON local como backup
        try:
            with open(PREDICTIONS_DB, 'w', encoding='utf-8') as f:
                json.dump(self.predictions_db, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ Erro ao salvar JSON local: {e}")
    
    def _save_prediction_to_db(self, prediction_entry: Dict) -> bool:
        """
        Salva uma previsÃ£o no banco de dados (PostgreSQL ou SQLite).
        
        Args:
            prediction_entry: DicionÃ¡rio com dados da previsÃ£o
        
        Returns:
            True se salvo com sucesso
        """
        if self.db is None:
            return False
        
        try:
            saved = self.db.insert_prediction(
                request_id=prediction_entry.get("request_id", ""),
                ticker=self.ticker,
                timestamp=prediction_entry.get("timestamp", ""),
                predicted_value=prediction_entry.get("predicted_value", 0.0)
            )
            if saved:
                db_type = "PostgreSQL" if getattr(self.db, 'pg_enabled', False) else "SQLite"
                print(f"âœ… PrevisÃ£o salva no {db_type}")
                return True
        except Exception as e:
            print(f"âš ï¸ Erro ao salvar no banco: {e}")
        
        return False
    
    def _load_metrics_history(self) -> Dict:
        """
        Carrega histÃ³rico de mÃ©tricas de performance.
        
        Returns:
            DicionÃ¡rio com histÃ³rico
        """
        if PERFORMANCE_METRICS.exists():
            with open(PERFORMANCE_METRICS, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"daily_metrics": [], "summary": {}}
    
    def _save_metrics_history(self):
        """Salva histÃ³rico de mÃ©tricas."""
        with open(PERFORMANCE_METRICS, 'w', encoding='utf-8') as f:
            json.dump(self.metrics_history, f, indent=2, ensure_ascii=False)
    
    def register_prediction(
        self,
        prediction_value: float,
        prediction_date: str = None,
        request_id: str = None
    ):
        """
        Registra uma previsÃ£o para validaÃ§Ã£o futura.
        Salva no SQLite (persistente) e JSON (backup local).
        
        Args:
            prediction_value: Valor previsto
            prediction_date: Data da previsÃ£o (ISO format)
            request_id: ID da requisiÃ§Ã£o
        """
        if prediction_date is None:
            prediction_date = datetime.now().isoformat()
        
        prediction_entry = {
            "request_id": request_id,
            "timestamp": prediction_date,
            "predicted_value": float(prediction_value),
            "validated": False,
            "actual_value": None,
            "error": None
        }
        
        # Salvar no banco de dados SQLite (persistÃªncia em produÃ§Ã£o)
        db_saved = self._save_prediction_to_db(prediction_entry)
        if db_saved:
            print(f"âœ… PrevisÃ£o {request_id[:8] if request_id else 'N/A'} salva no banco de dados")
        
        # TambÃ©m salvar no JSON local (backup)
        self.predictions_db["predictions"].append(prediction_entry)
        self._save_predictions_db()
    
    def validate_predictions(self, days_back: int = 1) -> Dict:
        """
        Valida previsÃµes comparando com valores reais do mercado.
        
        Args:
            days_back: Quantos dias atrÃ¡s validar
        
        Returns:
            Resumo da validaÃ§Ã£o
        """
        print(f"\n{'='*60}")
        print("ğŸ” VALIDAÃ‡ÃƒO DE PREVISÃ•ES")
        print(f"{'='*60}")
        
        # Filtra previsÃµes nÃ£o validadas
        unvalidated = [
            p for p in self.predictions_db["predictions"] 
            if not p["validated"]
        ]
        
        if not unvalidated:
            print("âœ… Nenhuma previsÃ£o pendente de validaÃ§Ã£o")
            return {"validated": 0, "pending": 0}
        
        print(f"ğŸ“Š PrevisÃµes pendentes: {len(unvalidated)}")
        
        # ObtÃ©m dados reais do mercado
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back + 5)  # Margem de seguranÃ§a
        
        print(f"ğŸ“ˆ Baixando dados reais de {self.ticker}...")
        data = None
        
        # EstratÃ©gia 1: API v8 (prioridade)
        if API_V8_DISPONIVEL:
            try:
                print(f"   ğŸ”„ Tentando Yahoo Finance API v8...")
                df = coletar_dados_yahoo_v8_custom_range(
                    ticker=self.ticker,
                    start_date=start_date.strftime("%Y-%m-%d"),
                    end_date=end_date.strftime("%Y-%m-%d")
                )
                if not df.empty:
                    data = df
                    print(f"   âœ… API v8: {len(data)} registros")
            except Exception as e:
                print(f"   âš ï¸ API v8 falhou: {str(e)[:80]}")
        
        # EstratÃ©gia 2: yfinance (fallback)
        if data is None or data.empty:
            try:
                print(f"   ğŸ”„ Tentando yfinance...")
                data = yf.download(
                    self.ticker,
                    start=start_date,
                    end=end_date,
                    progress=False
                )
                if not data.empty:
                    print(f"   âœ… yfinance: {len(data)} registros")
            except Exception as e:
                print(f"   âŒ yfinance falhou: {str(e)[:80]}")
        
        # Validar se conseguiu dados
        if data is None or data.empty:
            error_msg = f"NÃ£o foi possÃ­vel obter dados reais para validaÃ§Ã£o"
            print(f"âŒ {error_msg}")
            return {
                "error": error_msg,
                "validated": 0,
                "pending": len(unvalidated)
            }
        
        # CORREÃ‡ÃƒO: Normalizar Ã­ndice do DataFrame para comparaÃ§Ã£o correta
        # O Ã­ndice pode ter timezone e/ou horÃ¡rio (ex: '2025-11-21 13:00:00')
        # Precisamos normalizar para apenas data (ex: '2025-11-21')
        if hasattr(data.index, 'tz') and data.index.tz is not None:
            data.index = data.index.tz_localize(None)
        data.index = pd.to_datetime(data.index).normalize()
        
        print(f"   ğŸ“… Datas disponÃ­veis: {data.index[0].date()} a {data.index[-1].date()}")
        
        validated_count = 0
        skipped_future = 0
        not_found = 0
        
        # Valida cada previsÃ£o
        for prediction in unvalidated:
            pred_date = datetime.fromisoformat(prediction["timestamp"])
            
            # Busca preÃ§o real do dia seguinte
            next_day = pred_date + timedelta(days=1)
            next_day_normalized = pd.Timestamp(next_day.date())  # Apenas data, sem horÃ¡rio
            
            # Verificar se jÃ¡ passou tempo suficiente
            today_normalized = pd.Timestamp(datetime.now().date())
            if next_day_normalized > today_normalized:
                skipped_future += 1
                continue  # Pular previsÃµes muito recentes
            
            # Tenta encontrar o preÃ§o real
            actual_value = None
            found_date = None
            for offset in range(5):  # Procura atÃ© 5 dias Ã  frente (fins de semana/feriados)
                check_date = next_day_normalized + timedelta(days=offset)
                
                if check_date in data.index:
                    actual_value = float(data.loc[check_date, 'Close'])
                    found_date = check_date
                    break
            
            if actual_value is not None:
                # Calcula erro
                error = abs(prediction["predicted_value"] - actual_value)
                error_pct = (error / actual_value) * 100
                
                # Atualiza previsÃ£o no dicionÃ¡rio
                prediction["validated"] = True
                prediction["actual_value"] = actual_value
                prediction["error"] = error
                prediction["error_pct"] = error_pct
                prediction["validation_date"] = datetime.now().isoformat()
                
                # Atualiza no banco de dados (PostgreSQL ou SQLite)
                request_id = prediction.get("request_id", "")
                validation_date = prediction["validation_date"]
                
                # Atualizar no banco de dados
                if self.db is not None:
                    try:
                        self.db.update_prediction_validation(
                            request_id=request_id,
                            actual_value=actual_value,
                            error=error,
                            error_pct=error_pct,
                            validation_date=validation_date
                        )
                    except Exception as e:
                        print(f"âš ï¸ Erro ao validar no banco: {e}")
                
                validated_count += 1
                
                print(f"   âœ… {prediction['request_id'][:8]}: "
                      f"Previsto={prediction['predicted_value']:.2f}, "
                      f"Real={actual_value:.2f}, "
                      f"Erro={error_pct:.2f}%")
            else:
                not_found += 1
                print(f"   âš ï¸  {prediction['request_id'][:8]}: Dados reais nÃ£o encontrados para {next_day.date()}")
        
        # Salva atualizaÃ§Ãµes no JSON (backup local)
        self._save_predictions_db()
        
        print(f"\nâœ… Validadas: {validated_count} previsÃµes")
        if skipped_future > 0:
            print(f"â­ï¸  Ignoradas: {skipped_future} previsÃµes muito recentes (aguardando dia seguinte)")
        if not_found > 0:
            print(f"âš ï¸  Sem dados: {not_found} previsÃµes (dados de mercado nÃ£o disponÃ­veis)")
        print(f"â³ Pendentes: {len(unvalidated) - validated_count - skipped_future}")
        
        # Calcula mÃ©tricas se houver validaÃ§Ãµes
        if validated_count > 0:
            self.calculate_metrics()
        
        return {
            "validated": validated_count,
            "skipped_future": skipped_future,
            "not_found": not_found,
            "pending": len(unvalidated) - validated_count - skipped_future,
            "message": f"Validadas {validated_count}, {skipped_future} aguardando dados reais"
        }
    
    def calculate_metrics(self) -> Dict:
        """
        Calcula mÃ©tricas de erro para previsÃµes validadas.
        
        Returns:
            DicionÃ¡rio com mÃ©tricas
        """
        # Filtra previsÃµes validadas
        validated = [
            p for p in self.predictions_db["predictions"] 
            if p["validated"] and p["error"] is not None
        ]
        
        if not validated:
            print("âš ï¸  Nenhuma previsÃ£o validada disponÃ­vel")
            return {}
        
        # Ordena por data
        validated.sort(key=lambda x: x["timestamp"])
        
        # Pega Ãºltimos N dias
        recent = validated[-self.window_days:] if len(validated) > self.window_days else validated
        
        # Calcula mÃ©tricas
        errors = [p["error"] for p in recent]
        error_pcts = [p["error_pct"] for p in recent]
        
        mae = np.mean(errors)
        mape = np.mean(error_pcts)
        rmse = np.sqrt(np.mean([e**2 for e in errors]))
        
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "window_days": len(recent),
            "mae": float(mae),
            "mape": float(mape),
            "rmse": float(rmse),
            "total_validated": len(validated),
            "min_error_pct": float(min(error_pcts)),
            "max_error_pct": float(max(error_pcts))
        }
        
        # Adiciona ao histÃ³rico
        self.metrics_history["daily_metrics"].append(metrics)
        
        # Atualiza resumo
        self.metrics_history["summary"] = {
            "last_update": metrics["timestamp"],
            "current_mae": metrics["mae"],
            "current_mape": metrics["mape"],
            "total_predictions_validated": len(validated)
        }
        
        self._save_metrics_history()
        
        print(f"\n{'='*60}")
        print("ğŸ“Š MÃ‰TRICAS DE PERFORMANCE")
        print(f"{'='*60}")
        print(f"Janela: Ãšltimos {len(recent)} dias")
        print(f"MAE:  {mae:.4f}")
        print(f"MAPE: {mape:.2f}%")
        print(f"RMSE: {rmse:.4f}")
        print(f"Erro MÃ­nimo: {min(error_pcts):.2f}%")
        print(f"Erro MÃ¡ximo: {max(error_pcts):.2f}%")
        print(f"{'='*60}\n")
        
        return metrics
    
    def detect_degradation(self, threshold_mape: float = 5.0) -> bool:
        """
        Detecta se o modelo estÃ¡ degradando.
        
        Args:
            threshold_mape: Limiar de MAPE para alertar (%)
        
        Returns:
            True se detectou degradaÃ§Ã£o
        """
        if not self.metrics_history["daily_metrics"]:
            return False
        
        current_metrics = self.metrics_history["daily_metrics"][-1]
        current_mape = current_metrics["mape"]
        
        if current_mape > threshold_mape:
            print(f"\nâš ï¸  ALERTA: DegradaÃ§Ã£o detectada!")
            print(f"   MAPE atual ({current_mape:.2f}%) > "
                  f"Threshold ({threshold_mape:.2f}%)")
            return True
        
        return False
    
    def get_performance_trend(self, days: int = 7) -> Dict:
        """
        Analisa tendÃªncia de performance nos Ãºltimos dias.
        
        Args:
            days: NÃºmero de dias para anÃ¡lise
        
        Returns:
            AnÃ¡lise de tendÃªncia
        """
        metrics = self.metrics_history["daily_metrics"][-days:]
        
        if len(metrics) < 2:
            return {"trend": "insufficient_data"}
        
        mapes = [m["mape"] for m in metrics]
        
        # Calcula tendÃªncia (regressÃ£o linear simples)
        x = np.arange(len(mapes))
        slope = np.polyfit(x, mapes, 1)[0]
        
        trend = {
            "days_analyzed": len(mapes),
            "initial_mape": mapes[0],
            "final_mape": mapes[-1],
            "avg_mape": np.mean(mapes),
            "slope": float(slope),
            "trend": "improving" if slope < -0.1 else "degrading" if slope > 0.1 else "stable"
        }
        
        return trend


def main():
    """FunÃ§Ã£o principal para execuÃ§Ã£o standalone."""
    print("\nğŸ” Monitor de Performance do Modelo B3SA3")
    print("="*60)
    
    monitor = PerformanceMonitor()
    
    # Valida previsÃµes pendentes
    result = monitor.validate_predictions(days_back=7)
    
    # Calcula mÃ©tricas
    if result.get("validated", 0) > 0:
        metrics = monitor.calculate_metrics()
        
        # Detecta degradaÃ§Ã£o
        if monitor.detect_degradation(threshold_mape=5.0):
            print("\nâš ï¸  AÃ‡ÃƒO NECESSÃRIA: Considere re-treinar o modelo!")
        else:
            print("\nâœ… Performance do modelo dentro do esperado")
        
        # Analisa tendÃªncia
        trend = monitor.get_performance_trend(days=7)
        if trend.get("trend") != "insufficient_data":
            print(f"\nğŸ“ˆ TendÃªncia (7 dias): {trend['trend'].upper()}")
            print(f"   MAPE mÃ©dio: {trend['avg_mape']:.2f}%")


if __name__ == "__main__":
    main()
